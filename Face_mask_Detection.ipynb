{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Face mask Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLQpKmONMjk6"
      },
      "source": [
        "## General Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IekxEuU4cu9n",
        "outputId": "13489917-93a7-49f1-b21b-e2fa0f960a7c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBAZZPCNhdWn",
        "outputId": "071d13a3-5372-48d1-9d9e-a051ad1f2ed3"
      },
      "source": [
        "!nvidia-smi\n",
        "!pip uninstall tensorflow==2.4.1\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.test.is_gpu_available(\n",
        "    cuda_only=False, min_cuda_compute_capability=None\n",
        "))\n",
        "print(tf.test.is_built_with_cuda())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  1 11:42:53 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Uninstalling tensorflow-2.5.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.5.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/67/559ca8408431c37ad3a17e859c8c291ea82f092354074baef482b98ffb7b/tensorflow_gpu-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (377.1MB)\n",
            "\u001b[K     |████████████████████████████████| 377.1MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 41.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (0.12.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.3.4)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.7.4.3)\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSJJT4rBh3tt",
        "outputId": "2e647d1c-0ba8-4680-8ce2-813efa4ef990"
      },
      "source": [
        "%cd /content/drive/MyDrive/Face mask Detection\n",
        "#!wget \"https://github.com/tensorflow/models/archive/v1.13.0.zip\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Face mask Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1wp9mPIeCj3",
        "outputId": "68b42e44-f4e3-44d4-c680-ba7164e86ced"
      },
      "source": [
        "!unzip v1.13.0.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  v1.13.0.zip\n",
            "57e075203f8fba8d85e6b74f17f63d0a07da233a\n",
            "   creating: models-1.13.0/\n",
            "  inflating: models-1.13.0/.gitignore  \n",
            "  inflating: models-1.13.0/.gitmodules  \n",
            "  inflating: models-1.13.0/AUTHORS   \n",
            "  inflating: models-1.13.0/CODEOWNERS  \n",
            "  inflating: models-1.13.0/CONTRIBUTING.md  \n",
            "  inflating: models-1.13.0/ISSUE_TEMPLATE.md  \n",
            "  inflating: models-1.13.0/LICENSE   \n",
            "  inflating: models-1.13.0/README.md  \n",
            " extracting: models-1.13.0/WORKSPACE  \n",
            "   creating: models-1.13.0/official/\n",
            " extracting: models-1.13.0/official/.gitignore  \n",
            "  inflating: models-1.13.0/official/Dockerfile.cpu  \n",
            "  inflating: models-1.13.0/official/Dockerfile.gpu  \n",
            "  inflating: models-1.13.0/official/README.md  \n",
            " extracting: models-1.13.0/official/__init__.py  \n",
            "   creating: models-1.13.0/official/benchmark/\n",
            " extracting: models-1.13.0/official/benchmark/__init__.py  \n",
            "  inflating: models-1.13.0/official/benchmark/benchmark_uploader.py  \n",
            "  inflating: models-1.13.0/official/benchmark/benchmark_uploader_main.py  \n",
            "  inflating: models-1.13.0/official/benchmark/benchmark_uploader_test.py  \n",
            "   creating: models-1.13.0/official/benchmark/datastore/\n",
            "   creating: models-1.13.0/official/benchmark/datastore/schema/\n",
            "  inflating: models-1.13.0/official/benchmark/datastore/schema/benchmark_metric.json  \n",
            "  inflating: models-1.13.0/official/benchmark/datastore/schema/benchmark_run.json  \n",
            "  inflating: models-1.13.0/official/benchmark/datastore/schema/benchmark_run_status.json  \n",
            "   creating: models-1.13.0/official/boosted_trees/\n",
            "  inflating: models-1.13.0/official/boosted_trees/README.md  \n",
            " extracting: models-1.13.0/official/boosted_trees/__init__.py  \n",
            "  inflating: models-1.13.0/official/boosted_trees/data_download.py  \n",
            "  inflating: models-1.13.0/official/boosted_trees/train_higgs.py  \n",
            "  inflating: models-1.13.0/official/boosted_trees/train_higgs_test.csv  \n",
            "  inflating: models-1.13.0/official/boosted_trees/train_higgs_test.py  \n",
            "   creating: models-1.13.0/official/datasets/\n",
            " extracting: models-1.13.0/official/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/official/datasets/movielens.py  \n",
            "   creating: models-1.13.0/official/keras_application_models/\n",
            "  inflating: models-1.13.0/official/keras_application_models/README.md  \n",
            " extracting: models-1.13.0/official/keras_application_models/__init__.py  \n",
            "  inflating: models-1.13.0/official/keras_application_models/benchmark_main.py  \n",
            "  inflating: models-1.13.0/official/keras_application_models/dataset.py  \n",
            "  inflating: models-1.13.0/official/keras_application_models/model_callbacks.py  \n",
            "   creating: models-1.13.0/official/mnist/\n",
            "  inflating: models-1.13.0/official/mnist/README.md  \n",
            " extracting: models-1.13.0/official/mnist/__init__.py  \n",
            "  inflating: models-1.13.0/official/mnist/dataset.py  \n",
            " extracting: models-1.13.0/official/mnist/example3.png  \n",
            "  inflating: models-1.13.0/official/mnist/example5.png  \n",
            "  inflating: models-1.13.0/official/mnist/examples.npy  \n",
            "  inflating: models-1.13.0/official/mnist/mnist.py  \n",
            "  inflating: models-1.13.0/official/mnist/mnist_eager.py  \n",
            "  inflating: models-1.13.0/official/mnist/mnist_eager_test.py  \n",
            "  inflating: models-1.13.0/official/mnist/mnist_test.py  \n",
            "  inflating: models-1.13.0/official/mnist/mnist_tpu.py  \n",
            "   creating: models-1.13.0/official/recommendation/\n",
            "  inflating: models-1.13.0/official/recommendation/README.md  \n",
            " extracting: models-1.13.0/official/recommendation/__init__.py  \n",
            "  inflating: models-1.13.0/official/recommendation/constants.py  \n",
            "  inflating: models-1.13.0/official/recommendation/data_pipeline.py  \n",
            "  inflating: models-1.13.0/official/recommendation/data_preprocessing.py  \n",
            "  inflating: models-1.13.0/official/recommendation/data_test.py  \n",
            "  inflating: models-1.13.0/official/recommendation/ncf_main.py  \n",
            "  inflating: models-1.13.0/official/recommendation/ncf_test.py  \n",
            "  inflating: models-1.13.0/official/recommendation/neumf_model.py  \n",
            "  inflating: models-1.13.0/official/recommendation/popen_helper.py  \n",
            "  inflating: models-1.13.0/official/recommendation/run.sh  \n",
            "  inflating: models-1.13.0/official/recommendation/run_tpu.sh  \n",
            "  inflating: models-1.13.0/official/recommendation/stat_utils.py  \n",
            "  inflating: models-1.13.0/official/requirements.txt  \n",
            "   creating: models-1.13.0/official/resnet/\n",
            "  inflating: models-1.13.0/official/resnet/README.md  \n",
            " extracting: models-1.13.0/official/resnet/__init__.py  \n",
            "  inflating: models-1.13.0/official/resnet/cifar10_download_and_extract.py  \n",
            "  inflating: models-1.13.0/official/resnet/cifar10_main.py  \n",
            "  inflating: models-1.13.0/official/resnet/cifar10_test.py  \n",
            "  inflating: models-1.13.0/official/resnet/estimator_cifar_benchmark.py  \n",
            "  inflating: models-1.13.0/official/resnet/imagenet_main.py  \n",
            "  inflating: models-1.13.0/official/resnet/imagenet_preprocessing.py  \n",
            "  inflating: models-1.13.0/official/resnet/imagenet_test.py  \n",
            "   creating: models-1.13.0/official/resnet/keras/\n",
            " extracting: models-1.13.0/official/resnet/keras/__init__.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/keras_benchmark.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/keras_cifar_benchmark.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/keras_cifar_main.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/keras_common.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/keras_common_test.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/keras_imagenet_benchmark.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/keras_imagenet_main.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/resnet_cifar_model.py  \n",
            "  inflating: models-1.13.0/official/resnet/keras/resnet_model.py  \n",
            "  inflating: models-1.13.0/official/resnet/layer_test.py  \n",
            "  inflating: models-1.13.0/official/resnet/resnet_model.py  \n",
            "  inflating: models-1.13.0/official/resnet/resnet_run_loop.py  \n",
            "   creating: models-1.13.0/official/transformer/\n",
            "  inflating: models-1.13.0/official/transformer/README.md  \n",
            " extracting: models-1.13.0/official/transformer/__init__.py  \n",
            "  inflating: models-1.13.0/official/transformer/compute_bleu.py  \n",
            "  inflating: models-1.13.0/official/transformer/compute_bleu_test.py  \n",
            "  inflating: models-1.13.0/official/transformer/data_download.py  \n",
            "   creating: models-1.13.0/official/transformer/model/\n",
            " extracting: models-1.13.0/official/transformer/model/__init__.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/attention_layer.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/beam_search.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/beam_search_test.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/embedding_layer.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/ffn_layer.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/model_params.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/model_utils.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/model_utils_test.py  \n",
            "  inflating: models-1.13.0/official/transformer/model/transformer.py  \n",
            "   creating: models-1.13.0/official/transformer/test_data/\n",
            "  inflating: models-1.13.0/official/transformer/test_data/newstest2014.de  \n",
            "  inflating: models-1.13.0/official/transformer/test_data/newstest2014.en  \n",
            "  inflating: models-1.13.0/official/transformer/transformer_main.py  \n",
            "  inflating: models-1.13.0/official/transformer/translate.py  \n",
            "   creating: models-1.13.0/official/transformer/utils/\n",
            " extracting: models-1.13.0/official/transformer/utils/__init__.py  \n",
            "  inflating: models-1.13.0/official/transformer/utils/dataset.py  \n",
            "  inflating: models-1.13.0/official/transformer/utils/metrics.py  \n",
            "  inflating: models-1.13.0/official/transformer/utils/schedule.py  \n",
            "  inflating: models-1.13.0/official/transformer/utils/schedule_test.py  \n",
            "  inflating: models-1.13.0/official/transformer/utils/tokenizer.py  \n",
            "  inflating: models-1.13.0/official/transformer/utils/tokenizer_test.py  \n",
            "   creating: models-1.13.0/official/utils/\n",
            " extracting: models-1.13.0/official/utils/__init__.py  \n",
            "   creating: models-1.13.0/official/utils/accelerator/\n",
            " extracting: models-1.13.0/official/utils/accelerator/__init__.py  \n",
            "  inflating: models-1.13.0/official/utils/accelerator/tpu.py  \n",
            "  inflating: models-1.13.0/official/utils/accelerator/tpu_test.py  \n",
            "   creating: models-1.13.0/official/utils/data/\n",
            " extracting: models-1.13.0/official/utils/data/__init__.py  \n",
            "  inflating: models-1.13.0/official/utils/data/file_io.py  \n",
            "  inflating: models-1.13.0/official/utils/data/file_io_test.py  \n",
            "   creating: models-1.13.0/official/utils/export/\n",
            " extracting: models-1.13.0/official/utils/export/__init__.py  \n",
            "  inflating: models-1.13.0/official/utils/export/export.py  \n",
            "  inflating: models-1.13.0/official/utils/export/export_test.py  \n",
            "   creating: models-1.13.0/official/utils/flags/\n",
            "  inflating: models-1.13.0/official/utils/flags/README.md  \n",
            " extracting: models-1.13.0/official/utils/flags/__init__.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/_base.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/_benchmark.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/_conventions.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/_device.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/_misc.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/_performance.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/core.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/flags_test.py  \n",
            "  inflating: models-1.13.0/official/utils/flags/guidelines.md  \n",
            "   creating: models-1.13.0/official/utils/logs/\n",
            " extracting: models-1.13.0/official/utils/logs/__init__.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/cloud_lib.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/cloud_lib_test.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/guidelines.md  \n",
            "  inflating: models-1.13.0/official/utils/logs/hooks.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/hooks_helper.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/hooks_helper_test.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/hooks_test.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/logger.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/logger_test.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/metric_hook.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/metric_hook_test.py  \n",
            "  inflating: models-1.13.0/official/utils/logs/mlperf_helper.py  \n",
            "   creating: models-1.13.0/official/utils/misc/\n",
            " extracting: models-1.13.0/official/utils/misc/__init__.py  \n",
            "  inflating: models-1.13.0/official/utils/misc/distribution_utils.py  \n",
            "  inflating: models-1.13.0/official/utils/misc/distribution_utils_test.py  \n",
            "  inflating: models-1.13.0/official/utils/misc/model_helpers.py  \n",
            "  inflating: models-1.13.0/official/utils/misc/model_helpers_test.py  \n",
            "   creating: models-1.13.0/official/utils/testing/\n",
            " extracting: models-1.13.0/official/utils/testing/__init__.py  \n",
            "  inflating: models-1.13.0/official/utils/testing/integration.py  \n",
            "  inflating: models-1.13.0/official/utils/testing/mock_lib.py  \n",
            "  inflating: models-1.13.0/official/utils/testing/pylint.rcfile  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data.py  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/\n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/\n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/dense/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/dense/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/dense/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/dense/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/dense/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/reference_data_test/dense/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/uniform_random/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/uniform_random/expected_graph  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/reference_data_test/uniform_random/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/reference_data_test/uniform_random/model.ckpt.index  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/reference_data_test/uniform_random/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/reference_data_test/uniform_random/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/\n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-1_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-1_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-1_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-1_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-1_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-1_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-2_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-2_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-2_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-2_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-2_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_projection_version-2_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-1_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-1_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-1_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-1_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-1_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-1_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-2_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-2_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-2_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-2_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-2_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_bottleneck_version-2_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-1_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-1_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-1_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-1_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-1_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-1_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-2_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-2_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-2_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-2_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-2_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_projection_version-2_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-1_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-1_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-1_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-1_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-1_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-1_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-2_width-8_channels-4/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-2_width-8_channels-4/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-2_width-8_channels-4/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-2_width-8_channels-4/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-2_width-8_channels-4/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch-size-32_building_version-2_width-8_channels-4/tf_version.json  \n",
            "   creating: models-1.13.0/official/utils/testing/reference_data/resnet/batch_norm/\n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch_norm/expected_graph  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch_norm/model.ckpt.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch_norm/model.ckpt.index  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data/resnet/batch_norm/results.json  \n",
            " extracting: models-1.13.0/official/utils/testing/reference_data/resnet/batch_norm/tf_version.json  \n",
            "  inflating: models-1.13.0/official/utils/testing/reference_data_test.py  \n",
            "   creating: models-1.13.0/official/utils/testing/scripts/\n",
            "  inflating: models-1.13.0/official/utils/testing/scripts/presubmit.sh  \n",
            "   creating: models-1.13.0/official/wide_deep/\n",
            "  inflating: models-1.13.0/official/wide_deep/README.md  \n",
            " extracting: models-1.13.0/official/wide_deep/__init__.py  \n",
            "  inflating: models-1.13.0/official/wide_deep/census_dataset.py  \n",
            "  inflating: models-1.13.0/official/wide_deep/census_main.py  \n",
            "  inflating: models-1.13.0/official/wide_deep/census_test.csv  \n",
            "  inflating: models-1.13.0/official/wide_deep/census_test.py  \n",
            "  inflating: models-1.13.0/official/wide_deep/movielens_dataset.py  \n",
            "  inflating: models-1.13.0/official/wide_deep/movielens_main.py  \n",
            "  inflating: models-1.13.0/official/wide_deep/movielens_test.py  \n",
            "  inflating: models-1.13.0/official/wide_deep/wide_deep_run_loop.py  \n",
            "   creating: models-1.13.0/research/\n",
            "  inflating: models-1.13.0/research/README.md  \n",
            "   creating: models-1.13.0/research/a3c_blogpost/\n",
            "  inflating: models-1.13.0/research/a3c_blogpost/README.md  \n",
            "  inflating: models-1.13.0/research/a3c_blogpost/a3c_cartpole.py  \n",
            "   creating: models-1.13.0/research/adv_imagenet_models/\n",
            "  inflating: models-1.13.0/research/adv_imagenet_models/README.md  \n",
            "  inflating: models-1.13.0/research/adv_imagenet_models/eval_on_adversarial.py  \n",
            "  inflating: models-1.13.0/research/adv_imagenet_models/imagenet.py  \n",
            "  inflating: models-1.13.0/research/adv_imagenet_models/inception_resnet_v2.py  \n",
            "   creating: models-1.13.0/research/adversarial_crypto/\n",
            "  inflating: models-1.13.0/research/adversarial_crypto/README.md  \n",
            "  inflating: models-1.13.0/research/adversarial_crypto/train_eval.py  \n",
            "   creating: models-1.13.0/research/adversarial_logit_pairing/\n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/README.md  \n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/adversarial_attack.py  \n",
            "   creating: models-1.13.0/research/adversarial_logit_pairing/datasets/\n",
            " extracting: models-1.13.0/research/adversarial_logit_pairing/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/datasets/dataset_factory.py  \n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/datasets/imagenet_input.py  \n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/datasets/tiny_imagenet_input.py  \n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/eval.py  \n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/model_lib.py  \n",
            "   creating: models-1.13.0/research/adversarial_logit_pairing/tiny_imagenet_converter/\n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/tiny_imagenet_converter/converter.py  \n",
            "  inflating: models-1.13.0/research/adversarial_logit_pairing/train.py  \n",
            "   creating: models-1.13.0/research/adversarial_text/\n",
            "  inflating: models-1.13.0/research/adversarial_text/README.md  \n",
            " extracting: models-1.13.0/research/adversarial_text/__init__.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/adversarial_losses.py  \n",
            "   creating: models-1.13.0/research/adversarial_text/data/\n",
            " extracting: models-1.13.0/research/adversarial_text/data/__init__.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/data/data_utils.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/data/data_utils_test.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/data/document_generators.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/evaluate.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/gen_data.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/gen_vocab.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/graphs.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/graphs_test.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/inputs.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/layers.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/pretrain.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/train_classifier.py  \n",
            "  inflating: models-1.13.0/research/adversarial_text/train_utils.py  \n",
            "   creating: models-1.13.0/research/astronet/\n",
            "  inflating: models-1.13.0/research/astronet/README.md  \n",
            "   creating: models-1.13.0/research/attention_ocr/\n",
            "  inflating: models-1.13.0/research/attention_ocr/README.md  \n",
            "   creating: models-1.13.0/research/attention_ocr/python/\n",
            "  inflating: models-1.13.0/research/attention_ocr/python/all_jobs.screenrc  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/common_flags.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/data_provider.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/data_provider_test.py  \n",
            "   creating: models-1.13.0/research/attention_ocr/python/datasets/\n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/fsns.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/fsns_test.py  \n",
            "   creating: models-1.13.0/research/attention_ocr/python/datasets/testdata/\n",
            "   creating: models-1.13.0/research/attention_ocr/python/datasets/testdata/fsns/\n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/testdata/fsns/charset_size=134.txt  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/testdata/fsns/fsns-00000-of-00001  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/testdata/fsns/links.txt  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/unittest_utils.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/datasets/unittest_utils_test.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/demo_inference.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/demo_inference_test.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/eval.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/inception_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/metrics.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/metrics_test.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/model.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/model_test.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/sequence_layers.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/sequence_layers_test.py  \n",
            "   creating: models-1.13.0/research/attention_ocr/python/testdata/\n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_00.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_01.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_02.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_03.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_04.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_05.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_06.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_07.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_08.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_09.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_10.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_11.png  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_12.png  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_13.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_14.png  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_15.png  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_16.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_17.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_18.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_19.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_20.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_21.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_22.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_23.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_24.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_25.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_26.png  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_27.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_28.png  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_29.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_30.png  \n",
            " extracting: models-1.13.0/research/attention_ocr/python/testdata/fsns_train_31.png  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/train.py  \n",
            "  inflating: models-1.13.0/research/attention_ocr/python/utils.py  \n",
            "   creating: models-1.13.0/research/audioset/\n",
            "  inflating: models-1.13.0/research/audioset/README.md  \n",
            "  inflating: models-1.13.0/research/audioset/mel_features.py  \n",
            "  inflating: models-1.13.0/research/audioset/vggish_inference_demo.py  \n",
            "  inflating: models-1.13.0/research/audioset/vggish_input.py  \n",
            "  inflating: models-1.13.0/research/audioset/vggish_params.py  \n",
            "  inflating: models-1.13.0/research/audioset/vggish_postprocess.py  \n",
            "  inflating: models-1.13.0/research/audioset/vggish_slim.py  \n",
            "  inflating: models-1.13.0/research/audioset/vggish_smoke_test.py  \n",
            "  inflating: models-1.13.0/research/audioset/vggish_train_demo.py  \n",
            "   creating: models-1.13.0/research/autoaugment/\n",
            "  inflating: models-1.13.0/research/autoaugment/README.md  \n",
            "  inflating: models-1.13.0/research/autoaugment/augmentation_transforms.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/custom_ops.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/data_utils.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/helper_utils.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/policies.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/shake_drop.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/shake_shake.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/train_cifar.py  \n",
            "  inflating: models-1.13.0/research/autoaugment/wrn.py  \n",
            "   creating: models-1.13.0/research/autoencoder/\n",
            "  inflating: models-1.13.0/research/autoencoder/AdditiveGaussianNoiseAutoencoderRunner.py  \n",
            "  inflating: models-1.13.0/research/autoencoder/AutoencoderRunner.py  \n",
            "  inflating: models-1.13.0/research/autoencoder/MaskingNoiseAutoencoderRunner.py  \n",
            "  inflating: models-1.13.0/research/autoencoder/VariationalAutoencoderRunner.py  \n",
            " extracting: models-1.13.0/research/autoencoder/__init__.py  \n",
            "   creating: models-1.13.0/research/autoencoder/autoencoder_models/\n",
            "  inflating: models-1.13.0/research/autoencoder/autoencoder_models/Autoencoder.py  \n",
            "  inflating: models-1.13.0/research/autoencoder/autoencoder_models/DenoisingAutoencoder.py  \n",
            "  inflating: models-1.13.0/research/autoencoder/autoencoder_models/VariationalAutoencoder.py  \n",
            " extracting: models-1.13.0/research/autoencoder/autoencoder_models/__init__.py  \n",
            "   creating: models-1.13.0/research/brain_coder/\n",
            "  inflating: models-1.13.0/research/brain_coder/README.md  \n",
            "  inflating: models-1.13.0/research/brain_coder/WORKSPACE  \n",
            "   creating: models-1.13.0/research/brain_coder/common/\n",
            "  inflating: models-1.13.0/research/brain_coder/common/BUILD  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/bf.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/bf_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/config_lib.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/config_lib_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/reward.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/reward_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/rollout.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/rollout_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/schedules.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/schedules_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/utils.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/common/utils_test.py  \n",
            "   creating: models-1.13.0/research/brain_coder/single_task/\n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/BUILD  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/README.md  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/aggregate_experiment_results.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/aggregate_tuning_results.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/code_tasks.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/code_tasks_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/data.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/defaults.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/ga_lib.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/ga_train.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/ga_train_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/launch_training.sh  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/launch_tuning.sh  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/misc.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/pg_agent.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/pg_agent_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/pg_train.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/pg_train_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/results_lib.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/results_lib_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/run.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/run_eval_tasks.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/test_tasks.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/test_tasks_test.py  \n",
            "  inflating: models-1.13.0/research/brain_coder/single_task/tune.py  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/\n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/.gitignore  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/README.md  \n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/__init__.py  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/cfgs/\n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/cfgs/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/cfgs/config_cmp.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/cfgs/config_common.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/cfgs/config_distill.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/cfgs/config_vision_baseline.py  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/data/\n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/data/.gitignore  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/data/README.md  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/datasets/\n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/datasets/factory.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/datasets/nav_env.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/datasets/nav_env_config.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/matplotlibrc  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/output/\n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/output/.gitignore  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/output/README.md  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/patches/\n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/patches/GLES2_2_0.py.patch  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/patches/apply_patches.sh  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/patches/ctypesloader.py.patch  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/render/\n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/render/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/render/depth_rgb_encoded.fp  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/render/depth_rgb_encoded.vp  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/render/rgb_flat_color.fp  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/render/rgb_flat_color.vp  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/render/swiftshader_renderer.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/requirements.txt  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/\n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/scripts/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_distill.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_download_init_models.sh  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_env_vis.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_nav_agent_release.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_plot_trajectory.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_preprocess_annoations_S3DIS.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_preprocess_annoations_S3DIS.sh  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_preprocess_meshes_S3DIS.sh  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/scripts/script_test_pretrained_models.sh  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/src/\n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/src/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/src/depth_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/src/file_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/src/graph_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/src/map_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/src/rotation_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/src/utils.py  \n",
            "   creating: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/\n",
            " extracting: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/cmp.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/cmp_summary.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/cmp_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/nav_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/tf_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_mapping_and_planning/tfcode/vision_baseline_lstm.py  \n",
            "   creating: models-1.13.0/research/cognitive_planning/\n",
            "  inflating: models-1.13.0/research/cognitive_planning/BUILD  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/README.md  \n",
            " extracting: models-1.13.0/research/cognitive_planning/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/command  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/embedders.py  \n",
            "   creating: models-1.13.0/research/cognitive_planning/envs/\n",
            " extracting: models-1.13.0/research/cognitive_planning/envs/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/envs/active_vision_dataset_env.py  \n",
            "   creating: models-1.13.0/research/cognitive_planning/envs/configs/\n",
            "  inflating: models-1.13.0/research/cognitive_planning/envs/configs/active_vision_config.gin  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/envs/task_env.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/envs/util.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/label_map.txt  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/label_map_util.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/policies.py  \n",
            "   creating: models-1.13.0/research/cognitive_planning/preprocessing/\n",
            " extracting: models-1.13.0/research/cognitive_planning/preprocessing/__init__.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/preprocessing/cifarnet_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/preprocessing/inception_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/preprocessing/lenet_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/preprocessing/preprocessing_factory.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/preprocessing/vgg_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/standard_fields.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/string_int_label_map_pb2.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/tasks.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/train_supervised_active_vision.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/train_supervised_active_vision.sh  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/visualization_utils.py  \n",
            "  inflating: models-1.13.0/research/cognitive_planning/viz_active_vision_dataset_main.py  \n",
            "   creating: models-1.13.0/research/compression/\n",
            "  inflating: models-1.13.0/research/compression/README.md  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/\n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/README.md  \n",
            " extracting: models-1.13.0/research/compression/entropy_coder/__init__.py  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/all_models/\n",
            " extracting: models-1.13.0/research/compression/entropy_coder/all_models/__init__.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/all_models/all_models.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/all_models/all_models_test.py  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/configs/\n",
            "   creating: models-1.13.0/research/compression/entropy_coder/configs/gru_prime3/\n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/configs/gru_prime3/model_config.json  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/configs/synthetic/\n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/configs/synthetic/input_config.json  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/configs/synthetic/model_config.json  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/configs/synthetic/train_config.json  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/core/\n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/core/code_loader.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/core/config_helper.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/core/entropy_coder_single.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/core/entropy_coder_train.py  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/dataset/\n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/dataset/gen_synthetic_dataset.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/dataset/gen_synthetic_single.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/dataset/synthetic_model.py  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/lib/\n",
            " extracting: models-1.13.0/research/compression/entropy_coder/lib/__init__.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/block_base.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/block_util.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_binarizer.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_entropy_coding.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_entropy_coding_test.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_lstm.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_lstm_test.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_masked_conv2d.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_masked_conv2d_lstm.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_masked_conv2d_test.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_operator.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_operator_test.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_std.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/lib/blocks_std_test.py  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/model/\n",
            " extracting: models-1.13.0/research/compression/entropy_coder/model/__init__.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/model/entropy_coder_model.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/model/model_factory.py  \n",
            "   creating: models-1.13.0/research/compression/entropy_coder/progressive/\n",
            " extracting: models-1.13.0/research/compression/entropy_coder/progressive/__init__.py  \n",
            "  inflating: models-1.13.0/research/compression/entropy_coder/progressive/progressive.py  \n",
            "   creating: models-1.13.0/research/compression/image_encoder/\n",
            "  inflating: models-1.13.0/research/compression/image_encoder/README.md  \n",
            "  inflating: models-1.13.0/research/compression/image_encoder/decoder.py  \n",
            "  inflating: models-1.13.0/research/compression/image_encoder/encoder.py  \n",
            "  inflating: models-1.13.0/research/compression/image_encoder/example.png  \n",
            "  inflating: models-1.13.0/research/compression/image_encoder/msssim.py  \n",
            "   creating: models-1.13.0/research/cvt_text/\n",
            "  inflating: models-1.13.0/research/cvt_text/README.md  \n",
            " extracting: models-1.13.0/research/cvt_text/__init__.py  \n",
            "   creating: models-1.13.0/research/cvt_text/base/\n",
            " extracting: models-1.13.0/research/cvt_text/base/__init__.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/base/configure.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/base/embeddings.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/base/utils.py  \n",
            "   creating: models-1.13.0/research/cvt_text/corpus_processing/\n",
            " extracting: models-1.13.0/research/cvt_text/corpus_processing/__init__.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/corpus_processing/example.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/corpus_processing/minibatching.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/corpus_processing/scorer.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/corpus_processing/unlabeled_data.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/cvt.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/fetch_data.sh  \n",
            "   creating: models-1.13.0/research/cvt_text/model/\n",
            " extracting: models-1.13.0/research/cvt_text/model/__init__.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/model/encoder.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/model/model_helpers.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/model/multitask_model.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/model/shared_inputs.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/model/task_module.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/preprocessing.py  \n",
            "   creating: models-1.13.0/research/cvt_text/task_specific/\n",
            " extracting: models-1.13.0/research/cvt_text/task_specific/__init__.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/task_definitions.py  \n",
            "   creating: models-1.13.0/research/cvt_text/task_specific/word_level/\n",
            " extracting: models-1.13.0/research/cvt_text/task_specific/word_level/__init__.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/word_level/depparse_module.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/word_level/depparse_scorer.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/word_level/tagging_module.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/word_level/tagging_scorers.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/word_level/tagging_utils.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/word_level/word_level_data.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/task_specific/word_level/word_level_scorer.py  \n",
            "   creating: models-1.13.0/research/cvt_text/training/\n",
            " extracting: models-1.13.0/research/cvt_text/training/__init__.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/training/trainer.py  \n",
            "  inflating: models-1.13.0/research/cvt_text/training/training_progress.py  \n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/\n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/README.md  \n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/bandits/\n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/\n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/\n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/bb_alpha_divergence_model.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/bf_variational_neural_bandit_model.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/bootstrapped_bnn_sampling.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/fixed_policy_sampling.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/linear_full_posterior_sampling.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/multitask_gp.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/neural_bandit_model.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/neural_linear_sampling.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/parameter_noise_sampling.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/posterior_bnn_sampling.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/uniform_sampling.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/__pycache__/variational_neural_bandit_model.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/bb_alpha_divergence_model.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/bf_variational_neural_bandit_model.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/bootstrapped_bnn_sampling.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/fixed_policy_sampling.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/linear_full_posterior_sampling.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/multitask_gp.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/neural_bandit_model.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/neural_linear_sampling.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/parameter_noise_sampling.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/posterior_bnn_sampling.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/uniform_sampling.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/algorithms/variational_neural_bandit_model.py  \n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/bandits/core/\n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/bandits/core/__pycache__/\n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/__pycache__/bandit_algorithm.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/__pycache__/bayesian_nn.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/__pycache__/contextual_bandit.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/__pycache__/contextual_dataset.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/bandit_algorithm.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/bayesian_nn.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/contextual_bandit.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/core/contextual_dataset.py  \n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/bandits/data/\n",
            "   creating: models-1.13.0/research/deep_contextual_bandits/bandits/data/__pycache__/\n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/data/__pycache__/data_sampler.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/data/__pycache__/synthetic_data_sampler.cpython-36.pyc  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/data/data_sampler.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/bandits/data/synthetic_data_sampler.py  \n",
            "  inflating: models-1.13.0/research/deep_contextual_bandits/example_main.py  \n",
            "   creating: models-1.13.0/research/deep_speech/\n",
            "  inflating: models-1.13.0/research/deep_speech/README.md  \n",
            " extracting: models-1.13.0/research/deep_speech/__init__.py  \n",
            "   creating: models-1.13.0/research/deep_speech/data/\n",
            " extracting: models-1.13.0/research/deep_speech/data/__init__.py  \n",
            "  inflating: models-1.13.0/research/deep_speech/data/dataset.py  \n",
            "  inflating: models-1.13.0/research/deep_speech/data/download.py  \n",
            "  inflating: models-1.13.0/research/deep_speech/data/featurizer.py  \n",
            "  inflating: models-1.13.0/research/deep_speech/data/vocabulary.txt  \n",
            "  inflating: models-1.13.0/research/deep_speech/decoder.py  \n",
            "  inflating: models-1.13.0/research/deep_speech/deep_speech.py  \n",
            "  inflating: models-1.13.0/research/deep_speech/deep_speech_model.py  \n",
            "  inflating: models-1.13.0/research/deep_speech/requirements.txt  \n",
            "  inflating: models-1.13.0/research/deep_speech/run_deep_speech.sh  \n",
            "   creating: models-1.13.0/research/deeplab/\n",
            "  inflating: models-1.13.0/research/deeplab/README.md  \n",
            " extracting: models-1.13.0/research/deeplab/__init__.py  \n",
            "  inflating: models-1.13.0/research/deeplab/common.py  \n",
            "  inflating: models-1.13.0/research/deeplab/common_test.py  \n",
            "   creating: models-1.13.0/research/deeplab/core/\n",
            " extracting: models-1.13.0/research/deeplab/core/__init__.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/dense_prediction_cell.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/dense_prediction_cell_branch5_top1_cityscapes.json  \n",
            "  inflating: models-1.13.0/research/deeplab/core/dense_prediction_cell_test.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/preprocess_utils.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/preprocess_utils_test.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/resnet_v1_beta.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/resnet_v1_beta_test.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/utils.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/utils_test.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/xception.py  \n",
            "  inflating: models-1.13.0/research/deeplab/core/xception_test.py  \n",
            "   creating: models-1.13.0/research/deeplab/datasets/\n",
            " extracting: models-1.13.0/research/deeplab/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/build_ade20k_data.py  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/build_cityscapes_data.py  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/build_data.py  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/build_voc2012_data.py  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/convert_cityscapes.sh  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/download_and_convert_ade20k.sh  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/download_and_convert_voc2012.sh  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/remove_gt_colormap.py  \n",
            "  inflating: models-1.13.0/research/deeplab/datasets/segmentation_dataset.py  \n",
            "  inflating: models-1.13.0/research/deeplab/deeplab_demo.ipynb  \n",
            "  inflating: models-1.13.0/research/deeplab/eval.py  \n",
            "  inflating: models-1.13.0/research/deeplab/export_model.py  \n",
            "   creating: models-1.13.0/research/deeplab/g3doc/\n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/ade20k.md  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/cityscapes.md  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/export_model.md  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/faq.md  \n",
            "   creating: models-1.13.0/research/deeplab/g3doc/img/\n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/img/image1.jpg  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/img/image2.jpg  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/img/image3.jpg  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/img/image_info.txt  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/img/vis1.png  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/img/vis2.png  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/img/vis3.png  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/installation.md  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/model_zoo.md  \n",
            "  inflating: models-1.13.0/research/deeplab/g3doc/pascal.md  \n",
            "  inflating: models-1.13.0/research/deeplab/input_preprocess.py  \n",
            "  inflating: models-1.13.0/research/deeplab/local_test.sh  \n",
            "  inflating: models-1.13.0/research/deeplab/local_test_mobilenetv2.sh  \n",
            "  inflating: models-1.13.0/research/deeplab/model.py  \n",
            "  inflating: models-1.13.0/research/deeplab/model_test.py  \n",
            "  inflating: models-1.13.0/research/deeplab/train.py  \n",
            "   creating: models-1.13.0/research/deeplab/utils/\n",
            " extracting: models-1.13.0/research/deeplab/utils/__init__.py  \n",
            "  inflating: models-1.13.0/research/deeplab/utils/get_dataset_colormap.py  \n",
            "  inflating: models-1.13.0/research/deeplab/utils/get_dataset_colormap_test.py  \n",
            "  inflating: models-1.13.0/research/deeplab/utils/input_generator.py  \n",
            "  inflating: models-1.13.0/research/deeplab/utils/save_annotation.py  \n",
            "  inflating: models-1.13.0/research/deeplab/utils/train_utils.py  \n",
            "  inflating: models-1.13.0/research/deeplab/vis.py  \n",
            "   creating: models-1.13.0/research/delf/\n",
            "  inflating: models-1.13.0/research/delf/.gitignore  \n",
            "  inflating: models-1.13.0/research/delf/EXTRACTION_MATCHING.md  \n",
            "  inflating: models-1.13.0/research/delf/INSTALL_INSTRUCTIONS.md  \n",
            "  inflating: models-1.13.0/research/delf/README.md  \n",
            "   creating: models-1.13.0/research/delf/delf/\n",
            "  inflating: models-1.13.0/research/delf/delf/__init__.py  \n",
            "   creating: models-1.13.0/research/delf/delf/protos/\n",
            " extracting: models-1.13.0/research/delf/delf/protos/__init__.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/protos/datum.proto  \n",
            "  inflating: models-1.13.0/research/delf/delf/protos/delf_config.proto  \n",
            "  inflating: models-1.13.0/research/delf/delf/protos/feature.proto  \n",
            "   creating: models-1.13.0/research/delf/delf/python/\n",
            " extracting: models-1.13.0/research/delf/delf/python/__init__.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/datum_io.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/datum_io_test.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/delf_v1.py  \n",
            "   creating: models-1.13.0/research/delf/delf/python/examples/\n",
            "  inflating: models-1.13.0/research/delf/delf/python/examples/delf_config_example.pbtxt  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/examples/extract_features.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/examples/match_images.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/examples/matched_images_example.png  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/feature_io.py  \n",
            "  inflating: models-1.13.0/research/delf/delf/python/feature_io_test.py  \n",
            "  inflating: models-1.13.0/research/delf/setup.py  \n",
            "   creating: models-1.13.0/research/differential_privacy/\n",
            "  inflating: models-1.13.0/research/differential_privacy/README.md  \n",
            "   creating: models-1.13.0/research/domain_adaptation/\n",
            "  inflating: models-1.13.0/research/domain_adaptation/README.md  \n",
            " extracting: models-1.13.0/research/domain_adaptation/WORKSPACE  \n",
            " extracting: models-1.13.0/research/domain_adaptation/__init__.py  \n",
            "   creating: models-1.13.0/research/domain_adaptation/datasets/\n",
            "  inflating: models-1.13.0/research/domain_adaptation/datasets/BUILD  \n",
            " extracting: models-1.13.0/research/domain_adaptation/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/datasets/dataset_factory.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/datasets/download_and_convert_mnist_m.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/datasets/mnist_m.py  \n",
            "   creating: models-1.13.0/research/domain_adaptation/domain_separation/\n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/BUILD  \n",
            " extracting: models-1.13.0/research/domain_adaptation/domain_separation/__init__.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/_grl_ops.so  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/dsn.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/dsn_eval.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/dsn_test.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/dsn_train.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/grl_op_grads.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/grl_op_kernels.cc  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/grl_op_shapes.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/grl_ops.cc  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/grl_ops.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/grl_ops_test.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/losses.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/losses_test.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/models.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/models_test.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/domain_separation/utils.py  \n",
            "   creating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/\n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/BUILD  \n",
            " extracting: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/README.md  \n",
            "   creating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/baselines/\n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/baselines/BUILD  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/baselines/README.md  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/baselines/baseline_eval.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/baselines/baseline_train.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/hparams.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_eval.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_losses.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_model.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_preprocess.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_preprocess_test.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_task_towers.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_train.py  \n",
            "  inflating: models-1.13.0/research/domain_adaptation/pixel_domain_adaptation/pixelda_utils.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/\n",
            "  inflating: models-1.13.0/research/efficient-hrl/README.md  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/agent.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/agents/\n",
            " extracting: models-1.13.0/research/efficient-hrl/agents/__init__.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/agents/circular_buffer.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/agents/ddpg_agent.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/agents/ddpg_networks.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/cond_fn.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/configs/\n",
            "  inflating: models-1.13.0/research/efficient-hrl/configs/base_uvf.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/configs/eval_uvf.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/configs/train_uvf.gin  \n",
            "   creating: models-1.13.0/research/efficient-hrl/context/\n",
            " extracting: models-1.13.0/research/efficient-hrl/context/__init__.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/context/configs/\n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_block.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_block_maze.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_fall_multi.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_fall_multi_img.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_fall_single.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_maze.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_maze_img.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_push_multi.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_push_multi_img.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/ant_push_single.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/default.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/hiro_orig.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/hiro_repr.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/hiro_xy.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/configs/point_maze.gin  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/context.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/context_transition_functions.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/gin_imports.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/gin_utils.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/rewards_functions.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/context/samplers.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/environments/\n",
            " extracting: models-1.13.0/research/efficient-hrl/environments/__init__.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/ant.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/ant_maze_env.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/environments/assets/\n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/assets/ant.xml  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/create_maze_env.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/maze_env.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/maze_env_utils.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/point.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/environments/point_maze_env.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/eval.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/run_env.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/run_eval.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/run_train.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/scripts/\n",
            "  inflating: models-1.13.0/research/efficient-hrl/scripts/local_eval.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/scripts/local_train.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/train.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/train_utils.py  \n",
            "   creating: models-1.13.0/research/efficient-hrl/utils/\n",
            " extracting: models-1.13.0/research/efficient-hrl/utils/__init__.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/utils/eval_utils.py  \n",
            "  inflating: models-1.13.0/research/efficient-hrl/utils/utils.py  \n",
            "   creating: models-1.13.0/research/fivo/\n",
            "  inflating: models-1.13.0/research/fivo/.gitattributes  \n",
            "  inflating: models-1.13.0/research/fivo/.gitignore  \n",
            "  inflating: models-1.13.0/research/fivo/README.md  \n",
            "   creating: models-1.13.0/research/fivo/bin/\n",
            "  inflating: models-1.13.0/research/fivo/bin/download_pianorolls.sh  \n",
            "  inflating: models-1.13.0/research/fivo/bin/run_eval.sh  \n",
            "  inflating: models-1.13.0/research/fivo/bin/run_sample.sh  \n",
            "  inflating: models-1.13.0/research/fivo/bin/run_tests.sh  \n",
            "  inflating: models-1.13.0/research/fivo/bin/run_train.sh  \n",
            "   creating: models-1.13.0/research/fivo/experimental/\n",
            "  inflating: models-1.13.0/research/fivo/experimental/README.md  \n",
            "  inflating: models-1.13.0/research/fivo/experimental/bounds.py  \n",
            "  inflating: models-1.13.0/research/fivo/experimental/data.py  \n",
            "  inflating: models-1.13.0/research/fivo/experimental/models.py  \n",
            "  inflating: models-1.13.0/research/fivo/experimental/run.sh  \n",
            "  inflating: models-1.13.0/research/fivo/experimental/summary_utils.py  \n",
            "  inflating: models-1.13.0/research/fivo/experimental/train.py  \n",
            "   creating: models-1.13.0/research/fivo/fivo/\n",
            " extracting: models-1.13.0/research/fivo/fivo/__init__.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/bounds.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/bounds_test.py  \n",
            "   creating: models-1.13.0/research/fivo/fivo/data/\n",
            " extracting: models-1.13.0/research/fivo/fivo/data/__init__.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/data/calculate_pianoroll_mean.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/data/create_timit_dataset.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/data/datasets.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/data/datasets_test.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/ghmm_runners.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/ghmm_runners_test.py  \n",
            "   creating: models-1.13.0/research/fivo/fivo/models/\n",
            " extracting: models-1.13.0/research/fivo/fivo/models/__init__.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/models/base.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/models/ghmm.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/models/ghmm_test.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/models/srnn.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/models/srnn_test.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/models/vrnn.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/models/vrnn_test.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/nested_utils.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/nested_utils_test.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/runners.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/runners_test.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/smc.py  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/smc_test.py  \n",
            "   creating: models-1.13.0/research/fivo/fivo/test_data/\n",
            "  inflating: models-1.13.0/research/fivo/fivo/test_data/tiny_pianoroll.pkl  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/test_data/tiny_speech_dataset.tfrecord  \n",
            "  inflating: models-1.13.0/research/fivo/fivo/test_utils.py  \n",
            "  inflating: models-1.13.0/research/fivo/run_fivo.py  \n",
            "   creating: models-1.13.0/research/gan/\n",
            "  inflating: models-1.13.0/research/gan/README.md  \n",
            "   creating: models-1.13.0/research/gan/cifar/\n",
            "  inflating: models-1.13.0/research/gan/cifar/data_provider.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/data_provider_test.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/eval.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/eval_test.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/launch_jobs.sh  \n",
            "  inflating: models-1.13.0/research/gan/cifar/networks.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/networks_test.py  \n",
            "   creating: models-1.13.0/research/gan/cifar/testdata/\n",
            " extracting: models-1.13.0/research/gan/cifar/testdata/cifar10_train.tfrecord  \n",
            "  inflating: models-1.13.0/research/gan/cifar/train.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/train_test.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/util.py  \n",
            "  inflating: models-1.13.0/research/gan/cifar/util_test.py  \n",
            "   creating: models-1.13.0/research/gan/cyclegan/\n",
            "  inflating: models-1.13.0/research/gan/cyclegan/data_provider.py  \n",
            "  inflating: models-1.13.0/research/gan/cyclegan/data_provider_test.py  \n",
            "  inflating: models-1.13.0/research/gan/cyclegan/inference_demo.py  \n",
            "  inflating: models-1.13.0/research/gan/cyclegan/inference_demo_test.py  \n",
            "   creating: models-1.13.0/research/gan/cyclegan/testdata/\n",
            "  inflating: models-1.13.0/research/gan/cyclegan/testdata/00500.jpg  \n",
            "  inflating: models-1.13.0/research/gan/cyclegan/train.py  \n",
            "  inflating: models-1.13.0/research/gan/cyclegan/train_test.py  \n",
            "   creating: models-1.13.0/research/gan/g3doc/\n",
            "  inflating: models-1.13.0/research/gan/g3doc/cifar_conditional_gan.png  \n",
            "  inflating: models-1.13.0/research/gan/g3doc/cifar_unconditional_gan.png  \n",
            "  inflating: models-1.13.0/research/gan/g3doc/compression_wf0.png  \n",
            "  inflating: models-1.13.0/research/gan/g3doc/compression_wf10000.png  \n",
            "  inflating: models-1.13.0/research/gan/g3doc/mnist_conditional_gan.png  \n",
            "  inflating: models-1.13.0/research/gan/g3doc/mnist_estimator_unconditional_gan.png  \n",
            "  inflating: models-1.13.0/research/gan/g3doc/mnist_infogan.png  \n",
            "  inflating: models-1.13.0/research/gan/g3doc/mnist_unconditional_gan.png  \n",
            "   creating: models-1.13.0/research/gan/image_compression/\n",
            "  inflating: models-1.13.0/research/gan/image_compression/data_provider.py  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/data_provider_test.py  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/eval.py  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/eval_test.py  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/launch_jobs.sh  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/networks.py  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/networks_test.py  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/summaries.py  \n",
            "   creating: models-1.13.0/research/gan/image_compression/testdata/\n",
            " extracting: models-1.13.0/research/gan/image_compression/testdata/labels.txt  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/testdata/train-00000-of-00128  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/testdata/validation-00000-of-00128  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/train.py  \n",
            "  inflating: models-1.13.0/research/gan/image_compression/train_test.py  \n",
            "   creating: models-1.13.0/research/gan/mnist/\n",
            " extracting: models-1.13.0/research/gan/mnist/__init__.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/conditional_eval.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/conditional_eval_test.py  \n",
            "   creating: models-1.13.0/research/gan/mnist/data/\n",
            "  inflating: models-1.13.0/research/gan/mnist/data/classify_mnist_graph_def.pb  \n",
            "  inflating: models-1.13.0/research/gan/mnist/data/infogan_model.ckpt  \n",
            "  inflating: models-1.13.0/research/gan/mnist/data_provider.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/data_provider_test.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/eval.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/eval_test.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/infogan_eval.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/infogan_eval_test.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/launch_jobs.sh  \n",
            "  inflating: models-1.13.0/research/gan/mnist/networks.py  \n",
            "   creating: models-1.13.0/research/gan/mnist/testdata/\n",
            "  inflating: models-1.13.0/research/gan/mnist/testdata/mnist_test.tfrecord  \n",
            "  inflating: models-1.13.0/research/gan/mnist/train.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/train_test.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/util.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist/util_test.py  \n",
            "   creating: models-1.13.0/research/gan/mnist_estimator/\n",
            "  inflating: models-1.13.0/research/gan/mnist_estimator/launch_jobs.sh  \n",
            "  inflating: models-1.13.0/research/gan/mnist_estimator/train.py  \n",
            "  inflating: models-1.13.0/research/gan/mnist_estimator/train_test.py  \n",
            "   creating: models-1.13.0/research/gan/pix2pix/\n",
            "  inflating: models-1.13.0/research/gan/pix2pix/launch_jobs.sh  \n",
            "  inflating: models-1.13.0/research/gan/pix2pix/networks.py  \n",
            "  inflating: models-1.13.0/research/gan/pix2pix/networks_test.py  \n",
            "  inflating: models-1.13.0/research/gan/pix2pix/train.py  \n",
            "  inflating: models-1.13.0/research/gan/pix2pix/train_test.py  \n",
            "   creating: models-1.13.0/research/gan/progressive_gan/\n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/data_provider.py  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/data_provider_test.py  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/layers.py  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/layers_test.py  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/networks.py  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/networks_test.py  \n",
            "   creating: models-1.13.0/research/gan/progressive_gan/testdata/\n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/testdata/test.jpg  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/train.py  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/train_main.py  \n",
            "  inflating: models-1.13.0/research/gan/progressive_gan/train_test.py  \n",
            "   creating: models-1.13.0/research/gan/stargan/\n",
            "  inflating: models-1.13.0/research/gan/stargan/data_provider.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/data_provider_test.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/layers.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/layers_test.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/network.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/network_test.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/ops.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/ops_test.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/train.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan/train_test.py  \n",
            "   creating: models-1.13.0/research/gan/stargan_estimator/\n",
            "   creating: models-1.13.0/research/gan/stargan_estimator/data/\n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/data/celeba_test_split_images.npy  \n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/data/celeba_test_split_labels.npy  \n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/data_provider.py  \n",
            "   creating: models-1.13.0/research/gan/stargan_estimator/testdata/\n",
            "   creating: models-1.13.0/research/gan/stargan_estimator/testdata/celeba/\n",
            "   creating: models-1.13.0/research/gan/stargan_estimator/testdata/celeba/black/\n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/testdata/celeba/black/202598.jpg  \n",
            "   creating: models-1.13.0/research/gan/stargan_estimator/testdata/celeba/blond/\n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/testdata/celeba/blond/202599.jpg  \n",
            "   creating: models-1.13.0/research/gan/stargan_estimator/testdata/celeba/brown/\n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/testdata/celeba/brown/202587.jpg  \n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/train.py  \n",
            "  inflating: models-1.13.0/research/gan/stargan_estimator/train_test.py  \n",
            "  inflating: models-1.13.0/research/gan/tutorial.ipynb  \n",
            "   creating: models-1.13.0/research/global_objectives/\n",
            "  inflating: models-1.13.0/research/global_objectives/README.md  \n",
            "  inflating: models-1.13.0/research/global_objectives/loss_layers.py  \n",
            "  inflating: models-1.13.0/research/global_objectives/loss_layers_example.py  \n",
            "  inflating: models-1.13.0/research/global_objectives/loss_layers_test.py  \n",
            "  inflating: models-1.13.0/research/global_objectives/test_all.py  \n",
            "  inflating: models-1.13.0/research/global_objectives/util.py  \n",
            "  inflating: models-1.13.0/research/global_objectives/util_test.py  \n",
            "   creating: models-1.13.0/research/im2txt/\n",
            "  inflating: models-1.13.0/research/im2txt/.gitignore  \n",
            "  inflating: models-1.13.0/research/im2txt/README.md  \n",
            " extracting: models-1.13.0/research/im2txt/WORKSPACE  \n",
            "   creating: models-1.13.0/research/im2txt/conda-env/\n",
            "  inflating: models-1.13.0/research/im2txt/conda-env/ubuntu-18-04-environment.yaml  \n",
            "   creating: models-1.13.0/research/im2txt/g3doc/\n",
            " extracting: models-1.13.0/research/im2txt/g3doc/COCO_val2014_000000224477.jpg  \n",
            "  inflating: models-1.13.0/research/im2txt/g3doc/example_captions.jpg  \n",
            "  inflating: models-1.13.0/research/im2txt/g3doc/show_and_tell_architecture.png  \n",
            "   creating: models-1.13.0/research/im2txt/im2txt/\n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/BUILD  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/configuration.py  \n",
            "   creating: models-1.13.0/research/im2txt/im2txt/data/\n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/data/build_mscoco_data.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/data/download_and_preprocess_mscoco.sh  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/evaluate.py  \n",
            "   creating: models-1.13.0/research/im2txt/im2txt/inference_utils/\n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/inference_utils/BUILD  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/inference_utils/caption_generator.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/inference_utils/caption_generator_test.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/inference_utils/inference_wrapper_base.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/inference_utils/vocabulary.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/inference_wrapper.py  \n",
            "   creating: models-1.13.0/research/im2txt/im2txt/ops/\n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/ops/BUILD  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/ops/image_embedding.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/ops/image_embedding_test.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/ops/image_processing.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/ops/inputs.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/run_inference.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/show_and_tell_model.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/show_and_tell_model_test.py  \n",
            "  inflating: models-1.13.0/research/im2txt/im2txt/train.py  \n",
            "   creating: models-1.13.0/research/inception/\n",
            "  inflating: models-1.13.0/research/inception/.gitignore  \n",
            "  inflating: models-1.13.0/research/inception/README.md  \n",
            " extracting: models-1.13.0/research/inception/WORKSPACE  \n",
            "   creating: models-1.13.0/research/inception/g3doc/\n",
            "  inflating: models-1.13.0/research/inception/g3doc/inception_v3_architecture.png  \n",
            "   creating: models-1.13.0/research/inception/inception/\n",
            "  inflating: models-1.13.0/research/inception/inception/BUILD  \n",
            "   creating: models-1.13.0/research/inception/inception/data/\n",
            "  inflating: models-1.13.0/research/inception/inception/data/build_image_data.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/build_imagenet_data.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/download_and_preprocess_flowers.sh  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/download_and_preprocess_flowers_mac.sh  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/download_and_preprocess_imagenet.sh  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/download_imagenet.sh  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/imagenet_2012_validation_synset_labels.txt  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/imagenet_lsvrc_2015_synsets.txt  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/imagenet_metadata.txt  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/preprocess_imagenet_validation_data.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/data/process_bounding_boxes.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/dataset.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/flowers_data.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/flowers_eval.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/flowers_train.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/image_processing.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/imagenet_data.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/imagenet_distributed_train.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/imagenet_eval.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/imagenet_train.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/inception_distributed_train.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/inception_eval.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/inception_model.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/inception_train.py  \n",
            "   creating: models-1.13.0/research/inception/inception/slim/\n",
            "  inflating: models-1.13.0/research/inception/inception/slim/BUILD  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/README.md  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/collections_test.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/inception_model.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/inception_test.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/losses.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/losses_test.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/ops.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/ops_test.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/scopes.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/scopes_test.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/slim.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/variables.py  \n",
            "  inflating: models-1.13.0/research/inception/inception/slim/variables_test.py  \n",
            "   creating: models-1.13.0/research/keypointnet/\n",
            "  inflating: models-1.13.0/research/keypointnet/CONTRIBUTING.md  \n",
            "  inflating: models-1.13.0/research/keypointnet/LICENSE  \n",
            "  inflating: models-1.13.0/research/keypointnet/README.md  \n",
            "  inflating: models-1.13.0/research/keypointnet/main.py  \n",
            "   creating: models-1.13.0/research/keypointnet/tools/\n",
            "  inflating: models-1.13.0/research/keypointnet/tools/gen_tfrecords.py  \n",
            "  inflating: models-1.13.0/research/keypointnet/tools/render.py  \n",
            "  inflating: models-1.13.0/research/keypointnet/utils.py  \n",
            "   creating: models-1.13.0/research/learned_optimizer/\n",
            " extracting: models-1.13.0/research/learned_optimizer/.gitignore  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/BUILD  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/README.md  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/metaopt.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/metarun.py  \n",
            "   creating: models-1.13.0/research/learned_optimizer/optimizer/\n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/BUILD  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/coordinatewise_rnn.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/global_learning_rate.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/hierarchical_rnn.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/learning_rate_schedule.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/rnn_cells.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/trainable_adam.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/trainable_optimizer.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/optimizer/utils.py  \n",
            "   creating: models-1.13.0/research/learned_optimizer/problems/\n",
            "  inflating: models-1.13.0/research/learned_optimizer/problems/BUILD  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/problems/datasets.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/problems/model_adapter.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/problems/problem_generator.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/problems/problem_sets.py  \n",
            "  inflating: models-1.13.0/research/learned_optimizer/problems/problem_spec.py  \n",
            "   creating: models-1.13.0/research/learning_to_remember_rare_events/\n",
            "  inflating: models-1.13.0/research/learning_to_remember_rare_events/README.md  \n",
            "  inflating: models-1.13.0/research/learning_to_remember_rare_events/data_utils.py  \n",
            "  inflating: models-1.13.0/research/learning_to_remember_rare_events/memory.py  \n",
            "  inflating: models-1.13.0/research/learning_to_remember_rare_events/model.py  \n",
            "  inflating: models-1.13.0/research/learning_to_remember_rare_events/train.py  \n",
            "   creating: models-1.13.0/research/learning_unsupervised_learning/\n",
            " extracting: models-1.13.0/research/learning_unsupervised_learning/.gitignore  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/README.md  \n",
            " extracting: models-1.13.0/research/learning_unsupervised_learning/__init__.py  \n",
            "   creating: models-1.13.0/research/learning_unsupervised_learning/architectures/\n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/architectures/__init__.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/architectures/common.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/architectures/more_local_weight_update.py  \n",
            "   creating: models-1.13.0/research/learning_unsupervised_learning/datasets/\n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/datasets/common.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/datasets/mnist.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/evaluation.py  \n",
            "   creating: models-1.13.0/research/learning_unsupervised_learning/meta_objective/\n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/meta_objective/__init__.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/meta_objective/linear_regression.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/meta_objective/sklearn.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/meta_objective/utils.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/optimizers.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/run_eval.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/summary_utils.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/utils.py  \n",
            "  inflating: models-1.13.0/research/learning_unsupervised_learning/variable_replace.py  \n",
            "   creating: models-1.13.0/research/lexnet_nc/\n",
            "  inflating: models-1.13.0/research/lexnet_nc/README.md  \n",
            "  inflating: models-1.13.0/research/lexnet_nc/get_indicative_paths.py  \n",
            "  inflating: models-1.13.0/research/lexnet_nc/learn_classifier.py  \n",
            "  inflating: models-1.13.0/research/lexnet_nc/learn_path_embeddings.py  \n",
            "  inflating: models-1.13.0/research/lexnet_nc/lexnet_common.py  \n",
            "  inflating: models-1.13.0/research/lexnet_nc/lexnet_model.py  \n",
            "  inflating: models-1.13.0/research/lexnet_nc/path_model.py  \n",
            "   creating: models-1.13.0/research/lfads/\n",
            "  inflating: models-1.13.0/research/lfads/README.md  \n",
            "  inflating: models-1.13.0/research/lfads/distributions.py  \n",
            "  inflating: models-1.13.0/research/lfads/lfads.py  \n",
            "  inflating: models-1.13.0/research/lfads/plot_lfads.py  \n",
            "  inflating: models-1.13.0/research/lfads/run_lfads.py  \n",
            "   creating: models-1.13.0/research/lfads/synth_data/\n",
            "  inflating: models-1.13.0/research/lfads/synth_data/generate_chaotic_rnn_data.py  \n",
            "  inflating: models-1.13.0/research/lfads/synth_data/generate_itb_data.py  \n",
            "  inflating: models-1.13.0/research/lfads/synth_data/generate_labeled_rnn_data.py  \n",
            "  inflating: models-1.13.0/research/lfads/synth_data/run_generate_synth_data.sh  \n",
            "  inflating: models-1.13.0/research/lfads/synth_data/synthetic_data_utils.py  \n",
            "   creating: models-1.13.0/research/lfads/synth_data/trained_itb/\n",
            "  inflating: models-1.13.0/research/lfads/synth_data/trained_itb/model-65000.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/research/lfads/synth_data/trained_itb/model-65000.index  \n",
            "  inflating: models-1.13.0/research/lfads/synth_data/trained_itb/model-65000.meta  \n",
            "  inflating: models-1.13.0/research/lfads/utils.py  \n",
            "   creating: models-1.13.0/research/lm_1b/\n",
            "  inflating: models-1.13.0/research/lm_1b/BUILD  \n",
            "  inflating: models-1.13.0/research/lm_1b/README.md  \n",
            "  inflating: models-1.13.0/research/lm_1b/data_utils.py  \n",
            "  inflating: models-1.13.0/research/lm_1b/lm_1b_eval.py  \n",
            "   creating: models-1.13.0/research/lm_commonsense/\n",
            "  inflating: models-1.13.0/research/lm_commonsense/README.md  \n",
            "  inflating: models-1.13.0/research/lm_commonsense/eval.py  \n",
            "  inflating: models-1.13.0/research/lm_commonsense/method.jpg  \n",
            "  inflating: models-1.13.0/research/lm_commonsense/utils.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/\n",
            "  inflating: models-1.13.0/research/lstm_object_detection/README  \n",
            " extracting: models-1.13.0/research/lstm_object_detection/__init__.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/configs/\n",
            "  inflating: models-1.13.0/research/lstm_object_detection/configs/lstm_ssd_mobilenet_v1_imagenet.config  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/eval.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/evaluator.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/inputs/\n",
            "  inflating: models-1.13.0/research/lstm_object_detection/inputs/seq_dataset_builder.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/inputs/seq_dataset_builder_test.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/inputs/tf_sequence_example_decoder.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/inputs/tf_sequence_example_decoder_test.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/lstm/\n",
            " extracting: models-1.13.0/research/lstm_object_detection/lstm/__init__.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/lstm/lstm_cells.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/lstm/lstm_cells_test.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/lstm/lstm_meta_arch.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/lstm/rnn_decoder.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/metrics/\n",
            " extracting: models-1.13.0/research/lstm_object_detection/metrics/__init__.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/metrics/coco_evaluation_all_frames.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/metrics/coco_evaluation_all_frames_test.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/model_builder.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/model_builder_test.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/models/\n",
            " extracting: models-1.13.0/research/lstm_object_detection/models/__init__.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/models/lstm_ssd_mobilenet_v1_feature_extractor_test.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/protos/\n",
            " extracting: models-1.13.0/research/lstm_object_detection/protos/__init__.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/protos/input_reader_google.proto  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/protos/pipeline.proto  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/train.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/trainer.py  \n",
            "   creating: models-1.13.0/research/lstm_object_detection/utils/\n",
            "  inflating: models-1.13.0/research/lstm_object_detection/utils/config_util.py  \n",
            "  inflating: models-1.13.0/research/lstm_object_detection/utils/config_util_test.py  \n",
            "   creating: models-1.13.0/research/marco/\n",
            "  inflating: models-1.13.0/research/marco/Automated_Marco.py  \n",
            "  inflating: models-1.13.0/research/marco/README.md  \n",
            "  inflating: models-1.13.0/research/marco/jpeg2json.py  \n",
            "  inflating: models-1.13.0/research/marco/request.json  \n",
            "   creating: models-1.13.0/research/maskgan/\n",
            "  inflating: models-1.13.0/research/maskgan/README.md  \n",
            "   creating: models-1.13.0/research/maskgan/data/\n",
            " extracting: models-1.13.0/research/maskgan/data/__init__.py  \n",
            "  inflating: models-1.13.0/research/maskgan/data/imdb_loader.py  \n",
            "  inflating: models-1.13.0/research/maskgan/data/ptb_loader.py  \n",
            "  inflating: models-1.13.0/research/maskgan/generate_samples.py  \n",
            "   creating: models-1.13.0/research/maskgan/losses/\n",
            " extracting: models-1.13.0/research/maskgan/losses/__init__.py  \n",
            "  inflating: models-1.13.0/research/maskgan/losses/losses.py  \n",
            "   creating: models-1.13.0/research/maskgan/model_utils/\n",
            " extracting: models-1.13.0/research/maskgan/model_utils/__init__.py  \n",
            "  inflating: models-1.13.0/research/maskgan/model_utils/helper.py  \n",
            "  inflating: models-1.13.0/research/maskgan/model_utils/model_construction.py  \n",
            "  inflating: models-1.13.0/research/maskgan/model_utils/model_losses.py  \n",
            "  inflating: models-1.13.0/research/maskgan/model_utils/model_optimization.py  \n",
            "  inflating: models-1.13.0/research/maskgan/model_utils/model_utils.py  \n",
            "  inflating: models-1.13.0/research/maskgan/model_utils/n_gram.py  \n",
            "  inflating: models-1.13.0/research/maskgan/model_utils/variable_mapping.py  \n",
            "   creating: models-1.13.0/research/maskgan/models/\n",
            " extracting: models-1.13.0/research/maskgan/models/__init__.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/attention_utils.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/bidirectional.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/bidirectional_vd.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/bidirectional_zaremba.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/cnn.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/critic_vd.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/evaluation_utils.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/feedforward.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/rnn.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/rnn_nas.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/rnn_vd.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/rnn_zaremba.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/rollout.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/seq2seq.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/seq2seq_nas.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/seq2seq_vd.py  \n",
            "  inflating: models-1.13.0/research/maskgan/models/seq2seq_zaremba.py  \n",
            "   creating: models-1.13.0/research/maskgan/nas_utils/\n",
            " extracting: models-1.13.0/research/maskgan/nas_utils/__init__.py  \n",
            "  inflating: models-1.13.0/research/maskgan/nas_utils/configs.py  \n",
            "  inflating: models-1.13.0/research/maskgan/nas_utils/custom_cell.py  \n",
            "  inflating: models-1.13.0/research/maskgan/nas_utils/variational_dropout.py  \n",
            "  inflating: models-1.13.0/research/maskgan/pretrain_mask_gan.py  \n",
            "   creating: models-1.13.0/research/maskgan/regularization/\n",
            " extracting: models-1.13.0/research/maskgan/regularization/__init__.py  \n",
            "  inflating: models-1.13.0/research/maskgan/regularization/variational_dropout.py  \n",
            "  inflating: models-1.13.0/research/maskgan/regularization/zoneout.py  \n",
            "  inflating: models-1.13.0/research/maskgan/sample_shuffler.py  \n",
            "  inflating: models-1.13.0/research/maskgan/train_mask_gan.py  \n",
            "   creating: models-1.13.0/research/minigo/\n",
            "  inflating: models-1.13.0/research/minigo/README.md  \n",
            " extracting: models-1.13.0/research/minigo/__init__.py  \n",
            "  inflating: models-1.13.0/research/minigo/coords.py  \n",
            "  inflating: models-1.13.0/research/minigo/coords_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/dualnet.py  \n",
            "  inflating: models-1.13.0/research/minigo/dualnet_model.py  \n",
            "  inflating: models-1.13.0/research/minigo/dualnet_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/evaluation.py  \n",
            "  inflating: models-1.13.0/research/minigo/example_game.sgf  \n",
            "  inflating: models-1.13.0/research/minigo/features.py  \n",
            "  inflating: models-1.13.0/research/minigo/features_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/go.py  \n",
            "  inflating: models-1.13.0/research/minigo/go_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/gtp_extensions.py  \n",
            "  inflating: models-1.13.0/research/minigo/gtp_wrapper.py  \n",
            "  inflating: models-1.13.0/research/minigo/mcts.py  \n",
            "  inflating: models-1.13.0/research/minigo/mcts_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/minigo.py  \n",
            "  inflating: models-1.13.0/research/minigo/model_params.py  \n",
            "  inflating: models-1.13.0/research/minigo/preprocessing.py  \n",
            "  inflating: models-1.13.0/research/minigo/preprocessing_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/selfplay_mcts.py  \n",
            "  inflating: models-1.13.0/research/minigo/sgf_wrapper.py  \n",
            "  inflating: models-1.13.0/research/minigo/sgf_wrapper_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/strategies.py  \n",
            "  inflating: models-1.13.0/research/minigo/strategies_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/symmetries.py  \n",
            "  inflating: models-1.13.0/research/minigo/symmetries_test.py  \n",
            "  inflating: models-1.13.0/research/minigo/utils.py  \n",
            "  inflating: models-1.13.0/research/minigo/utils_test.py  \n",
            "   creating: models-1.13.0/research/morph_net/\n",
            "  inflating: models-1.13.0/research/morph_net/README.md  \n",
            " extracting: models-1.13.0/research/morph_net/__init__.py  \n",
            "   creating: models-1.13.0/research/morph_net/framework/\n",
            "  inflating: models-1.13.0/research/morph_net/framework/README.md  \n",
            " extracting: models-1.13.0/research/morph_net/framework/__init__.py  \n",
            "  inflating: models-1.13.0/research/morph_net/framework/concat_and_slice_regularizers.py  \n",
            "  inflating: models-1.13.0/research/morph_net/framework/concat_and_slice_regularizers_test.py  \n",
            "  inflating: models-1.13.0/research/morph_net/framework/generic_regularizers.py  \n",
            "  inflating: models-1.13.0/research/morph_net/framework/grouping_regularizers.py  \n",
            "  inflating: models-1.13.0/research/morph_net/framework/grouping_regularizers_test.py  \n",
            "  inflating: models-1.13.0/research/morph_net/framework/op_regularizer_manager.py  \n",
            "  inflating: models-1.13.0/research/morph_net/framework/op_regularizer_manager_test.py  \n",
            "   creating: models-1.13.0/research/morph_net/g3doc/\n",
            "  inflating: models-1.13.0/research/morph_net/g3doc/grouping.png  \n",
            "  inflating: models-1.13.0/research/morph_net/g3doc/histogram.png  \n",
            "  inflating: models-1.13.0/research/morph_net/g3doc/tensorboard.png  \n",
            "   creating: models-1.13.0/research/morph_net/network_regularizers/\n",
            " extracting: models-1.13.0/research/morph_net/network_regularizers/__init__.py  \n",
            "  inflating: models-1.13.0/research/morph_net/network_regularizers/bilinear_cost_utils.py  \n",
            "  inflating: models-1.13.0/research/morph_net/network_regularizers/bilinear_cost_utils_test.py  \n",
            "  inflating: models-1.13.0/research/morph_net/network_regularizers/flop_regularizer.py  \n",
            "  inflating: models-1.13.0/research/morph_net/network_regularizers/flop_regularizer_test.py  \n",
            "  inflating: models-1.13.0/research/morph_net/network_regularizers/model_size_regularizer.py  \n",
            "   creating: models-1.13.0/research/morph_net/op_regularizers/\n",
            " extracting: models-1.13.0/research/morph_net/op_regularizers/__init__.py  \n",
            "  inflating: models-1.13.0/research/morph_net/op_regularizers/conv_group_lasso_regularizer.py  \n",
            "  inflating: models-1.13.0/research/morph_net/op_regularizers/conv_group_lasso_regularizer_test.py  \n",
            "  inflating: models-1.13.0/research/morph_net/op_regularizers/gamma_l1_regularizer.py  \n",
            "  inflating: models-1.13.0/research/morph_net/op_regularizers/gamma_mapper.py  \n",
            "  inflating: models-1.13.0/research/morph_net/op_regularizers/gamma_mapper_test.py  \n",
            "   creating: models-1.13.0/research/morph_net/testing/\n",
            " extracting: models-1.13.0/research/morph_net/testing/__init__.py  \n",
            "  inflating: models-1.13.0/research/morph_net/testing/op_regularizer_stub.py  \n",
            "   creating: models-1.13.0/research/namignizer/\n",
            "  inflating: models-1.13.0/research/namignizer/.gitignore  \n",
            "  inflating: models-1.13.0/research/namignizer/README.md  \n",
            "  inflating: models-1.13.0/research/namignizer/data_utils.py  \n",
            "  inflating: models-1.13.0/research/namignizer/model.py  \n",
            "  inflating: models-1.13.0/research/namignizer/names.py  \n",
            "   creating: models-1.13.0/research/neural_gpu/\n",
            "  inflating: models-1.13.0/research/neural_gpu/README.md  \n",
            "  inflating: models-1.13.0/research/neural_gpu/data_utils.py  \n",
            "  inflating: models-1.13.0/research/neural_gpu/neural_gpu.py  \n",
            "  inflating: models-1.13.0/research/neural_gpu/neural_gpu_trainer.py  \n",
            "  inflating: models-1.13.0/research/neural_gpu/program_utils.py  \n",
            "  inflating: models-1.13.0/research/neural_gpu/wmt_utils.py  \n",
            "   creating: models-1.13.0/research/neural_programmer/\n",
            "  inflating: models-1.13.0/research/neural_programmer/README.md  \n",
            "  inflating: models-1.13.0/research/neural_programmer/data_utils.py  \n",
            "  inflating: models-1.13.0/research/neural_programmer/model.py  \n",
            "  inflating: models-1.13.0/research/neural_programmer/neural_programmer.py  \n",
            "  inflating: models-1.13.0/research/neural_programmer/nn_utils.py  \n",
            "  inflating: models-1.13.0/research/neural_programmer/parameters.py  \n",
            "  inflating: models-1.13.0/research/neural_programmer/wiki_data.py  \n",
            "   creating: models-1.13.0/research/next_frame_prediction/\n",
            "  inflating: models-1.13.0/research/next_frame_prediction/README.md  \n",
            "   creating: models-1.13.0/research/next_frame_prediction/cross_conv/\n",
            "  inflating: models-1.13.0/research/next_frame_prediction/cross_conv/BUILD  \n",
            "  inflating: models-1.13.0/research/next_frame_prediction/cross_conv/eval.py  \n",
            "  inflating: models-1.13.0/research/next_frame_prediction/cross_conv/example_gen.py  \n",
            "  inflating: models-1.13.0/research/next_frame_prediction/cross_conv/model.py  \n",
            "  inflating: models-1.13.0/research/next_frame_prediction/cross_conv/reader.py  \n",
            "  inflating: models-1.13.0/research/next_frame_prediction/cross_conv/sprites_gen.py  \n",
            "  inflating: models-1.13.0/research/next_frame_prediction/cross_conv/train.py  \n",
            "   creating: models-1.13.0/research/next_frame_prediction/g3doc/\n",
            "  inflating: models-1.13.0/research/next_frame_prediction/g3doc/cross_conv.png  \n",
            " extracting: models-1.13.0/research/next_frame_prediction/g3doc/cross_conv2.png  \n",
            "  inflating: models-1.13.0/research/next_frame_prediction/g3doc/cross_conv3.png  \n",
            "   creating: models-1.13.0/research/nst_blogpost/\n",
            "  inflating: models-1.13.0/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb  \n",
            "  inflating: models-1.13.0/research/nst_blogpost/Green_Sea_Turtle_grazing_seagrass.jpg  \n",
            "  inflating: models-1.13.0/research/nst_blogpost/The_Great_Wave_off_Kanagawa.jpg  \n",
            " extracting: models-1.13.0/research/nst_blogpost/wave_turtle.png  \n",
            "   creating: models-1.13.0/research/object_detection/\n",
            "  inflating: models-1.13.0/research/object_detection/CONTRIBUTING.md  \n",
            "  inflating: models-1.13.0/research/object_detection/README.md  \n",
            " extracting: models-1.13.0/research/object_detection/__init__.py  \n",
            "   creating: models-1.13.0/research/object_detection/anchor_generators/\n",
            " extracting: models-1.13.0/research/object_detection/anchor_generators/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/anchor_generators/grid_anchor_generator.py  \n",
            "  inflating: models-1.13.0/research/object_detection/anchor_generators/grid_anchor_generator_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/anchor_generators/multiple_grid_anchor_generator.py  \n",
            "  inflating: models-1.13.0/research/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py  \n",
            "  inflating: models-1.13.0/research/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/box_coders/\n",
            " extracting: models-1.13.0/research/object_detection/box_coders/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/faster_rcnn_box_coder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/faster_rcnn_box_coder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/keypoint_box_coder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/keypoint_box_coder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/mean_stddev_box_coder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/mean_stddev_box_coder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/square_box_coder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/box_coders/square_box_coder_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/builders/\n",
            " extracting: models-1.13.0/research/object_detection/builders/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/anchor_generator_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/anchor_generator_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/box_coder_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/box_coder_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/box_predictor_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/box_predictor_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/dataset_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/dataset_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/graph_rewriter_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/graph_rewriter_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/hyperparams_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/hyperparams_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/image_resizer_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/image_resizer_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/input_reader_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/input_reader_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/losses_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/losses_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/matcher_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/matcher_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/model_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/model_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/optimizer_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/optimizer_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/post_processing_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/post_processing_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/preprocessor_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/preprocessor_builder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/region_similarity_calculator_builder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/builders/region_similarity_calculator_builder_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/core/\n",
            " extracting: models-1.13.0/research/object_detection/core/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/anchor_generator.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/balanced_positive_negative_sampler.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/balanced_positive_negative_sampler_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/batcher.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/batcher_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/box_coder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/box_coder_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/box_list.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/box_list_ops.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/box_list_ops_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/box_list_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/box_predictor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/data_decoder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/data_parser.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/freezable_batch_norm.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/freezable_batch_norm_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/keypoint_ops.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/keypoint_ops_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/losses.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/losses_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/matcher.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/matcher_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/minibatch_sampler.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/minibatch_sampler_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/model.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/post_processing.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/post_processing_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/prefetcher.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/prefetcher_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/preprocessor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/preprocessor_cache.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/preprocessor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/region_similarity_calculator.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/region_similarity_calculator_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/standard_fields.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/target_assigner.py  \n",
            "  inflating: models-1.13.0/research/object_detection/core/target_assigner_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/data/\n",
            "  inflating: models-1.13.0/research/object_detection/data/ava_label_map_v2.1.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/face_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/fgvc_2854_classes_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/kitti_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/mscoco_complete_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/mscoco_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/mscoco_minival_ids.txt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/oid_bbox_trainable_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/pascal_label_map.pbtxt  \n",
            "  inflating: models-1.13.0/research/object_detection/data/pet_label_map.pbtxt  \n",
            "   creating: models-1.13.0/research/object_detection/data_decoders/\n",
            " extracting: models-1.13.0/research/object_detection/data_decoders/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/data_decoders/tf_example_decoder.py  \n",
            "  inflating: models-1.13.0/research/object_detection/data_decoders/tf_example_decoder_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/dataset_tools/\n",
            " extracting: models-1.13.0/research/object_detection/dataset_tools/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_coco_tf_record.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_coco_tf_record_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_kitti_tf_record.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_kitti_tf_record_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_oid_tf_record.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_pascal_tf_record.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_pascal_tf_record_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_pet_tf_record.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/create_pycocotools_package.sh  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/download_and_preprocess_mscoco.sh  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/oid_tfrecord_creation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/oid_tfrecord_creation_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/tf_record_creation_util.py  \n",
            "  inflating: models-1.13.0/research/object_detection/dataset_tools/tf_record_creation_util_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/dockerfiles/\n",
            "   creating: models-1.13.0/research/object_detection/dockerfiles/android/\n",
            "  inflating: models-1.13.0/research/object_detection/dockerfiles/android/Dockerfile  \n",
            "  inflating: models-1.13.0/research/object_detection/dockerfiles/android/README.md  \n",
            "  inflating: models-1.13.0/research/object_detection/eval_util.py  \n",
            "  inflating: models-1.13.0/research/object_detection/eval_util_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/export_inference_graph.py  \n",
            "  inflating: models-1.13.0/research/object_detection/export_tflite_ssd_graph.py  \n",
            "  inflating: models-1.13.0/research/object_detection/export_tflite_ssd_graph_lib.py  \n",
            "  inflating: models-1.13.0/research/object_detection/export_tflite_ssd_graph_lib_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/exporter.py  \n",
            "  inflating: models-1.13.0/research/object_detection/exporter_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/g3doc/\n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/challenge_evaluation.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/configuring_jobs.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/defining_your_own_model.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/detection_model_zoo.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/evaluation_protocols.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/exporting_models.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/faq.md  \n",
            "   creating: models-1.13.0/research/object_detection/g3doc/img/\n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/dataset_explorer.png  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/dogs_detections_output.jpg  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/example_cat.jpg  \n",
            " extracting: models-1.13.0/research/object_detection/g3doc/img/groupof_case_eval.png  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/kites_detections_output.jpg  \n",
            " extracting: models-1.13.0/research/object_detection/g3doc/img/kites_with_segment_overlay.png  \n",
            " extracting: models-1.13.0/research/object_detection/g3doc/img/nongroupof_case_eval.png  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg  \n",
            " extracting: models-1.13.0/research/object_detection/g3doc/img/oxford_pet.png  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/tensorboard.png  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/tensorboard2.png  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/img/tf-od-api-logo.png  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/installation.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/instance_segmentation.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/oid_inference_and_evaluation.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/preparing_inputs.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/running_locally.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/running_notebook.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/running_on_cloud.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/running_pets.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/tpu_compatibility.md  \n",
            "  inflating: models-1.13.0/research/object_detection/g3doc/using_your_own_dataset.md  \n",
            "   creating: models-1.13.0/research/object_detection/inference/\n",
            " extracting: models-1.13.0/research/object_detection/inference/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/inference/detection_inference.py  \n",
            "  inflating: models-1.13.0/research/object_detection/inference/detection_inference_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/inference/infer_detections.py  \n",
            "  inflating: models-1.13.0/research/object_detection/inputs.py  \n",
            "  inflating: models-1.13.0/research/object_detection/inputs_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/legacy/\n",
            " extracting: models-1.13.0/research/object_detection/legacy/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/legacy/eval.py  \n",
            "  inflating: models-1.13.0/research/object_detection/legacy/evaluator.py  \n",
            "  inflating: models-1.13.0/research/object_detection/legacy/train.py  \n",
            "  inflating: models-1.13.0/research/object_detection/legacy/trainer.py  \n",
            "  inflating: models-1.13.0/research/object_detection/legacy/trainer_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/matchers/\n",
            " extracting: models-1.13.0/research/object_detection/matchers/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/matchers/argmax_matcher.py  \n",
            "  inflating: models-1.13.0/research/object_detection/matchers/argmax_matcher_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/matchers/bipartite_matcher.py  \n",
            "  inflating: models-1.13.0/research/object_detection/matchers/bipartite_matcher_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/meta_architectures/\n",
            " extracting: models-1.13.0/research/object_detection/meta_architectures/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/rfcn_meta_arch.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/rfcn_meta_arch_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/ssd_meta_arch.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/ssd_meta_arch_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/meta_architectures/ssd_meta_arch_test_lib.py  \n",
            "   creating: models-1.13.0/research/object_detection/metrics/\n",
            " extracting: models-1.13.0/research/object_detection/metrics/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/coco_evaluation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/coco_evaluation_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/coco_tools.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/coco_tools_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/io_utils.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/offline_eval_map_corloc.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/offline_eval_map_corloc_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/oid_od_challenge_evaluation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/oid_od_challenge_evaluation_utils.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/oid_od_challenge_evaluation_utils_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/oid_vrd_challenge_evaluation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/tf_example_parser.py  \n",
            "  inflating: models-1.13.0/research/object_detection/metrics/tf_example_parser_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/model_hparams.py  \n",
            "  inflating: models-1.13.0/research/object_detection/model_lib.py  \n",
            "  inflating: models-1.13.0/research/object_detection/model_lib_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/model_main.py  \n",
            "  inflating: models-1.13.0/research/object_detection/model_tpu_main.py  \n",
            "   creating: models-1.13.0/research/object_detection/models/\n",
            " extracting: models-1.13.0/research/object_detection/models/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_nas_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_nas_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_pnas_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/feature_map_generators.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/feature_map_generators_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/models/keras_applications/\n",
            " extracting: models-1.13.0/research/object_detection/models/keras_applications/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/keras_applications/mobilenet_v2.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/keras_applications/mobilenet_v2_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_inception_v2_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_inception_v2_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_inception_v3_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_inception_v3_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v1_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v2_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_pnasnet_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_pnasnet_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py  \n",
            "  inflating: models-1.13.0/research/object_detection/object_detection_tutorial.ipynb  \n",
            "   creating: models-1.13.0/research/object_detection/predictors/\n",
            " extracting: models-1.13.0/research/object_detection/predictors/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/convolutional_box_predictor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/convolutional_box_predictor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/convolutional_keras_box_predictor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/convolutional_keras_box_predictor_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/predictors/heads/\n",
            " extracting: models-1.13.0/research/object_detection/predictors/heads/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/box_head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/box_head_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/class_head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/class_head_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keras_box_head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keras_box_head_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keras_class_head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keras_class_head_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keras_mask_head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keras_mask_head_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keypoint_head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/keypoint_head_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/mask_head.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/heads/mask_head_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/mask_rcnn_box_predictor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/mask_rcnn_box_predictor_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/rfcn_box_predictor.py  \n",
            "  inflating: models-1.13.0/research/object_detection/predictors/rfcn_box_predictor_test.py  \n",
            "   creating: models-1.13.0/research/object_detection/protos/\n",
            " extracting: models-1.13.0/research/object_detection/protos/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/anchor_generator.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/argmax_matcher.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/bipartite_matcher.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/box_coder.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/box_predictor.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/eval.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/faster_rcnn.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/faster_rcnn_box_coder.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/graph_rewriter.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/grid_anchor_generator.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/hyperparams.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/image_resizer.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/input_reader.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/keypoint_box_coder.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/losses.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/matcher.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/mean_stddev_box_coder.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/model.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/multiscale_anchor_generator.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/optimizer.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/pipeline.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/post_processing.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/preprocessor.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/region_similarity_calculator.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/square_box_coder.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/ssd.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/ssd_anchor_generator.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/string_int_label_map.proto  \n",
            "  inflating: models-1.13.0/research/object_detection/protos/train.proto  \n",
            "   creating: models-1.13.0/research/object_detection/samples/\n",
            "   creating: models-1.13.0/research/object_detection/samples/cloud/\n",
            "  inflating: models-1.13.0/research/object_detection/samples/cloud/cloud.yml  \n",
            "   creating: models-1.13.0/research/object_detection/samples/configs/\n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_nas_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet101_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet101_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet152_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet152_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet50_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/faster_rcnn_resnet50_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/mask_rcnn_resnet101_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/rfcn_resnet101_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/rfcn_resnet101_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_inception_v2_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_inception_v2_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_inception_v3_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_pets.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config  \n",
            "  inflating: models-1.13.0/research/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config  \n",
            "   creating: models-1.13.0/research/object_detection/test_ckpt/\n",
            "  inflating: models-1.13.0/research/object_detection/test_ckpt/ssd_inception_v2.pb  \n",
            "   creating: models-1.13.0/research/object_detection/test_data/\n",
            "  inflating: models-1.13.0/research/object_detection/test_data/pets_examples.record  \n",
            "   creating: models-1.13.0/research/object_detection/test_images/\n",
            " extracting: models-1.13.0/research/object_detection/test_images/image1.jpg  \n",
            "  inflating: models-1.13.0/research/object_detection/test_images/image2.jpg  \n",
            "  inflating: models-1.13.0/research/object_detection/test_images/image_info.txt  \n",
            "   creating: models-1.13.0/research/object_detection/utils/\n",
            " extracting: models-1.13.0/research/object_detection/utils/__init__.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/category_util.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/category_util_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/config_util.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/config_util_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/context_manager.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/context_manager_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/dataset_util.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/dataset_util_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/json_utils.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/json_utils_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/label_map_util.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/label_map_util_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/learning_schedules.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/learning_schedules_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/metrics.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/metrics_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_list.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_list_ops.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_list_ops_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_list_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_mask_list.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_mask_list_ops.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_mask_list_ops_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_mask_list_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_ops.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_box_ops_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_mask_ops.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/np_mask_ops_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/object_detection_evaluation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/object_detection_evaluation_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/ops.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/ops_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/per_image_evaluation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/per_image_evaluation_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/per_image_vrd_evaluation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/per_image_vrd_evaluation_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/shape_utils.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/shape_utils_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/static_shape.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/static_shape_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/test_case.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/test_utils.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/test_utils_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/variables_helper.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/variables_helper_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/visualization_utils.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/visualization_utils_test.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/vrd_evaluation.py  \n",
            "  inflating: models-1.13.0/research/object_detection/utils/vrd_evaluation_test.py  \n",
            "   creating: models-1.13.0/research/pcl_rl/\n",
            "  inflating: models-1.13.0/research/pcl_rl/README.md  \n",
            "  inflating: models-1.13.0/research/pcl_rl/baseline.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/controller.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/env_spec.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/expert_paths.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/full_episode_objective.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/gym_wrapper.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/model.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/objective.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/optimizers.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/policy.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/replay_buffer.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/trainer.py  \n",
            "  inflating: models-1.13.0/research/pcl_rl/trust_region.py  \n",
            "   creating: models-1.13.0/research/ptn/\n",
            "  inflating: models-1.13.0/research/ptn/.gitignore  \n",
            "  inflating: models-1.13.0/research/ptn/BUILD  \n",
            "  inflating: models-1.13.0/research/ptn/README.md  \n",
            " extracting: models-1.13.0/research/ptn/WORKSPACE  \n",
            "  inflating: models-1.13.0/research/ptn/eval_ptn.py  \n",
            "  inflating: models-1.13.0/research/ptn/eval_rotator.py  \n",
            "  inflating: models-1.13.0/research/ptn/input_generator.py  \n",
            "  inflating: models-1.13.0/research/ptn/losses.py  \n",
            "  inflating: models-1.13.0/research/ptn/metrics.py  \n",
            "  inflating: models-1.13.0/research/ptn/model_ptn.py  \n",
            "  inflating: models-1.13.0/research/ptn/model_rotator.py  \n",
            "  inflating: models-1.13.0/research/ptn/model_voxel_generation.py  \n",
            "   creating: models-1.13.0/research/ptn/nets/\n",
            "  inflating: models-1.13.0/research/ptn/nets/BUILD  \n",
            "  inflating: models-1.13.0/research/ptn/nets/deeprotator_factory.py  \n",
            "  inflating: models-1.13.0/research/ptn/nets/im2vox_factory.py  \n",
            "  inflating: models-1.13.0/research/ptn/nets/perspective_projector.py  \n",
            "  inflating: models-1.13.0/research/ptn/nets/perspective_transform.py  \n",
            "  inflating: models-1.13.0/research/ptn/nets/ptn_encoder.py  \n",
            "  inflating: models-1.13.0/research/ptn/nets/ptn_im_decoder.py  \n",
            "  inflating: models-1.13.0/research/ptn/nets/ptn_rotator.py  \n",
            "  inflating: models-1.13.0/research/ptn/nets/ptn_vox_decoder.py  \n",
            "  inflating: models-1.13.0/research/ptn/pretrain_rotator.py  \n",
            "  inflating: models-1.13.0/research/ptn/train_ptn.py  \n",
            "  inflating: models-1.13.0/research/ptn/utils.py  \n",
            "   creating: models-1.13.0/research/qa_kg/\n",
            "  inflating: models-1.13.0/research/qa_kg/README.md  \n",
            "   creating: models-1.13.0/research/qa_kg/exp_1_hop/\n",
            "  inflating: models-1.13.0/research/qa_kg/exp_1_hop/config.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/exp_1_hop/test.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/exp_1_hop/train_gt_layout.py  \n",
            "   creating: models-1.13.0/research/qa_kg/model_n2nmn/\n",
            " extracting: models-1.13.0/research/qa_kg/model_n2nmn/__init__.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/model_n2nmn/assembler.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/model_n2nmn/model.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/model_n2nmn/modules.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/model_n2nmn/netgen_att.py  \n",
            "   creating: models-1.13.0/research/qa_kg/util/\n",
            " extracting: models-1.13.0/research/qa_kg/util/__init__.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/util/data_reader.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/util/misc.py  \n",
            "  inflating: models-1.13.0/research/qa_kg/util/nn.py  \n",
            "   creating: models-1.13.0/research/real_nvp/\n",
            "  inflating: models-1.13.0/research/real_nvp/README.md  \n",
            " extracting: models-1.13.0/research/real_nvp/__init__.py  \n",
            "  inflating: models-1.13.0/research/real_nvp/celeba_formatting.py  \n",
            "  inflating: models-1.13.0/research/real_nvp/imnet_formatting.py  \n",
            "  inflating: models-1.13.0/research/real_nvp/lsun_formatting.py  \n",
            "  inflating: models-1.13.0/research/real_nvp/real_nvp_multiscale_dataset.py  \n",
            "  inflating: models-1.13.0/research/real_nvp/real_nvp_utils.py  \n",
            "   creating: models-1.13.0/research/rebar/\n",
            "  inflating: models-1.13.0/research/rebar/README.md  \n",
            "  inflating: models-1.13.0/research/rebar/config.py  \n",
            "  inflating: models-1.13.0/research/rebar/datasets.py  \n",
            "  inflating: models-1.13.0/research/rebar/download_data.py  \n",
            "  inflating: models-1.13.0/research/rebar/logger.py  \n",
            "  inflating: models-1.13.0/research/rebar/rebar.py  \n",
            "  inflating: models-1.13.0/research/rebar/rebar_train.py  \n",
            "  inflating: models-1.13.0/research/rebar/utils.py  \n",
            "   creating: models-1.13.0/research/resnet/\n",
            "  inflating: models-1.13.0/research/resnet/BUILD  \n",
            "  inflating: models-1.13.0/research/resnet/README.md  \n",
            "  inflating: models-1.13.0/research/resnet/cifar_input.py  \n",
            "   creating: models-1.13.0/research/resnet/g3doc/\n",
            " extracting: models-1.13.0/research/resnet/g3doc/cifar_resnet.gif  \n",
            "  inflating: models-1.13.0/research/resnet/g3doc/cifar_resnet_legends.gif  \n",
            "  inflating: models-1.13.0/research/resnet/resnet_main.py  \n",
            "  inflating: models-1.13.0/research/resnet/resnet_model.py  \n",
            "   creating: models-1.13.0/research/sentiment_analysis/\n",
            "  inflating: models-1.13.0/research/sentiment_analysis/README.md  \n",
            " extracting: models-1.13.0/research/sentiment_analysis/__init__.py  \n",
            "   creating: models-1.13.0/research/sentiment_analysis/data/\n",
            " extracting: models-1.13.0/research/sentiment_analysis/data/__init__.py  \n",
            "  inflating: models-1.13.0/research/sentiment_analysis/data/dataset.py  \n",
            "  inflating: models-1.13.0/research/sentiment_analysis/data/imdb.py  \n",
            "  inflating: models-1.13.0/research/sentiment_analysis/data/util.py  \n",
            "  inflating: models-1.13.0/research/sentiment_analysis/sentiment_main.py  \n",
            "  inflating: models-1.13.0/research/sentiment_analysis/sentiment_model.py  \n",
            "   creating: models-1.13.0/research/seq2species/\n",
            "  inflating: models-1.13.0/research/seq2species/README.md  \n",
            "  inflating: models-1.13.0/research/seq2species/build_model.py  \n",
            "  inflating: models-1.13.0/research/seq2species/configuration.py  \n",
            "  inflating: models-1.13.0/research/seq2species/input.py  \n",
            "   creating: models-1.13.0/research/seq2species/protos/\n",
            "  inflating: models-1.13.0/research/seq2species/protos/BUILD  \n",
            " extracting: models-1.13.0/research/seq2species/protos/__init__.py  \n",
            "  inflating: models-1.13.0/research/seq2species/protos/seq2label.proto  \n",
            "  inflating: models-1.13.0/research/seq2species/run_training.py  \n",
            "  inflating: models-1.13.0/research/seq2species/run_training_test.py  \n",
            "  inflating: models-1.13.0/research/seq2species/seq2label_utils.py  \n",
            "  inflating: models-1.13.0/research/seq2species/test_utils.py  \n",
            "  inflating: models-1.13.0/research/setup.py  \n",
            "   creating: models-1.13.0/research/skip_thoughts/\n",
            "  inflating: models-1.13.0/research/skip_thoughts/.gitignore  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/README.md  \n",
            " extracting: models-1.13.0/research/skip_thoughts/WORKSPACE  \n",
            "   creating: models-1.13.0/research/skip_thoughts/skip_thoughts/\n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/BUILD  \n",
            " extracting: models-1.13.0/research/skip_thoughts/skip_thoughts/__init__.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/configuration.py  \n",
            "   creating: models-1.13.0/research/skip_thoughts/skip_thoughts/data/\n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/data/BUILD  \n",
            " extracting: models-1.13.0/research/skip_thoughts/skip_thoughts/data/__init__.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/data/preprocess_dataset.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/data/special_words.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/encoder_manager.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/evaluate.py  \n",
            "   creating: models-1.13.0/research/skip_thoughts/skip_thoughts/ops/\n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/ops/BUILD  \n",
            " extracting: models-1.13.0/research/skip_thoughts/skip_thoughts/ops/__init__.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/ops/gru_cell.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/ops/input_ops.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/skip_thoughts_encoder.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/skip_thoughts_model.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/skip_thoughts_model_test.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/track_perplexity.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/train.py  \n",
            "  inflating: models-1.13.0/research/skip_thoughts/skip_thoughts/vocabulary_expansion.py  \n",
            "   creating: models-1.13.0/research/slim/\n",
            "  inflating: models-1.13.0/research/slim/BUILD  \n",
            "  inflating: models-1.13.0/research/slim/README.md  \n",
            " extracting: models-1.13.0/research/slim/WORKSPACE  \n",
            " extracting: models-1.13.0/research/slim/__init__.py  \n",
            "   creating: models-1.13.0/research/slim/datasets/\n",
            " extracting: models-1.13.0/research/slim/datasets/__init__.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/build_imagenet_data.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/cifar10.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/dataset_factory.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/dataset_utils.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/download_and_convert_cifar10.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/download_and_convert_flowers.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/download_and_convert_imagenet.sh  \n",
            "  inflating: models-1.13.0/research/slim/datasets/download_and_convert_mnist.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/download_imagenet.sh  \n",
            "  inflating: models-1.13.0/research/slim/datasets/flowers.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/imagenet.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/imagenet_2012_validation_synset_labels.txt  \n",
            "  inflating: models-1.13.0/research/slim/datasets/imagenet_lsvrc_2015_synsets.txt  \n",
            "  inflating: models-1.13.0/research/slim/datasets/imagenet_metadata.txt  \n",
            "  inflating: models-1.13.0/research/slim/datasets/mnist.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/preprocess_imagenet_validation_data.py  \n",
            "  inflating: models-1.13.0/research/slim/datasets/process_bounding_boxes.py  \n",
            "   creating: models-1.13.0/research/slim/deployment/\n",
            " extracting: models-1.13.0/research/slim/deployment/__init__.py  \n",
            "  inflating: models-1.13.0/research/slim/deployment/model_deploy.py  \n",
            "  inflating: models-1.13.0/research/slim/deployment/model_deploy_test.py  \n",
            "  inflating: models-1.13.0/research/slim/download_and_convert_data.py  \n",
            "  inflating: models-1.13.0/research/slim/eval_image_classifier.py  \n",
            "  inflating: models-1.13.0/research/slim/export_inference_graph.py  \n",
            "  inflating: models-1.13.0/research/slim/export_inference_graph_test.py  \n",
            "   creating: models-1.13.0/research/slim/nets/\n",
            " extracting: models-1.13.0/research/slim/nets/__init__.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/alexnet.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/alexnet_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/cifarnet.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/cyclegan.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/cyclegan_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/dcgan.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/dcgan_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/i3d.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/i3d_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/i3d_utils.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_resnet_v2.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_resnet_v2_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_utils.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v1.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v1_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v2.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v2_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v3.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v3_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v4.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/inception_v4_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/lenet.py  \n",
            "   creating: models-1.13.0/research/slim/nets/mobilenet/\n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/README.md  \n",
            " extracting: models-1.13.0/research/slim/nets/mobilenet/__init__.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/conv_blocks.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/madds_top1_accuracy.png  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/mobilenet.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/mobilenet_example.ipynb  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/mobilenet_v2.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet/mobilenet_v2_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet_v1.md  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet_v1.png  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet_v1.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet_v1_eval.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet_v1_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/mobilenet_v1_train.py  \n",
            "   creating: models-1.13.0/research/slim/nets/nasnet/\n",
            "  inflating: models-1.13.0/research/slim/nets/nasnet/README.md  \n",
            " extracting: models-1.13.0/research/slim/nets/nasnet/__init__.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nasnet/nasnet.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nasnet/nasnet_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nasnet/nasnet_utils.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nasnet/nasnet_utils_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nasnet/pnasnet.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nasnet/pnasnet_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nets_factory.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/nets_factory_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/overfeat.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/overfeat_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/pix2pix.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/pix2pix_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/resnet_utils.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/resnet_v1.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/resnet_v1_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/resnet_v2.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/resnet_v2_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/s3dg.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/s3dg_test.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/vgg.py  \n",
            "  inflating: models-1.13.0/research/slim/nets/vgg_test.py  \n",
            "   creating: models-1.13.0/research/slim/preprocessing/\n",
            " extracting: models-1.13.0/research/slim/preprocessing/__init__.py  \n",
            "  inflating: models-1.13.0/research/slim/preprocessing/cifarnet_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/slim/preprocessing/inception_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/slim/preprocessing/lenet_preprocessing.py  \n",
            "  inflating: models-1.13.0/research/slim/preprocessing/preprocessing_factory.py  \n",
            "  inflating: models-1.13.0/research/slim/preprocessing/vgg_preprocessing.py  \n",
            "   creating: models-1.13.0/research/slim/scripts/\n",
            "  inflating: models-1.13.0/research/slim/scripts/export_mobilenet.sh  \n",
            "  inflating: models-1.13.0/research/slim/scripts/finetune_inception_resnet_v2_on_flowers.sh  \n",
            "  inflating: models-1.13.0/research/slim/scripts/finetune_inception_v1_on_flowers.sh  \n",
            "  inflating: models-1.13.0/research/slim/scripts/finetune_inception_v3_on_flowers.sh  \n",
            "  inflating: models-1.13.0/research/slim/scripts/finetune_resnet_v1_50_on_flowers.sh  \n",
            "  inflating: models-1.13.0/research/slim/scripts/train_cifarnet_on_cifar10.sh  \n",
            "  inflating: models-1.13.0/research/slim/scripts/train_lenet_on_mnist.sh  \n",
            "  inflating: models-1.13.0/research/slim/setup.py  \n",
            "  inflating: models-1.13.0/research/slim/slim_walkthrough.ipynb  \n",
            "  inflating: models-1.13.0/research/slim/train_image_classifier.py  \n",
            "   creating: models-1.13.0/research/steve/\n",
            "  inflating: models-1.13.0/research/steve/README.md  \n",
            "  inflating: models-1.13.0/research/steve/agent.py  \n",
            "  inflating: models-1.13.0/research/steve/config.py  \n",
            "   creating: models-1.13.0/research/steve/config/\n",
            "   creating: models-1.13.0/research/steve/config/algos/\n",
            " extracting: models-1.13.0/research/steve/config/algos/ddpg.json  \n",
            "  inflating: models-1.13.0/research/steve/config/algos/mve_mean.json  \n",
            "  inflating: models-1.13.0/research/steve/config/algos/mve_tdk.json  \n",
            "  inflating: models-1.13.0/research/steve/config/algos/mve_tdlambda.json  \n",
            "  inflating: models-1.13.0/research/steve/config/algos/steve.json  \n",
            "  inflating: models-1.13.0/research/steve/config/algos/steve_cov.json  \n",
            "   creating: models-1.13.0/research/steve/config/core/\n",
            "  inflating: models-1.13.0/research/steve/config/core/basic.json  \n",
            "  inflating: models-1.13.0/research/steve/config/core/bayesian.json  \n",
            "  inflating: models-1.13.0/research/steve/config/core/model.json  \n",
            "   creating: models-1.13.0/research/steve/config/envs/\n",
            "  inflating: models-1.13.0/research/steve/config/envs/flagrun.json  \n",
            "  inflating: models-1.13.0/research/steve/config/envs/halfcheetah.json  \n",
            "  inflating: models-1.13.0/research/steve/config/envs/hardcore.json  \n",
            "  inflating: models-1.13.0/research/steve/config/envs/hopper.json  \n",
            "  inflating: models-1.13.0/research/steve/config/envs/humanoid.json  \n",
            "  inflating: models-1.13.0/research/steve/config/envs/rshum.json  \n",
            "  inflating: models-1.13.0/research/steve/config/envs/swimmer.json  \n",
            "  inflating: models-1.13.0/research/steve/config/envs/walker2d.json  \n",
            "   creating: models-1.13.0/research/steve/config/experimental_setups/\n",
            "  inflating: models-1.13.0/research/steve/config/experimental_setups/speedrun.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/\n",
            "   creating: models-1.13.0/research/steve/config/experiments/ablations/\n",
            "   creating: models-1.13.0/research/steve/config/experiments/ablations/baselines/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/ensemble_mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/ensemble_mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/ensemble_mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_25tdlambda0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_25tdlambda1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_25tdlambda2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_75tdlambda0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_75tdlambda1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_75tdlambda2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_meank0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_meank1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/mve_meank2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/steve_cov0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/steve_cov1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/baselines/steve_cov2.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/ablations/horizons/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_1h0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_1h1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_1h2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_2h0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_2h1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_2h2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_5h0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_5h1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/ablations/horizons/steve_5h2.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/\n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/flagrun/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/halfcheetah/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hardcore/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/hopper/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/humanoid/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/rshum/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/swimmer/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/ddpg2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/ddpg3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/mve_tdk2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/mve_tdk3.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/steve2.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/goodruns/walker2d/steve3.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/speedruns/\n",
            "   creating: models-1.13.0/research/steve/config/experiments/speedruns/flagrun/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/flagrun/speedy_ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/flagrun/speedy_ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/flagrun/speedy_mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/flagrun/speedy_mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/flagrun/speedy_steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/flagrun/speedy_steve1.json  \n",
            "   creating: models-1.13.0/research/steve/config/experiments/speedruns/humanoid/\n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/humanoid/speedy_ddpg0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/humanoid/speedy_ddpg1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/humanoid/speedy_mve_tdk0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/humanoid/speedy_mve_tdk1.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/humanoid/speedy_steve0.json  \n",
            "  inflating: models-1.13.0/research/steve/config/experiments/speedruns/humanoid/speedy_steve1.json  \n",
            "  inflating: models-1.13.0/research/steve/envwrap.py  \n",
            "  inflating: models-1.13.0/research/steve/learner.py  \n",
            "  inflating: models-1.13.0/research/steve/master.py  \n",
            "  inflating: models-1.13.0/research/steve/nn.py  \n",
            "  inflating: models-1.13.0/research/steve/replay.py  \n",
            "  inflating: models-1.13.0/research/steve/toy_demo.py  \n",
            "  inflating: models-1.13.0/research/steve/util.py  \n",
            "  inflating: models-1.13.0/research/steve/valuerl.py  \n",
            "  inflating: models-1.13.0/research/steve/valuerl_learner.py  \n",
            "  inflating: models-1.13.0/research/steve/visualizer.py  \n",
            "  inflating: models-1.13.0/research/steve/worldmodel.py  \n",
            "  inflating: models-1.13.0/research/steve/worldmodel_learner.py  \n",
            "   creating: models-1.13.0/research/street/\n",
            "  inflating: models-1.13.0/research/street/README.md  \n",
            "   creating: models-1.13.0/research/street/cc/\n",
            "  inflating: models-1.13.0/research/street/cc/rnn_ops.cc  \n",
            "   creating: models-1.13.0/research/street/g3doc/\n",
            "  inflating: models-1.13.0/research/street/g3doc/avdessapins.png  \n",
            "  inflating: models-1.13.0/research/street/g3doc/vgslspecs.md  \n",
            "   creating: models-1.13.0/research/street/python/\n",
            "  inflating: models-1.13.0/research/street/python/decoder.py  \n",
            "  inflating: models-1.13.0/research/street/python/decoder_test.py  \n",
            "  inflating: models-1.13.0/research/street/python/errorcounter.py  \n",
            "  inflating: models-1.13.0/research/street/python/errorcounter_test.py  \n",
            "  inflating: models-1.13.0/research/street/python/fsns_urls.py  \n",
            "  inflating: models-1.13.0/research/street/python/fsns_urls.txt  \n",
            "  inflating: models-1.13.0/research/street/python/nn_ops.py  \n",
            "  inflating: models-1.13.0/research/street/python/shapes.py  \n",
            "  inflating: models-1.13.0/research/street/python/shapes_test.py  \n",
            "  inflating: models-1.13.0/research/street/python/vgsl_eval.py  \n",
            "  inflating: models-1.13.0/research/street/python/vgsl_input.py  \n",
            "  inflating: models-1.13.0/research/street/python/vgsl_model.py  \n",
            "  inflating: models-1.13.0/research/street/python/vgsl_model_test.py  \n",
            "  inflating: models-1.13.0/research/street/python/vgsl_train.py  \n",
            "  inflating: models-1.13.0/research/street/python/vgslspecs.py  \n",
            "  inflating: models-1.13.0/research/street/python/vgslspecs_test.py  \n",
            "   creating: models-1.13.0/research/street/testdata/\n",
            "  inflating: models-1.13.0/research/street/testdata/arial-32-tiny  \n",
            "  inflating: models-1.13.0/research/street/testdata/arial.charset_size=105.txt  \n",
            "  inflating: models-1.13.0/research/street/testdata/charset_size=134.txt  \n",
            " extracting: models-1.13.0/research/street/testdata/charset_size_10.txt  \n",
            "  inflating: models-1.13.0/research/street/testdata/mnist-tiny  \n",
            "  inflating: models-1.13.0/research/street/testdata/numbers-16-tiny  \n",
            "  inflating: models-1.13.0/research/street/testdata/numbers.charset_size=12.txt  \n",
            "   creating: models-1.13.0/research/struct2depth/\n",
            "  inflating: models-1.13.0/research/struct2depth/BUILD  \n",
            "  inflating: models-1.13.0/research/struct2depth/README.md  \n",
            "  inflating: models-1.13.0/research/struct2depth/alignment.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/gen_data_city.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/gen_data_kitti.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/inference.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/model.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/nets.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/optimize.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/project.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/reader.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/train.py  \n",
            "  inflating: models-1.13.0/research/struct2depth/util.py  \n",
            "   creating: models-1.13.0/research/swivel/\n",
            "  inflating: models-1.13.0/research/swivel/.gitignore  \n",
            "  inflating: models-1.13.0/research/swivel/README.md  \n",
            "  inflating: models-1.13.0/research/swivel/analogy.cc  \n",
            "  inflating: models-1.13.0/research/swivel/distributed.sh  \n",
            "  inflating: models-1.13.0/research/swivel/eval.mk  \n",
            "  inflating: models-1.13.0/research/swivel/fastprep.cc  \n",
            "  inflating: models-1.13.0/research/swivel/fastprep.mk  \n",
            "  inflating: models-1.13.0/research/swivel/glove_to_shards.py  \n",
            "  inflating: models-1.13.0/research/swivel/nearest.py  \n",
            "  inflating: models-1.13.0/research/swivel/prep.py  \n",
            "  inflating: models-1.13.0/research/swivel/swivel.py  \n",
            "  inflating: models-1.13.0/research/swivel/text2bin.py  \n",
            "  inflating: models-1.13.0/research/swivel/vecs.py  \n",
            "  inflating: models-1.13.0/research/swivel/wordsim.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/\n",
            " extracting: models-1.13.0/research/syntaxnet/.dockerignore  \n",
            "  inflating: models-1.13.0/research/syntaxnet/.gitignore  \n",
            "  inflating: models-1.13.0/research/syntaxnet/Dockerfile  \n",
            "  inflating: models-1.13.0/research/syntaxnet/README.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/WORKSPACE  \n",
            "   creating: models-1.13.0/research/syntaxnet/docker-devel/\n",
            "  inflating: models-1.13.0/research/syntaxnet/docker-devel/Dockerfile-test  \n",
            "  inflating: models-1.13.0/research/syntaxnet/docker-devel/Dockerfile-test-base  \n",
            "  inflating: models-1.13.0/research/syntaxnet/docker-devel/Dockerfile.min  \n",
            "  inflating: models-1.13.0/research/syntaxnet/docker-devel/README.txt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/docker-devel/build_devel.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/docker-devel/build_wheels.sh  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/BUILD  \n",
            " extracting: models-1.13.0/research/syntaxnet/dragnn/__init__.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/components/\n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/components/stateless/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/stateless/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/stateless/stateless_component.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/testdata/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/testdata/master_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.master-spec  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.tag-map  \n",
            " extracting: models-1.13.0/research/syntaxnet/dragnn/components/syntaxnet/testdata/syntaxnet-tagger.word-map  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/components/util/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/util/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/config_builder/\n",
            " extracting: models-1.13.0/research/syntaxnet/dragnn/config_builder/__init__.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/conll2017/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/conll_parser_trainer.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/make_parser_spec.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/\n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/category-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/char-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/char-ngram-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/lcword-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/prefix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/suffix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/tag-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/tag-to-category  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter-resource/word-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.checkpoint.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.checkpoint.index  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.checkpoint.meta  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/conll2017/sample/zh-segmenter.master_spec  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/core/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/beam.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/beam_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/component_registry.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/component_registry.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/compute_session.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/compute_session_impl.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/compute_session_impl.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/compute_session_impl_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/compute_session_pool.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/compute_session_pool.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/compute_session_pool_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/index_translator.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/index_translator.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/index_translator_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/input_batch_cache.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/input_batch_cache_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/core/interfaces/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/interfaces/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/interfaces/component.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/interfaces/input_batch.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/interfaces/transition_state.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/interfaces/transition_state_starter_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/core/ops/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/compute_session_op.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/compute_session_op.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/ops/shape_helpers.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/resource_container.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/resource_container_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/core/test/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/test/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/test/fake_component_base.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/test/generic.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/test/generic.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/test/mock_component.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/test/mock_compute_session.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/test/mock_transition_state.h  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/brain-parser-model  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/repository  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/simple-tagger.brain-parser-model  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/simple-tagger.repository  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/simple-tagger.tag-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/simple_parser_master_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/simple_tagger_lstm_master_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/simple_tagger_master_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/simple_tagger_wrapped_lstm_master_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/split_tagger_master_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/syntaxnet_tagger.label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/syntaxnet_tagger.tag-map  \n",
            " extracting: models-1.13.0/research/syntaxnet/dragnn/core/testdata/syntaxnet_tagger.word-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/tagger_parser_master_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/testdata/ud-hungarian.master-spec  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/core/util/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/util/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/core/util/label.h  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/io/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/io/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/io/sentence_input_batch.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/io/sentence_input_batch.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/io/syntaxnet_sentence.h  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/mst/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/README.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/disjoint_set_forest.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/disjoint_set_forest_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/mst_solver.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/mst_solver_random_comparison_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/mst_solver_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/mst/ops/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/ops/mst_op_kernels.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/ops/mst_ops.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/spanning_tree_iterator.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/spanning_tree_iterator.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/mst/spanning_tree_iterator_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/protos/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/protos/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/protos/cell_trace.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/protos/data.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/protos/export.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/protos/runtime.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/protos/spec.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/protos/trace.proto  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/python/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/biaffine_units.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/biaffine_units_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/bulk_component.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/bulk_component_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/component.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/component_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/composite_optimizer.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/composite_optimizer_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/digraph_ops.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/digraph_ops_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/dragnn_model_saver.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/dragnn_ops.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/evaluation.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/evaluation_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/file_diff_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/graph_builder.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/graph_builder_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/lexicon.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/lexicon_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/load_dragnn_cc_impl.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/load_mst_cc_impl.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/mst_ops.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/mst_ops_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/mst_units.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/mst_units_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/network_units.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/network_units_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/render_parse_tree_graphviz.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/render_parse_tree_graphviz_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/render_spec_with_graphviz.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/runtime_support.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/runtime_support_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/sentence_io.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/sentence_io_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/spec_builder.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/spec_builder_test.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/python/testdata/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/trainer_lib.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/trainer_lib_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/transformer_units.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/transformer_units_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/visualization.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/visualization_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/python/wrapped_units.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/tools/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/BUILD  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/tools/benchmarks/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/benchmarks/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/build_pip_package.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/evaluator.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/model_trainer.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/model_trainer_test.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/oss_notebook_launcher.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/oss_setup.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/parse_to_conll.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/parser_trainer.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/segmenter-evaluator.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/segmenter_trainer.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/\n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/config.txt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/hyperparameters.pbtxt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/master.pbtxt  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/category-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/char-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/char-ngram-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/lcword-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/prefix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/suffix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/tag-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/tag-to-category  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/resources/word-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/biaffine.model/targets.pbtxt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/testdata/small.conll  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/tools/trainer.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/dragnn/viz/\n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/Dockerfile  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/README.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/compile-minified.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/develop.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/dragnn_layout.js  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/dragnn_tutorial_2.html  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/example_with_lookahead.html  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/index.html  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/interactive_graph.jsx  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/node_info.jsx  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/package.json  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/sample_master_state.json  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/trace_interaction_handlers.js  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/visualize.js  \n",
            " extracting: models-1.13.0/research/syntaxnet/dragnn/viz/viz.min.js.gz  \n",
            "  inflating: models-1.13.0/research/syntaxnet/dragnn/viz/webpack.config.js  \n",
            "   creating: models-1.13.0/research/syntaxnet/examples/\n",
            "   creating: models-1.13.0/research/syntaxnet/examples/dragnn/\n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/BUILD  \n",
            "   creating: models-1.13.0/research/syntaxnet/examples/dragnn/data/\n",
            "   creating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/\n",
            " extracting: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/category-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/char-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/char-ngram-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/checkpoint  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/lcword-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/parser_spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/prefix-table  \n",
            "   creating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/\n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/category-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/char-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/char-ngram-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/checkpoint.data-00000-of-00001  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/checkpoint.index  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/checkpoint.meta  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/lcword-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/prefix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/spec.textproto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/suffix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/tag-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/tag-to-category  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/segmenter/word-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/suffix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/tag-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/tag-to-category  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/en/word-map  \n",
            "   creating: models-1.13.0/research/syntaxnet/examples/dragnn/data/es/\n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/es/es-universal-dev.conll  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/data/es/es-universal-train.conll  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/interactive_text_analyzer.ipynb  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/test_run_all_tutorials.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/trainer_tutorial.ipynb  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/tutorial_1.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/tutorial_2.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/examples/dragnn/tutorial_data/\n",
            "  inflating: models-1.13.0/research/syntaxnet/examples/dragnn/tutorial_data/sentence.prototext  \n",
            "   creating: models-1.13.0/research/syntaxnet/g3doc/\n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/CLOUD.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/DRAGNN.md  \n",
            "   creating: models-1.13.0/research/syntaxnet/g3doc/conll2017/\n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/conll2017/README.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/conll2017/cooking.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/conll2017/paper.pdf  \n",
            "   creating: models-1.13.0/research/syntaxnet/g3doc/dragnn/\n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn/cpp_api.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn/creating_components.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops.md  \n",
            "   creating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/\n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/advance_from_oracle.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/advance_from_prediction.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/attach_data_reader.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/batch_size.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/bulk_advance_from_oracle.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/bulk_advance_from_prediction.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/bulk_fixed_embeddings.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/bulk_fixed_feature_ids.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/bulk_fixed_features.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/dragnn_embedding_initializer.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/emit_all_final.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/emit_annotations.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/emit_oracle_labels.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/extract_fixed_features.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/extract_link_features.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/get_component_trace.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/get_session.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/init_component_data.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/release_session.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/set_tracing.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/tf.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/dragnn_ops/write_annotations.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/full-trace-image.png  \n",
            "   creating: models-1.13.0/research/syntaxnet/g3doc/images/\n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/api_manager.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/beam_search_training.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/cloudshell2.jpg  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/dragnn-spec-overview.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/dragnn-train-eval.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/dragnn-unrolling.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/dragnn_tf_overview.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/ff_nn_schematic.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/hamburger.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/ipython-link.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/looping-parser.gif  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/notebook-upload.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/sawman.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/tutorial_1.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/images/tutorial_2.png  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/structured.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/syntaxnet-tutorial.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/universal.md  \n",
            "  inflating: models-1.13.0/research/syntaxnet/g3doc/unrolled-dragnn.png  \n",
            "   creating: models-1.13.0/research/syntaxnet/syntaxnet/\n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/affix.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/affix.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/arc_standard_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/arc_standard_transitions_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/base.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/beam_reader_ops.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/beam_reader_ops_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/binary_segment_state.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/binary_segment_state.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/binary_segment_state_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/binary_segment_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/binary_segment_transitions_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_ngram_string_extractor.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_ngram_string_extractor.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_ngram_string_extractor_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_properties.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_properties.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_properties_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_shift_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_shift_transitions.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/conll2tree.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/context.pbtxt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/demo.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/dictionary.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/document_filters.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/document_format.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/document_format.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/embedding_feature_extractor.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/feature_extractor.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/feature_extractor.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/feature_extractor.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/feature_types.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/fml_parser.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/fml_parser.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/fml_parser_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/generic_features.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/generic_features.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/generic_features_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/graph_builder.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/graph_builder_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/head_label_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/head_label_transitions.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/head_label_transitions_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/head_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/head_transitions.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/head_transitions_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/kbest_syntax.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/label_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/label_transitions.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/label_transitions_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/lexicon_builder.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/lexicon_builder_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/load_parser_ops.py  \n",
            "   creating: models-1.13.0/research/syntaxnet/syntaxnet/models/\n",
            "   creating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/\n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/context.pbtxt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/fine-to-universal.map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/label-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/parser-params  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/prefix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/suffix-table  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/tag-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/tagger-params  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/models/parsey_mcparseface/word-map  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/morpher_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/morphology_label_set.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/morphology_label_set.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/morphology_label_set_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/once_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/once_transitions_test.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/syntaxnet/ops/\n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/ops/parser_ops.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/ops/shape_helpers.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_eval.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_features.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_features.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_features_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_state.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_state.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_trainer.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_trainer_test.sh  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/parser_transitions.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/populate_test_inputs.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/populate_test_inputs.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/proto_io.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/reader_ops.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/reader_ops_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/registry.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/registry.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/registry_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/segmenter_utils.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/segmenter_utils.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/segmenter_utils_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/sentence.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/sentence_batch.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/sentence_batch.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/sentence_features.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/sentence_features.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/sentence_features_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/shared_store.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/shared_store.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/shared_store_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/shift_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/sparse.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/structured_graph_builder.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/syntaxnet.bzl  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/syntaxnet_ops.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/tagger_transitions.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/tagger_transitions_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/task_context.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/task_context.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/task_spec.proto  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/term_frequency_map.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/term_frequency_map.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/term_frequency_map_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/test_flags.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/test_main.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/syntaxnet/testdata/\n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/testdata/context.pbtxt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/testdata/document  \n",
            " extracting: models-1.13.0/research/syntaxnet/syntaxnet/testdata/hello.txt  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/testdata/mini-training-set  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/text_formats.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/text_formats_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/unpack_sparse_features.cc  \n",
            "   creating: models-1.13.0/research/syntaxnet/syntaxnet/util/\n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/check.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/check_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/registry.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/registry_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/registry_test_base.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/registry_test_impl.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/resources.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/util/resources_test.py  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/utils.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/utils.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/whole_sentence_features.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/whole_sentence_features.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/whole_sentence_features_test.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/workspace.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/syntaxnet/workspace.h  \n",
            "   creating: models-1.13.0/research/syntaxnet/tensorflow/\n",
            "   creating: models-1.13.0/research/syntaxnet/third_party/\n",
            "   creating: models-1.13.0/research/syntaxnet/third_party/utf/\n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/LICENSE  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/README  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/rune.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrcat.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrchr.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrcmp.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrcpy.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrdup.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrecpy.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrlen.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrncat.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrncmp.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrncpy.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrrchr.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runestrstr.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runetype.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/runetypebody.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utf.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utfdef.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utfecpy.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utflen.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utfnlen.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utfrrune.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utfrune.c  \n",
            "  inflating: models-1.13.0/research/syntaxnet/third_party/utf/utfutf.c  \n",
            "   creating: models-1.13.0/research/syntaxnet/tools/\n",
            "  inflating: models-1.13.0/research/syntaxnet/tools/bazel.rc  \n",
            "   creating: models-1.13.0/research/syntaxnet/util/\n",
            "   creating: models-1.13.0/research/syntaxnet/util/utf8/\n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/BUILD  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/gtest_main.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/unicodetext.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/unicodetext.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/unicodetext_main.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/unicodetext_unittest.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/unilib.cc  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/unilib.h  \n",
            "  inflating: models-1.13.0/research/syntaxnet/util/utf8/unilib_utf8_utils.h  \n",
            "   creating: models-1.13.0/research/tcn/\n",
            "  inflating: models-1.13.0/research/tcn/BUILD  \n",
            "  inflating: models-1.13.0/research/tcn/README.md  \n",
            " extracting: models-1.13.0/research/tcn/WORKSPACE  \n",
            "  inflating: models-1.13.0/research/tcn/alignment.py  \n",
            "   creating: models-1.13.0/research/tcn/configs/\n",
            "  inflating: models-1.13.0/research/tcn/configs/pouring.yml  \n",
            "  inflating: models-1.13.0/research/tcn/configs/tcn_default.yml  \n",
            "  inflating: models-1.13.0/research/tcn/configs/test_estimator.yml  \n",
            "  inflating: models-1.13.0/research/tcn/data_providers.py  \n",
            "  inflating: models-1.13.0/research/tcn/data_providers_test.py  \n",
            "   creating: models-1.13.0/research/tcn/dataset/\n",
            "  inflating: models-1.13.0/research/tcn/dataset/images_to_videos.py  \n",
            "  inflating: models-1.13.0/research/tcn/dataset/videos_to_tfrecords.py  \n",
            "  inflating: models-1.13.0/research/tcn/dataset/webcam.py  \n",
            "  inflating: models-1.13.0/research/tcn/download_pretrained.py  \n",
            "   creating: models-1.13.0/research/tcn/estimators/\n",
            "  inflating: models-1.13.0/research/tcn/estimators/base_estimator.py  \n",
            "  inflating: models-1.13.0/research/tcn/estimators/get_estimator.py  \n",
            "  inflating: models-1.13.0/research/tcn/estimators/mvtcn_estimator.py  \n",
            "  inflating: models-1.13.0/research/tcn/estimators/svtcn_estimator.py  \n",
            "  inflating: models-1.13.0/research/tcn/estimators/svtcn_loss.py  \n",
            "  inflating: models-1.13.0/research/tcn/estimators/svtcn_loss_test.py  \n",
            "  inflating: models-1.13.0/research/tcn/eval.py  \n",
            "   creating: models-1.13.0/research/tcn/g3doc/\n",
            "  inflating: models-1.13.0/research/tcn/g3doc/alignment.png  \n",
            "  inflating: models-1.13.0/research/tcn/g3doc/all_error.png  \n",
            "  inflating: models-1.13.0/research/tcn/g3doc/avg_error.png  \n",
            "  inflating: models-1.13.0/research/tcn/g3doc/im.gif  \n",
            "  inflating: models-1.13.0/research/tcn/g3doc/loss.png  \n",
            "  inflating: models-1.13.0/research/tcn/g3doc/pca.png  \n",
            "  inflating: models-1.13.0/research/tcn/g3doc/val_loss.png  \n",
            "  inflating: models-1.13.0/research/tcn/generate_videos.py  \n",
            "  inflating: models-1.13.0/research/tcn/labeled_eval.py  \n",
            "  inflating: models-1.13.0/research/tcn/labeled_eval_test.py  \n",
            "  inflating: models-1.13.0/research/tcn/model.py  \n",
            "  inflating: models-1.13.0/research/tcn/preprocessing.py  \n",
            "  inflating: models-1.13.0/research/tcn/train.py  \n",
            "   creating: models-1.13.0/research/tcn/utils/\n",
            "  inflating: models-1.13.0/research/tcn/utils/luatables.py  \n",
            "  inflating: models-1.13.0/research/tcn/utils/progress.py  \n",
            "  inflating: models-1.13.0/research/tcn/utils/util.py  \n",
            "  inflating: models-1.13.0/research/tcn/visualize_embeddings.py  \n",
            "   creating: models-1.13.0/research/tensorrt/\n",
            "  inflating: models-1.13.0/research/tensorrt/README.md  \n",
            "  inflating: models-1.13.0/research/tensorrt/image.jpg  \n",
            "  inflating: models-1.13.0/research/tensorrt/labellist.json  \n",
            "  inflating: models-1.13.0/research/tensorrt/tensorrt.py  \n",
            "   creating: models-1.13.0/research/textsum/\n",
            "  inflating: models-1.13.0/research/textsum/BUILD  \n",
            "  inflating: models-1.13.0/research/textsum/README.md  \n",
            "  inflating: models-1.13.0/research/textsum/batch_reader.py  \n",
            "  inflating: models-1.13.0/research/textsum/beam_search.py  \n",
            "  inflating: models-1.13.0/research/textsum/data.py  \n",
            "   creating: models-1.13.0/research/textsum/data/\n",
            "  inflating: models-1.13.0/research/textsum/data/data  \n",
            "  inflating: models-1.13.0/research/textsum/data/vocab  \n",
            "  inflating: models-1.13.0/research/textsum/data_convert_example.py  \n",
            "  inflating: models-1.13.0/research/textsum/seq2seq_attention.py  \n",
            "  inflating: models-1.13.0/research/textsum/seq2seq_attention_decode.py  \n",
            "  inflating: models-1.13.0/research/textsum/seq2seq_attention_model.py  \n",
            "  inflating: models-1.13.0/research/textsum/seq2seq_lib.py  \n",
            "   creating: models-1.13.0/research/transformer/\n",
            "  inflating: models-1.13.0/research/transformer/README.md  \n",
            "  inflating: models-1.13.0/research/transformer/cluttered_mnist.py  \n",
            "   creating: models-1.13.0/research/transformer/data/\n",
            "  inflating: models-1.13.0/research/transformer/data/README.md  \n",
            "  inflating: models-1.13.0/research/transformer/example.py  \n",
            "  inflating: models-1.13.0/research/transformer/spatial_transformer.py  \n",
            "  inflating: models-1.13.0/research/transformer/tf_utils.py  \n",
            "   creating: models-1.13.0/research/vid2depth/\n",
            "  inflating: models-1.13.0/research/vid2depth/.bazelrc  \n",
            "  inflating: models-1.13.0/research/vid2depth/BUILD  \n",
            "  inflating: models-1.13.0/research/vid2depth/README.md  \n",
            "  inflating: models-1.13.0/research/vid2depth/WORKSPACE  \n",
            "   creating: models-1.13.0/research/vid2depth/dataset/\n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/__init__.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/dataset_loader.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/gen_data.py  \n",
            "   creating: models-1.13.0/research/vid2depth/dataset/kitti/\n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/kitti/static_frames.txt  \n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/kitti/test_files_eigen.txt  \n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/kitti/test_files_stereo.txt  \n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/kitti/test_scenes_eigen.txt  \n",
            "  inflating: models-1.13.0/research/vid2depth/dataset/kitti/test_scenes_stereo.txt  \n",
            "  inflating: models-1.13.0/research/vid2depth/inference.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/model.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/nets.py  \n",
            "   creating: models-1.13.0/research/vid2depth/ops/\n",
            "  inflating: models-1.13.0/research/vid2depth/ops/BUILD  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/__init__.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/icp_grad.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/icp_grad_test.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/icp_op.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/icp_op_kernel.cc  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/icp_test.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/icp_train_demo.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/icp_util.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/ops/pcl_demo.cc  \n",
            "   creating: models-1.13.0/research/vid2depth/ops/testdata/\n",
            "  inflating: models-1.13.0/research/vid2depth/ops/testdata/pointcloud.npy  \n",
            "  inflating: models-1.13.0/research/vid2depth/project.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/reader.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/repo.bzl  \n",
            "   creating: models-1.13.0/research/vid2depth/third_party/\n",
            " extracting: models-1.13.0/research/vid2depth/third_party/BUILD  \n",
            "  inflating: models-1.13.0/research/vid2depth/third_party/eigen.BUILD  \n",
            "  inflating: models-1.13.0/research/vid2depth/third_party/flann.BUILD  \n",
            "  inflating: models-1.13.0/research/vid2depth/third_party/hdf5.BUILD  \n",
            "  inflating: models-1.13.0/research/vid2depth/third_party/pcl.BUILD  \n",
            "  inflating: models-1.13.0/research/vid2depth/train.py  \n",
            "  inflating: models-1.13.0/research/vid2depth/util.py  \n",
            "   creating: models-1.13.0/research/video_prediction/\n",
            "  inflating: models-1.13.0/research/video_prediction/README.md  \n",
            "  inflating: models-1.13.0/research/video_prediction/download_data.sh  \n",
            "  inflating: models-1.13.0/research/video_prediction/lstm_ops.py  \n",
            "  inflating: models-1.13.0/research/video_prediction/prediction_input.py  \n",
            "  inflating: models-1.13.0/research/video_prediction/prediction_model.py  \n",
            "  inflating: models-1.13.0/research/video_prediction/prediction_train.py  \n",
            "  inflating: models-1.13.0/research/video_prediction/push_datafiles.txt  \n",
            "   creating: models-1.13.0/samples/\n",
            "   creating: models-1.13.0/samples/cookbook/\n",
            "   creating: models-1.13.0/samples/cookbook/regression/\n",
            "  inflating: models-1.13.0/samples/cookbook/regression/__init__.py  \n",
            "  inflating: models-1.13.0/samples/cookbook/regression/automobile_data.py  \n",
            "  inflating: models-1.13.0/samples/cookbook/regression/custom_regression.py  \n",
            "  inflating: models-1.13.0/samples/cookbook/regression/dnn_regression.py  \n",
            "  inflating: models-1.13.0/samples/cookbook/regression/linear_regression.py  \n",
            "  inflating: models-1.13.0/samples/cookbook/regression/linear_regression_categorical.py  \n",
            "  inflating: models-1.13.0/samples/cookbook/regression/regression_test.py  \n",
            "   creating: models-1.13.0/samples/core/\n",
            "   creating: models-1.13.0/samples/core/get_started/\n",
            "  inflating: models-1.13.0/samples/core/get_started/_index.ipynb  \n",
            "  inflating: models-1.13.0/samples/core/get_started/custom_estimator.py  \n",
            "  inflating: models-1.13.0/samples/core/get_started/eager.ipynb  \n",
            "  inflating: models-1.13.0/samples/core/get_started/estimator_test.py  \n",
            "  inflating: models-1.13.0/samples/core/get_started/iris_data.py  \n",
            "  inflating: models-1.13.0/samples/core/get_started/premade_estimator.py  \n",
            "   creating: models-1.13.0/samples/core/guide/\n",
            "  inflating: models-1.13.0/samples/core/guide/autograph.ipynb  \n",
            "   creating: models-1.13.0/samples/core/tutorials/\n",
            "   creating: models-1.13.0/samples/core/tutorials/eager/\n",
            "  inflating: models-1.13.0/samples/core/tutorials/eager/custom_training_walkthrough.ipynb  \n",
            "   creating: models-1.13.0/samples/core/tutorials/estimators/\n",
            "  inflating: models-1.13.0/samples/core/tutorials/estimators/linear.ipynb  \n",
            "   creating: models-1.13.0/samples/core/tutorials/keras/\n",
            "  inflating: models-1.13.0/samples/core/tutorials/keras/basic_classification.ipynb  \n",
            "  inflating: models-1.13.0/samples/core/tutorials/keras/basic_regression.ipynb  \n",
            "  inflating: models-1.13.0/samples/core/tutorials/keras/basic_text_classification.ipynb  \n",
            "  inflating: models-1.13.0/samples/core/tutorials/keras/overfit_and_underfit.ipynb  \n",
            "  inflating: models-1.13.0/samples/core/tutorials/keras/save_and_restore_models.ipynb  \n",
            "   creating: models-1.13.0/samples/languages/\n",
            "   creating: models-1.13.0/samples/languages/java/\n",
            "  inflating: models-1.13.0/samples/languages/java/README.md  \n",
            "   creating: models-1.13.0/samples/languages/java/docker/\n",
            "  inflating: models-1.13.0/samples/languages/java/docker/Dockerfile  \n",
            "  inflating: models-1.13.0/samples/languages/java/docker/README.md  \n",
            "  inflating: models-1.13.0/samples/languages/java/docker/sanity_test.sh  \n",
            "  inflating: models-1.13.0/samples/languages/java/docker/test_inside_container.sh  \n",
            "   creating: models-1.13.0/samples/languages/java/label_image/\n",
            " extracting: models-1.13.0/samples/languages/java/label_image/.gitignore  \n",
            "  inflating: models-1.13.0/samples/languages/java/label_image/README.md  \n",
            "  inflating: models-1.13.0/samples/languages/java/label_image/download.py  \n",
            "  inflating: models-1.13.0/samples/languages/java/label_image/download.sh  \n",
            "  inflating: models-1.13.0/samples/languages/java/label_image/download_sample_images.sh  \n",
            "  inflating: models-1.13.0/samples/languages/java/label_image/pom.xml  \n",
            "   creating: models-1.13.0/samples/languages/java/label_image/src/\n",
            "   creating: models-1.13.0/samples/languages/java/label_image/src/main/\n",
            "   creating: models-1.13.0/samples/languages/java/label_image/src/main/java/\n",
            "  inflating: models-1.13.0/samples/languages/java/label_image/src/main/java/LabelImage.java  \n",
            "   creating: models-1.13.0/samples/languages/java/object_detection/\n",
            "  inflating: models-1.13.0/samples/languages/java/object_detection/.gitignore  \n",
            "  inflating: models-1.13.0/samples/languages/java/object_detection/README.md  \n",
            "  inflating: models-1.13.0/samples/languages/java/object_detection/download.sh  \n",
            "  inflating: models-1.13.0/samples/languages/java/object_detection/pom.xml  \n",
            "   creating: models-1.13.0/samples/languages/java/object_detection/src/\n",
            "   creating: models-1.13.0/samples/languages/java/object_detection/src/main/\n",
            "   creating: models-1.13.0/samples/languages/java/object_detection/src/main/java/\n",
            "  inflating: models-1.13.0/samples/languages/java/object_detection/src/main/java/DetectObjects.java  \n",
            "   creating: models-1.13.0/samples/languages/java/object_detection/src/main/java/object_detection/\n",
            "   creating: models-1.13.0/samples/languages/java/object_detection/src/main/java/object_detection/protos/\n",
            "  inflating: models-1.13.0/samples/languages/java/object_detection/src/main/java/object_detection/protos/StringIntLabelMapOuterClass.java  \n",
            "   creating: models-1.13.0/samples/languages/java/training/\n",
            " extracting: models-1.13.0/samples/languages/java/training/.gitignore  \n",
            "  inflating: models-1.13.0/samples/languages/java/training/README.md  \n",
            "   creating: models-1.13.0/samples/languages/java/training/model/\n",
            "  inflating: models-1.13.0/samples/languages/java/training/model/create_graph.py  \n",
            "  inflating: models-1.13.0/samples/languages/java/training/model/graph.pb  \n",
            "  inflating: models-1.13.0/samples/languages/java/training/pom.xml  \n",
            "   creating: models-1.13.0/samples/languages/java/training/src/\n",
            "   creating: models-1.13.0/samples/languages/java/training/src/main/\n",
            "   creating: models-1.13.0/samples/languages/java/training/src/main/java/\n",
            "  inflating: models-1.13.0/samples/languages/java/training/src/main/java/Train.java  \n",
            "   creating: models-1.13.0/samples/outreach/\n",
            "   creating: models-1.13.0/samples/outreach/blogs/\n",
            "  inflating: models-1.13.0/samples/outreach/blogs/blog_custom_estimators.py  \n",
            "  inflating: models-1.13.0/samples/outreach/blogs/blog_estimators_dataset.py  \n",
            "  inflating: models-1.13.0/samples/outreach/blogs/housing_prices.ipynb  \n",
            "   creating: models-1.13.0/samples/outreach/blogs/segmentation_blogpost/\n",
            "  inflating: models-1.13.0/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb  \n",
            "   creating: models-1.13.0/samples/outreach/demos/\n",
            "  inflating: models-1.13.0/samples/outreach/demos/eager_execution.ipynb  \n",
            "   creating: models-1.13.0/tutorials/\n",
            "  inflating: models-1.13.0/tutorials/README.md  \n",
            " extracting: models-1.13.0/tutorials/__init__.py  \n",
            "   creating: models-1.13.0/tutorials/embedding/\n",
            "  inflating: models-1.13.0/tutorials/embedding/README.md  \n",
            "  inflating: models-1.13.0/tutorials/embedding/__init__.py  \n",
            "  inflating: models-1.13.0/tutorials/embedding/word2vec.py  \n",
            "  inflating: models-1.13.0/tutorials/embedding/word2vec_kernels.cc  \n",
            "  inflating: models-1.13.0/tutorials/embedding/word2vec_ops.cc  \n",
            "  inflating: models-1.13.0/tutorials/embedding/word2vec_optimized.py  \n",
            "  inflating: models-1.13.0/tutorials/embedding/word2vec_optimized_test.py  \n",
            "  inflating: models-1.13.0/tutorials/embedding/word2vec_test.py  \n",
            "   creating: models-1.13.0/tutorials/image/\n",
            " extracting: models-1.13.0/tutorials/image/__init__.py  \n",
            "   creating: models-1.13.0/tutorials/image/alexnet/\n",
            "  inflating: models-1.13.0/tutorials/image/alexnet/BUILD  \n",
            " extracting: models-1.13.0/tutorials/image/alexnet/__init__.py  \n",
            "  inflating: models-1.13.0/tutorials/image/alexnet/alexnet_benchmark.py  \n",
            "   creating: models-1.13.0/tutorials/image/cifar10/\n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/BUILD  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/README.md  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/__init__.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/cifar10.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/cifar10_eval.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/cifar10_input.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/cifar10_input_test.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/cifar10_multi_gpu_train.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10/cifar10_train.py  \n",
            "   creating: models-1.13.0/tutorials/image/cifar10_estimator/\n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/README.md  \n",
            " extracting: models-1.13.0/tutorials/image/cifar10_estimator/__init__.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/cifar10.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/cifar10_main.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/cifar10_model.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/cifar10_utils.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/cmle_config.yaml  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/generate_cifar10_tfrecords.py  \n",
            "  inflating: models-1.13.0/tutorials/image/cifar10_estimator/model_base.py  \n",
            "   creating: models-1.13.0/tutorials/image/imagenet/\n",
            "  inflating: models-1.13.0/tutorials/image/imagenet/BUILD  \n",
            "  inflating: models-1.13.0/tutorials/image/imagenet/classify_image.py  \n",
            "   creating: models-1.13.0/tutorials/image/mnist/\n",
            "  inflating: models-1.13.0/tutorials/image/mnist/BUILD  \n",
            " extracting: models-1.13.0/tutorials/image/mnist/__init__.py  \n",
            "  inflating: models-1.13.0/tutorials/image/mnist/convolutional.py  \n",
            "   creating: models-1.13.0/tutorials/rnn/\n",
            "  inflating: models-1.13.0/tutorials/rnn/BUILD  \n",
            "  inflating: models-1.13.0/tutorials/rnn/README.md  \n",
            "  inflating: models-1.13.0/tutorials/rnn/__init__.py  \n",
            "   creating: models-1.13.0/tutorials/rnn/ptb/\n",
            "  inflating: models-1.13.0/tutorials/rnn/ptb/BUILD  \n",
            "  inflating: models-1.13.0/tutorials/rnn/ptb/__init__.py  \n",
            "  inflating: models-1.13.0/tutorials/rnn/ptb/ptb_word_lm.py  \n",
            "  inflating: models-1.13.0/tutorials/rnn/ptb/reader.py  \n",
            "  inflating: models-1.13.0/tutorials/rnn/ptb/reader_test.py  \n",
            "  inflating: models-1.13.0/tutorials/rnn/ptb/util.py  \n",
            "   creating: models-1.13.0/tutorials/rnn/quickdraw/\n",
            "  inflating: models-1.13.0/tutorials/rnn/quickdraw/BUILD  \n",
            "  inflating: models-1.13.0/tutorials/rnn/quickdraw/create_dataset.py  \n",
            "  inflating: models-1.13.0/tutorials/rnn/quickdraw/train_model.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiR5U1uNe5rV"
      },
      "source": [
        "!mv modelsn/ models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOmSyd3kfWHH",
        "outputId": "81219b23-2aa8-4ab0-f657-6df25f8d8359"
      },
      "source": [
        "%cd /content/drive/MyDrive/Face mask Detection/models/research"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Face mask Detection/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYMh3zRrf1hj"
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5FNuiRPWKMN"
      },
      "source": [
        "## Object detection imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbSgV9HcQMy6",
        "outputId": "11a3e393-7c17-484f-c517-4f7f31e495b4"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-01 11:10:21--  http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.33.208, 2607:f8b0:4004:837::2010\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.33.208|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149119618 (142M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_inception_v2_coco_2018_01_28.tar.gz’\n",
            "\n",
            "faster_rcnn_incepti 100%[===================>] 142.21M  76.0MB/s    in 1.9s    \n",
            "\n",
            "2021-06-01 11:10:23 (76.0 MB/s) - ‘faster_rcnn_inception_v2_coco_2018_01_28.tar.gz’ saved [149119618/149119618]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m7PDmtERJSN",
        "outputId": "da7e62af-dbab-4bae-81eb-dfed701806c1"
      },
      "source": [
        "!tar xvf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "faster_rcnn_inception_v2_coco_2018_01_28/\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.index\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/checkpoint\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.data-00000-of-00001\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt.meta\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/saved_model.pb\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/saved_model/variables/\n",
            "faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNE24bNVRYC1"
      },
      "source": [
        "!mv faster_rcnn_inception_v2_coco_2018_01_28/ faster_rcnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX3yABwSWAki",
        "outputId": "6d221fd7-1c84-457d-d7d7-bd281961c4b3"
      },
      "source": [
        "!python generate_tfrecord.py --csv_input=dataset/train/train.csv --image_dir=dataset/train/ --output_path=train.record"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From generate_tfrecord.py:102: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0601 11:48:46.458747 140484202735488 deprecation_wrapper.py:119] From generate_tfrecord.py:88: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0601 11:48:47.728027 140484202735488 deprecation_wrapper.py:119] From generate_tfrecord.py:47: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/drive/My Drive/Face mask Detection/models/research/train.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHuEAv4caMa2",
        "outputId": "285728f5-4c7c-44f0-a640-0e47d94438af"
      },
      "source": [
        "!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_coco.config"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:tensorflow:global step 7508: loss = 0.1117 (0.186 sec/step)\n",
            "I0601 12:15:44.163445 140438660523904 learning.py:507] global step 7508: loss = 0.1117 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7509: loss = 0.0996 (0.162 sec/step)\n",
            "I0601 12:15:44.327042 140438660523904 learning.py:507] global step 7509: loss = 0.0996 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7510: loss = 0.1896 (0.170 sec/step)\n",
            "I0601 12:15:44.498279 140438660523904 learning.py:507] global step 7510: loss = 0.1896 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7511: loss = 0.1271 (0.171 sec/step)\n",
            "I0601 12:15:44.671213 140438660523904 learning.py:507] global step 7511: loss = 0.1271 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7512: loss = 0.1738 (0.171 sec/step)\n",
            "I0601 12:15:44.843806 140438660523904 learning.py:507] global step 7512: loss = 0.1738 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7513: loss = 0.4784 (0.183 sec/step)\n",
            "I0601 12:15:45.027706 140438660523904 learning.py:507] global step 7513: loss = 0.4784 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7514: loss = 0.0379 (0.153 sec/step)\n",
            "I0601 12:15:45.182601 140438660523904 learning.py:507] global step 7514: loss = 0.0379 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 7515: loss = 0.1740 (0.168 sec/step)\n",
            "I0601 12:15:45.351552 140438660523904 learning.py:507] global step 7515: loss = 0.1740 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7516: loss = 0.1349 (0.169 sec/step)\n",
            "I0601 12:15:45.522163 140438660523904 learning.py:507] global step 7516: loss = 0.1349 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7517: loss = 0.0733 (0.210 sec/step)\n",
            "I0601 12:15:45.733381 140438660523904 learning.py:507] global step 7517: loss = 0.0733 (0.210 sec/step)\n",
            "INFO:tensorflow:global step 7518: loss = 0.0511 (0.167 sec/step)\n",
            "I0601 12:15:45.901847 140438660523904 learning.py:507] global step 7518: loss = 0.0511 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7519: loss = 0.2312 (0.182 sec/step)\n",
            "I0601 12:15:46.085224 140438660523904 learning.py:507] global step 7519: loss = 0.2312 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7520: loss = 0.0446 (0.183 sec/step)\n",
            "I0601 12:15:46.269823 140438660523904 learning.py:507] global step 7520: loss = 0.0446 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7521: loss = 0.0857 (0.153 sec/step)\n",
            "I0601 12:15:46.424292 140438660523904 learning.py:507] global step 7521: loss = 0.0857 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 7522: loss = 0.2242 (0.188 sec/step)\n",
            "I0601 12:15:46.613836 140438660523904 learning.py:507] global step 7522: loss = 0.2242 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7523: loss = 0.0516 (0.188 sec/step)\n",
            "I0601 12:15:46.803688 140438660523904 learning.py:507] global step 7523: loss = 0.0516 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7524: loss = 0.2394 (0.157 sec/step)\n",
            "I0601 12:15:46.962208 140438660523904 learning.py:507] global step 7524: loss = 0.2394 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7525: loss = 0.0215 (0.161 sec/step)\n",
            "I0601 12:15:47.124726 140438660523904 learning.py:507] global step 7525: loss = 0.0215 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7526: loss = 0.0909 (0.163 sec/step)\n",
            "I0601 12:15:47.288766 140438660523904 learning.py:507] global step 7526: loss = 0.0909 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7527: loss = 0.0813 (0.189 sec/step)\n",
            "I0601 12:15:47.478721 140438660523904 learning.py:507] global step 7527: loss = 0.0813 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 7528: loss = 0.2331 (0.177 sec/step)\n",
            "I0601 12:15:47.657654 140438660523904 learning.py:507] global step 7528: loss = 0.2331 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7529: loss = 0.0642 (0.198 sec/step)\n",
            "I0601 12:15:47.856829 140438660523904 learning.py:507] global step 7529: loss = 0.0642 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 7530: loss = 0.0214 (0.146 sec/step)\n",
            "I0601 12:15:48.003887 140438660523904 learning.py:507] global step 7530: loss = 0.0214 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 7531: loss = 0.0328 (0.174 sec/step)\n",
            "I0601 12:15:48.179650 140438660523904 learning.py:507] global step 7531: loss = 0.0328 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7532: loss = 0.0428 (0.172 sec/step)\n",
            "I0601 12:15:48.352649 140438660523904 learning.py:507] global step 7532: loss = 0.0428 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7533: loss = 0.0210 (0.178 sec/step)\n",
            "I0601 12:15:48.531790 140438660523904 learning.py:507] global step 7533: loss = 0.0210 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7534: loss = 0.2670 (0.171 sec/step)\n",
            "I0601 12:15:48.703847 140438660523904 learning.py:507] global step 7534: loss = 0.2670 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7535: loss = 0.0380 (0.179 sec/step)\n",
            "I0601 12:15:48.884599 140438660523904 learning.py:507] global step 7535: loss = 0.0380 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7536: loss = 0.0602 (0.171 sec/step)\n",
            "I0601 12:15:49.057188 140438660523904 learning.py:507] global step 7536: loss = 0.0602 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7537: loss = 0.0946 (0.178 sec/step)\n",
            "I0601 12:15:49.237272 140438660523904 learning.py:507] global step 7537: loss = 0.0946 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7538: loss = 0.1192 (0.172 sec/step)\n",
            "I0601 12:15:49.410103 140438660523904 learning.py:507] global step 7538: loss = 0.1192 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7539: loss = 0.3053 (0.188 sec/step)\n",
            "I0601 12:15:49.599731 140438660523904 learning.py:507] global step 7539: loss = 0.3053 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7540: loss = 0.1111 (0.185 sec/step)\n",
            "I0601 12:15:49.786646 140438660523904 learning.py:507] global step 7540: loss = 0.1111 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7541: loss = 0.1775 (0.161 sec/step)\n",
            "I0601 12:15:49.949599 140438660523904 learning.py:507] global step 7541: loss = 0.1775 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7542: loss = 0.1043 (0.185 sec/step)\n",
            "I0601 12:15:50.135522 140438660523904 learning.py:507] global step 7542: loss = 0.1043 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7543: loss = 0.2168 (0.175 sec/step)\n",
            "I0601 12:15:50.311888 140438660523904 learning.py:507] global step 7543: loss = 0.2168 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7544: loss = 0.3565 (0.197 sec/step)\n",
            "I0601 12:15:50.510525 140438660523904 learning.py:507] global step 7544: loss = 0.3565 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 7545: loss = 0.5157 (0.178 sec/step)\n",
            "I0601 12:15:50.690028 140438660523904 learning.py:507] global step 7545: loss = 0.5157 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7546: loss = 0.1212 (0.176 sec/step)\n",
            "I0601 12:15:50.867368 140438660523904 learning.py:507] global step 7546: loss = 0.1212 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7547: loss = 0.0397 (0.160 sec/step)\n",
            "I0601 12:15:51.028509 140438660523904 learning.py:507] global step 7547: loss = 0.0397 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7548: loss = 0.5905 (0.175 sec/step)\n",
            "I0601 12:15:51.204833 140438660523904 learning.py:507] global step 7548: loss = 0.5905 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7549: loss = 0.0255 (0.194 sec/step)\n",
            "I0601 12:15:51.400417 140438660523904 learning.py:507] global step 7549: loss = 0.0255 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 7550: loss = 0.0970 (0.182 sec/step)\n",
            "I0601 12:15:51.583589 140438660523904 learning.py:507] global step 7550: loss = 0.0970 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7551: loss = 0.1165 (0.184 sec/step)\n",
            "I0601 12:15:51.769295 140438660523904 learning.py:507] global step 7551: loss = 0.1165 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7552: loss = 0.1779 (0.212 sec/step)\n",
            "I0601 12:15:51.982900 140438660523904 learning.py:507] global step 7552: loss = 0.1779 (0.212 sec/step)\n",
            "INFO:tensorflow:global step 7553: loss = 0.1674 (0.175 sec/step)\n",
            "I0601 12:15:52.159795 140438660523904 learning.py:507] global step 7553: loss = 0.1674 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7554: loss = 0.1139 (0.182 sec/step)\n",
            "I0601 12:15:52.343153 140438660523904 learning.py:507] global step 7554: loss = 0.1139 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7555: loss = 0.1098 (0.191 sec/step)\n",
            "I0601 12:15:52.535510 140438660523904 learning.py:507] global step 7555: loss = 0.1098 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 7556: loss = 0.2584 (0.163 sec/step)\n",
            "I0601 12:15:52.699600 140438660523904 learning.py:507] global step 7556: loss = 0.2584 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7557: loss = 0.0419 (0.170 sec/step)\n",
            "I0601 12:15:52.871142 140438660523904 learning.py:507] global step 7557: loss = 0.0419 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7558: loss = 0.1628 (0.182 sec/step)\n",
            "I0601 12:15:53.055945 140438660523904 learning.py:507] global step 7558: loss = 0.1628 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7559: loss = 0.0862 (0.176 sec/step)\n",
            "I0601 12:15:53.233129 140438660523904 learning.py:507] global step 7559: loss = 0.0862 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7560: loss = 0.3125 (0.193 sec/step)\n",
            "I0601 12:15:53.427674 140438660523904 learning.py:507] global step 7560: loss = 0.3125 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7561: loss = 0.4149 (0.169 sec/step)\n",
            "I0601 12:15:53.598839 140438660523904 learning.py:507] global step 7561: loss = 0.4149 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7562: loss = 0.0282 (0.155 sec/step)\n",
            "I0601 12:15:53.755822 140438660523904 learning.py:507] global step 7562: loss = 0.0282 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7563: loss = 0.1609 (0.219 sec/step)\n",
            "I0601 12:15:53.976497 140438660523904 learning.py:507] global step 7563: loss = 0.1609 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 7564: loss = 0.0482 (0.185 sec/step)\n",
            "I0601 12:15:54.162436 140438660523904 learning.py:507] global step 7564: loss = 0.0482 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7565: loss = 0.1578 (0.171 sec/step)\n",
            "I0601 12:15:54.335033 140438660523904 learning.py:507] global step 7565: loss = 0.1578 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7566: loss = 0.1538 (0.164 sec/step)\n",
            "I0601 12:15:54.500493 140438660523904 learning.py:507] global step 7566: loss = 0.1538 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7567: loss = 0.5554 (0.166 sec/step)\n",
            "I0601 12:15:54.667976 140438660523904 learning.py:507] global step 7567: loss = 0.5554 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7568: loss = 0.1004 (0.160 sec/step)\n",
            "I0601 12:15:54.829060 140438660523904 learning.py:507] global step 7568: loss = 0.1004 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7569: loss = 0.0911 (0.203 sec/step)\n",
            "I0601 12:15:55.033760 140438660523904 learning.py:507] global step 7569: loss = 0.0911 (0.203 sec/step)\n",
            "INFO:tensorflow:global step 7570: loss = 0.1523 (0.169 sec/step)\n",
            "I0601 12:15:55.204225 140438660523904 learning.py:507] global step 7570: loss = 0.1523 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7571: loss = 0.1571 (0.166 sec/step)\n",
            "I0601 12:15:55.372075 140438660523904 learning.py:507] global step 7571: loss = 0.1571 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7572: loss = 0.1061 (0.157 sec/step)\n",
            "I0601 12:15:55.530719 140438660523904 learning.py:507] global step 7572: loss = 0.1061 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7573: loss = 0.2594 (0.183 sec/step)\n",
            "I0601 12:15:55.715712 140438660523904 learning.py:507] global step 7573: loss = 0.2594 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7574: loss = 0.1326 (0.167 sec/step)\n",
            "I0601 12:15:55.884240 140438660523904 learning.py:507] global step 7574: loss = 0.1326 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7575: loss = 0.1087 (0.213 sec/step)\n",
            "I0601 12:15:56.098527 140438660523904 learning.py:507] global step 7575: loss = 0.1087 (0.213 sec/step)\n",
            "INFO:tensorflow:global step 7576: loss = 0.0386 (0.173 sec/step)\n",
            "I0601 12:15:56.272581 140438660523904 learning.py:507] global step 7576: loss = 0.0386 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7577: loss = 0.2895 (0.167 sec/step)\n",
            "I0601 12:15:56.440643 140438660523904 learning.py:507] global step 7577: loss = 0.2895 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7578: loss = 0.2494 (0.206 sec/step)\n",
            "I0601 12:15:56.647686 140438660523904 learning.py:507] global step 7578: loss = 0.2494 (0.206 sec/step)\n",
            "INFO:tensorflow:global step 7579: loss = 0.0999 (0.183 sec/step)\n",
            "I0601 12:15:56.832143 140438660523904 learning.py:507] global step 7579: loss = 0.0999 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7580: loss = 0.1747 (0.170 sec/step)\n",
            "I0601 12:15:57.003504 140438660523904 learning.py:507] global step 7580: loss = 0.1747 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7581: loss = 0.0494 (0.215 sec/step)\n",
            "I0601 12:15:57.219733 140438660523904 learning.py:507] global step 7581: loss = 0.0494 (0.215 sec/step)\n",
            "INFO:tensorflow:global step 7582: loss = 0.0172 (0.148 sec/step)\n",
            "I0601 12:15:57.369748 140438660523904 learning.py:507] global step 7582: loss = 0.0172 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 7583: loss = 0.0259 (0.171 sec/step)\n",
            "I0601 12:15:57.542334 140438660523904 learning.py:507] global step 7583: loss = 0.0259 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7584: loss = 0.0626 (0.156 sec/step)\n",
            "I0601 12:15:57.700992 140438660523904 learning.py:507] global step 7584: loss = 0.0626 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7585: loss = 0.1392 (0.180 sec/step)\n",
            "I0601 12:15:57.882834 140438660523904 learning.py:507] global step 7585: loss = 0.1392 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7586: loss = 0.1651 (0.173 sec/step)\n",
            "I0601 12:15:58.056820 140438660523904 learning.py:507] global step 7586: loss = 0.1651 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7587: loss = 0.3266 (0.181 sec/step)\n",
            "I0601 12:15:58.239355 140438660523904 learning.py:507] global step 7587: loss = 0.3266 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7588: loss = 0.2804 (0.165 sec/step)\n",
            "I0601 12:15:58.406199 140438660523904 learning.py:507] global step 7588: loss = 0.2804 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7589: loss = 0.0398 (0.161 sec/step)\n",
            "I0601 12:15:58.568754 140438660523904 learning.py:507] global step 7589: loss = 0.0398 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7590: loss = 0.2598 (0.189 sec/step)\n",
            "I0601 12:15:58.758617 140438660523904 learning.py:507] global step 7590: loss = 0.2598 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 7591: loss = 0.0477 (0.180 sec/step)\n",
            "I0601 12:15:58.940319 140438660523904 learning.py:507] global step 7591: loss = 0.0477 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7592: loss = 0.2357 (0.177 sec/step)\n",
            "I0601 12:15:59.119119 140438660523904 learning.py:507] global step 7592: loss = 0.2357 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7593: loss = 0.3738 (0.192 sec/step)\n",
            "I0601 12:15:59.312166 140438660523904 learning.py:507] global step 7593: loss = 0.3738 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 7594: loss = 0.1428 (0.156 sec/step)\n",
            "I0601 12:15:59.469588 140438660523904 learning.py:507] global step 7594: loss = 0.1428 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7595: loss = 0.0807 (0.189 sec/step)\n",
            "I0601 12:15:59.660487 140438660523904 learning.py:507] global step 7595: loss = 0.0807 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 7596: loss = 0.1610 (0.175 sec/step)\n",
            "I0601 12:15:59.836404 140438660523904 learning.py:507] global step 7596: loss = 0.1610 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7597: loss = 0.1171 (0.158 sec/step)\n",
            "I0601 12:15:59.995502 140438660523904 learning.py:507] global step 7597: loss = 0.1171 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7598: loss = 0.0218 (0.170 sec/step)\n",
            "I0601 12:16:00.166744 140438660523904 learning.py:507] global step 7598: loss = 0.0218 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7599: loss = 0.1146 (0.181 sec/step)\n",
            "I0601 12:16:00.350072 140438660523904 learning.py:507] global step 7599: loss = 0.1146 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7600: loss = 0.0577 (0.160 sec/step)\n",
            "I0601 12:16:00.512014 140438660523904 learning.py:507] global step 7600: loss = 0.0577 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7601: loss = 0.1665 (0.149 sec/step)\n",
            "I0601 12:16:00.662834 140438660523904 learning.py:507] global step 7601: loss = 0.1665 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 7602: loss = 0.2734 (0.177 sec/step)\n",
            "I0601 12:16:00.841584 140438660523904 learning.py:507] global step 7602: loss = 0.2734 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7603: loss = 0.1633 (0.141 sec/step)\n",
            "I0601 12:16:00.983657 140438660523904 learning.py:507] global step 7603: loss = 0.1633 (0.141 sec/step)\n",
            "INFO:tensorflow:global step 7604: loss = 0.0359 (0.165 sec/step)\n",
            "I0601 12:16:01.150048 140438660523904 learning.py:507] global step 7604: loss = 0.0359 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7605: loss = 0.2471 (0.181 sec/step)\n",
            "I0601 12:16:01.331982 140438660523904 learning.py:507] global step 7605: loss = 0.2471 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7606: loss = 0.1256 (0.191 sec/step)\n",
            "I0601 12:16:01.524316 140438660523904 learning.py:507] global step 7606: loss = 0.1256 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 7607: loss = 0.2616 (0.190 sec/step)\n",
            "I0601 12:16:01.715765 140438660523904 learning.py:507] global step 7607: loss = 0.2616 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 7608: loss = 0.1513 (0.175 sec/step)\n",
            "I0601 12:16:01.891697 140438660523904 learning.py:507] global step 7608: loss = 0.1513 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7609: loss = 0.0211 (0.160 sec/step)\n",
            "I0601 12:16:02.053061 140438660523904 learning.py:507] global step 7609: loss = 0.0211 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7610: loss = 0.0571 (0.177 sec/step)\n",
            "I0601 12:16:02.231278 140438660523904 learning.py:507] global step 7610: loss = 0.0571 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7611: loss = 0.1062 (0.182 sec/step)\n",
            "I0601 12:16:02.414624 140438660523904 learning.py:507] global step 7611: loss = 0.1062 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7612: loss = 0.2100 (0.183 sec/step)\n",
            "I0601 12:16:02.599070 140438660523904 learning.py:507] global step 7612: loss = 0.2100 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7613: loss = 0.5265 (0.169 sec/step)\n",
            "I0601 12:16:02.769866 140438660523904 learning.py:507] global step 7613: loss = 0.5265 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7614: loss = 0.1267 (0.205 sec/step)\n",
            "I0601 12:16:02.976309 140438660523904 learning.py:507] global step 7614: loss = 0.1267 (0.205 sec/step)\n",
            "INFO:tensorflow:global step 7615: loss = 0.0241 (0.170 sec/step)\n",
            "I0601 12:16:03.147623 140438660523904 learning.py:507] global step 7615: loss = 0.0241 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7616: loss = 0.2271 (0.172 sec/step)\n",
            "I0601 12:16:03.320937 140438660523904 learning.py:507] global step 7616: loss = 0.2271 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7617: loss = 0.3325 (0.161 sec/step)\n",
            "I0601 12:16:03.482748 140438660523904 learning.py:507] global step 7617: loss = 0.3325 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7618: loss = 0.0713 (0.204 sec/step)\n",
            "I0601 12:16:03.688434 140438660523904 learning.py:507] global step 7618: loss = 0.0713 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 7619: loss = 0.1789 (0.171 sec/step)\n",
            "I0601 12:16:03.860633 140438660523904 learning.py:507] global step 7619: loss = 0.1789 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7620: loss = 0.3815 (0.182 sec/step)\n",
            "I0601 12:16:04.044161 140438660523904 learning.py:507] global step 7620: loss = 0.3815 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7621: loss = 0.5019 (0.164 sec/step)\n",
            "I0601 12:16:04.209903 140438660523904 learning.py:507] global step 7621: loss = 0.5019 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7622: loss = 0.0717 (0.154 sec/step)\n",
            "I0601 12:16:04.365331 140438660523904 learning.py:507] global step 7622: loss = 0.0717 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 7623: loss = 0.1846 (0.158 sec/step)\n",
            "I0601 12:16:04.524828 140438660523904 learning.py:507] global step 7623: loss = 0.1846 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7624: loss = 0.0717 (0.169 sec/step)\n",
            "I0601 12:16:04.695526 140438660523904 learning.py:507] global step 7624: loss = 0.0717 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7625: loss = 0.1892 (0.177 sec/step)\n",
            "I0601 12:16:04.873854 140438660523904 learning.py:507] global step 7625: loss = 0.1892 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7626: loss = 0.2536 (0.156 sec/step)\n",
            "I0601 12:16:05.031486 140438660523904 learning.py:507] global step 7626: loss = 0.2536 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7627: loss = 0.1314 (0.170 sec/step)\n",
            "I0601 12:16:05.202875 140438660523904 learning.py:507] global step 7627: loss = 0.1314 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7628: loss = 0.2775 (0.166 sec/step)\n",
            "I0601 12:16:05.370305 140438660523904 learning.py:507] global step 7628: loss = 0.2775 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7629: loss = 0.2578 (0.190 sec/step)\n",
            "I0601 12:16:05.561573 140438660523904 learning.py:507] global step 7629: loss = 0.2578 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 7630: loss = 0.1620 (0.177 sec/step)\n",
            "I0601 12:16:05.740321 140438660523904 learning.py:507] global step 7630: loss = 0.1620 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7631: loss = 0.1151 (0.186 sec/step)\n",
            "I0601 12:16:05.927363 140438660523904 learning.py:507] global step 7631: loss = 0.1151 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7632: loss = 0.3441 (0.183 sec/step)\n",
            "I0601 12:16:06.111670 140438660523904 learning.py:507] global step 7632: loss = 0.3441 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7633: loss = 0.1279 (0.146 sec/step)\n",
            "I0601 12:16:06.259677 140438660523904 learning.py:507] global step 7633: loss = 0.1279 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 7634: loss = 0.6500 (0.178 sec/step)\n",
            "I0601 12:16:06.439504 140438660523904 learning.py:507] global step 7634: loss = 0.6500 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7635: loss = 0.1099 (0.165 sec/step)\n",
            "I0601 12:16:06.606018 140438660523904 learning.py:507] global step 7635: loss = 0.1099 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7636: loss = 0.0956 (0.173 sec/step)\n",
            "I0601 12:16:06.780067 140438660523904 learning.py:507] global step 7636: loss = 0.0956 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7637: loss = 0.3781 (0.166 sec/step)\n",
            "I0601 12:16:06.947315 140438660523904 learning.py:507] global step 7637: loss = 0.3781 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7638: loss = 0.1212 (0.158 sec/step)\n",
            "I0601 12:16:07.107046 140438660523904 learning.py:507] global step 7638: loss = 0.1212 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7639: loss = 0.5131 (0.186 sec/step)\n",
            "I0601 12:16:07.294105 140438660523904 learning.py:507] global step 7639: loss = 0.5131 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7640: loss = 0.2490 (0.180 sec/step)\n",
            "I0601 12:16:07.475594 140438660523904 learning.py:507] global step 7640: loss = 0.2490 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7641: loss = 0.1002 (0.174 sec/step)\n",
            "I0601 12:16:07.650782 140438660523904 learning.py:507] global step 7641: loss = 0.1002 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7642: loss = 0.0587 (0.181 sec/step)\n",
            "I0601 12:16:07.834046 140438660523904 learning.py:507] global step 7642: loss = 0.0587 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7643: loss = 0.2411 (0.168 sec/step)\n",
            "I0601 12:16:08.003500 140438660523904 learning.py:507] global step 7643: loss = 0.2411 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7644: loss = 0.1218 (0.168 sec/step)\n",
            "I0601 12:16:08.173105 140438660523904 learning.py:507] global step 7644: loss = 0.1218 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7645: loss = 0.1074 (0.169 sec/step)\n",
            "I0601 12:16:08.343747 140438660523904 learning.py:507] global step 7645: loss = 0.1074 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7646: loss = 0.1247 (0.173 sec/step)\n",
            "I0601 12:16:08.517728 140438660523904 learning.py:507] global step 7646: loss = 0.1247 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7647: loss = 0.1041 (0.155 sec/step)\n",
            "I0601 12:16:08.674088 140438660523904 learning.py:507] global step 7647: loss = 0.1041 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7648: loss = 0.1221 (0.157 sec/step)\n",
            "I0601 12:16:08.832015 140438660523904 learning.py:507] global step 7648: loss = 0.1221 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7649: loss = 0.1011 (0.185 sec/step)\n",
            "I0601 12:16:09.018334 140438660523904 learning.py:507] global step 7649: loss = 0.1011 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7650: loss = 0.0336 (0.178 sec/step)\n",
            "I0601 12:16:09.197762 140438660523904 learning.py:507] global step 7650: loss = 0.0336 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7651: loss = 0.1149 (0.169 sec/step)\n",
            "I0601 12:16:09.368260 140438660523904 learning.py:507] global step 7651: loss = 0.1149 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7652: loss = 0.0921 (0.162 sec/step)\n",
            "I0601 12:16:09.531632 140438660523904 learning.py:507] global step 7652: loss = 0.0921 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7653: loss = 0.0696 (0.154 sec/step)\n",
            "I0601 12:16:09.686724 140438660523904 learning.py:507] global step 7653: loss = 0.0696 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 7654: loss = 0.2313 (0.168 sec/step)\n",
            "I0601 12:16:09.857575 140438660523904 learning.py:507] global step 7654: loss = 0.2313 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7655: loss = 0.1211 (0.180 sec/step)\n",
            "I0601 12:16:10.039331 140438660523904 learning.py:507] global step 7655: loss = 0.1211 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7656: loss = 0.1541 (0.168 sec/step)\n",
            "I0601 12:16:10.209235 140438660523904 learning.py:507] global step 7656: loss = 0.1541 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7657: loss = 0.3267 (0.155 sec/step)\n",
            "I0601 12:16:10.367275 140438660523904 learning.py:507] global step 7657: loss = 0.3267 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7658: loss = 0.1251 (0.183 sec/step)\n",
            "I0601 12:16:10.552369 140438660523904 learning.py:507] global step 7658: loss = 0.1251 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7659: loss = 0.2767 (0.153 sec/step)\n",
            "I0601 12:16:10.707029 140438660523904 learning.py:507] global step 7659: loss = 0.2767 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 7660: loss = 0.0608 (0.172 sec/step)\n",
            "I0601 12:16:10.882385 140438660523904 learning.py:507] global step 7660: loss = 0.0608 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7661: loss = 0.1928 (0.209 sec/step)\n",
            "I0601 12:16:11.093262 140438660523904 learning.py:507] global step 7661: loss = 0.1928 (0.209 sec/step)\n",
            "INFO:tensorflow:global step 7662: loss = 0.2216 (0.167 sec/step)\n",
            "I0601 12:16:11.261968 140438660523904 learning.py:507] global step 7662: loss = 0.2216 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7663: loss = 0.1735 (0.157 sec/step)\n",
            "I0601 12:16:11.420721 140438660523904 learning.py:507] global step 7663: loss = 0.1735 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7664: loss = 0.1707 (0.150 sec/step)\n",
            "I0601 12:16:11.572637 140438660523904 learning.py:507] global step 7664: loss = 0.1707 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 7665: loss = 0.0730 (0.167 sec/step)\n",
            "I0601 12:16:11.741415 140438660523904 learning.py:507] global step 7665: loss = 0.0730 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7666: loss = 4.4890 (0.169 sec/step)\n",
            "I0601 12:16:11.912048 140438660523904 learning.py:507] global step 7666: loss = 4.4890 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7667: loss = 0.0957 (0.193 sec/step)\n",
            "I0601 12:16:12.106258 140438660523904 learning.py:507] global step 7667: loss = 0.0957 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7668: loss = 0.1740 (0.172 sec/step)\n",
            "I0601 12:16:12.279923 140438660523904 learning.py:507] global step 7668: loss = 0.1740 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7669: loss = 0.3972 (0.165 sec/step)\n",
            "I0601 12:16:12.446117 140438660523904 learning.py:507] global step 7669: loss = 0.3972 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7670: loss = 0.1476 (0.159 sec/step)\n",
            "I0601 12:16:12.606892 140438660523904 learning.py:507] global step 7670: loss = 0.1476 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7671: loss = 0.0666 (0.171 sec/step)\n",
            "I0601 12:16:12.779374 140438660523904 learning.py:507] global step 7671: loss = 0.0666 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7672: loss = 4.4914 (0.185 sec/step)\n",
            "I0601 12:16:12.965465 140438660523904 learning.py:507] global step 7672: loss = 4.4914 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7673: loss = 0.0212 (0.161 sec/step)\n",
            "I0601 12:16:13.127708 140438660523904 learning.py:507] global step 7673: loss = 0.0212 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7674: loss = 0.0207 (0.176 sec/step)\n",
            "I0601 12:16:13.305393 140438660523904 learning.py:507] global step 7674: loss = 0.0207 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7675: loss = 0.1016 (0.171 sec/step)\n",
            "I0601 12:16:13.478210 140438660523904 learning.py:507] global step 7675: loss = 0.1016 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7676: loss = 0.1902 (0.186 sec/step)\n",
            "I0601 12:16:13.665524 140438660523904 learning.py:507] global step 7676: loss = 0.1902 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7677: loss = 0.0982 (0.179 sec/step)\n",
            "I0601 12:16:13.846262 140438660523904 learning.py:507] global step 7677: loss = 0.0982 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7678: loss = 0.1557 (0.180 sec/step)\n",
            "I0601 12:16:14.027882 140438660523904 learning.py:507] global step 7678: loss = 0.1557 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7679: loss = 0.0917 (0.175 sec/step)\n",
            "I0601 12:16:14.204433 140438660523904 learning.py:507] global step 7679: loss = 0.0917 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7680: loss = 0.2910 (0.176 sec/step)\n",
            "I0601 12:16:14.382107 140438660523904 learning.py:507] global step 7680: loss = 0.2910 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7681: loss = 0.2046 (0.167 sec/step)\n",
            "I0601 12:16:14.550139 140438660523904 learning.py:507] global step 7681: loss = 0.2046 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7682: loss = 0.0899 (0.187 sec/step)\n",
            "I0601 12:16:14.738585 140438660523904 learning.py:507] global step 7682: loss = 0.0899 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7683: loss = 0.3151 (0.185 sec/step)\n",
            "I0601 12:16:14.925121 140438660523904 learning.py:507] global step 7683: loss = 0.3151 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7684: loss = 0.0983 (0.179 sec/step)\n",
            "I0601 12:16:15.105602 140438660523904 learning.py:507] global step 7684: loss = 0.0983 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7685: loss = 0.2101 (0.169 sec/step)\n",
            "I0601 12:16:15.275840 140438660523904 learning.py:507] global step 7685: loss = 0.2101 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7686: loss = 0.0719 (0.184 sec/step)\n",
            "I0601 12:16:15.461579 140438660523904 learning.py:507] global step 7686: loss = 0.0719 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7687: loss = 0.1361 (0.178 sec/step)\n",
            "I0601 12:16:15.640635 140438660523904 learning.py:507] global step 7687: loss = 0.1361 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7688: loss = 0.0589 (0.147 sec/step)\n",
            "I0601 12:16:15.788811 140438660523904 learning.py:507] global step 7688: loss = 0.0589 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 7689: loss = 0.1883 (0.179 sec/step)\n",
            "I0601 12:16:15.969473 140438660523904 learning.py:507] global step 7689: loss = 0.1883 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7690: loss = 0.1098 (0.164 sec/step)\n",
            "I0601 12:16:16.134709 140438660523904 learning.py:507] global step 7690: loss = 0.1098 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7691: loss = 0.0904 (0.189 sec/step)\n",
            "I0601 12:16:16.324699 140438660523904 learning.py:507] global step 7691: loss = 0.0904 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 7692: loss = 0.1682 (0.170 sec/step)\n",
            "I0601 12:16:16.496356 140438660523904 learning.py:507] global step 7692: loss = 0.1682 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7693: loss = 0.3925 (0.176 sec/step)\n",
            "I0601 12:16:16.673748 140438660523904 learning.py:507] global step 7693: loss = 0.3925 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7694: loss = 0.2727 (0.159 sec/step)\n",
            "I0601 12:16:16.834427 140438660523904 learning.py:507] global step 7694: loss = 0.2727 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7695: loss = 0.1491 (0.175 sec/step)\n",
            "I0601 12:16:17.010843 140438660523904 learning.py:507] global step 7695: loss = 0.1491 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7696: loss = 0.0967 (0.174 sec/step)\n",
            "I0601 12:16:17.186579 140438660523904 learning.py:507] global step 7696: loss = 0.0967 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7697: loss = 0.0624 (0.170 sec/step)\n",
            "I0601 12:16:17.359686 140438660523904 learning.py:507] global step 7697: loss = 0.0624 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7698: loss = 0.2682 (0.169 sec/step)\n",
            "I0601 12:16:17.530012 140438660523904 learning.py:507] global step 7698: loss = 0.2682 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7699: loss = 0.0971 (0.176 sec/step)\n",
            "I0601 12:16:17.707278 140438660523904 learning.py:507] global step 7699: loss = 0.0971 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7700: loss = 0.1608 (0.160 sec/step)\n",
            "I0601 12:16:17.868726 140438660523904 learning.py:507] global step 7700: loss = 0.1608 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7701: loss = 0.1057 (0.188 sec/step)\n",
            "I0601 12:16:18.057684 140438660523904 learning.py:507] global step 7701: loss = 0.1057 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7702: loss = 0.0742 (0.192 sec/step)\n",
            "I0601 12:16:18.250817 140438660523904 learning.py:507] global step 7702: loss = 0.0742 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 7703: loss = 0.0540 (0.160 sec/step)\n",
            "I0601 12:16:18.412073 140438660523904 learning.py:507] global step 7703: loss = 0.0540 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7704: loss = 0.2111 (0.169 sec/step)\n",
            "I0601 12:16:18.583057 140438660523904 learning.py:507] global step 7704: loss = 0.2111 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7705: loss = 0.1945 (0.170 sec/step)\n",
            "I0601 12:16:18.754872 140438660523904 learning.py:507] global step 7705: loss = 0.1945 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7706: loss = 0.0972 (0.156 sec/step)\n",
            "I0601 12:16:18.912209 140438660523904 learning.py:507] global step 7706: loss = 0.0972 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7707: loss = 0.0232 (0.193 sec/step)\n",
            "I0601 12:16:19.106351 140438660523904 learning.py:507] global step 7707: loss = 0.0232 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7708: loss = 0.2233 (0.163 sec/step)\n",
            "I0601 12:16:19.271179 140438660523904 learning.py:507] global step 7708: loss = 0.2233 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7709: loss = 0.2712 (0.174 sec/step)\n",
            "I0601 12:16:19.446843 140438660523904 learning.py:507] global step 7709: loss = 0.2712 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7710: loss = 0.2691 (0.168 sec/step)\n",
            "I0601 12:16:19.616064 140438660523904 learning.py:507] global step 7710: loss = 0.2691 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7711: loss = 0.0172 (0.179 sec/step)\n",
            "I0601 12:16:19.796593 140438660523904 learning.py:507] global step 7711: loss = 0.0172 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7712: loss = 0.3779 (0.173 sec/step)\n",
            "I0601 12:16:19.971368 140438660523904 learning.py:507] global step 7712: loss = 0.3779 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7713: loss = 0.0881 (0.196 sec/step)\n",
            "I0601 12:16:20.169009 140438660523904 learning.py:507] global step 7713: loss = 0.0881 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 7714: loss = 0.1200 (0.150 sec/step)\n",
            "I0601 12:16:20.320614 140438660523904 learning.py:507] global step 7714: loss = 0.1200 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 7715: loss = 0.0597 (0.169 sec/step)\n",
            "I0601 12:16:20.490669 140438660523904 learning.py:507] global step 7715: loss = 0.0597 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7716: loss = 0.0849 (0.158 sec/step)\n",
            "I0601 12:16:20.650823 140438660523904 learning.py:507] global step 7716: loss = 0.0849 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7717: loss = 0.0714 (0.174 sec/step)\n",
            "I0601 12:16:20.826088 140438660523904 learning.py:507] global step 7717: loss = 0.0714 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7718: loss = 0.0506 (0.144 sec/step)\n",
            "I0601 12:16:20.971935 140438660523904 learning.py:507] global step 7718: loss = 0.0506 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 7719: loss = 0.0714 (0.173 sec/step)\n",
            "I0601 12:16:21.146066 140438660523904 learning.py:507] global step 7719: loss = 0.0714 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7720: loss = 0.0597 (0.137 sec/step)\n",
            "I0601 12:16:21.284577 140438660523904 learning.py:507] global step 7720: loss = 0.0597 (0.137 sec/step)\n",
            "INFO:tensorflow:global step 7721: loss = 0.2504 (0.181 sec/step)\n",
            "I0601 12:16:21.466680 140438660523904 learning.py:507] global step 7721: loss = 0.2504 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7722: loss = 0.3571 (0.191 sec/step)\n",
            "I0601 12:16:21.658796 140438660523904 learning.py:507] global step 7722: loss = 0.3571 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 7723: loss = 0.0557 (0.142 sec/step)\n",
            "I0601 12:16:21.801825 140438660523904 learning.py:507] global step 7723: loss = 0.0557 (0.142 sec/step)\n",
            "INFO:tensorflow:global step 7724: loss = 0.2971 (0.179 sec/step)\n",
            "I0601 12:16:21.982208 140438660523904 learning.py:507] global step 7724: loss = 0.2971 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7725: loss = 0.0559 (0.161 sec/step)\n",
            "I0601 12:16:22.145097 140438660523904 learning.py:507] global step 7725: loss = 0.0559 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7726: loss = 0.1847 (0.157 sec/step)\n",
            "I0601 12:16:22.304089 140438660523904 learning.py:507] global step 7726: loss = 0.1847 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7727: loss = 0.0741 (0.157 sec/step)\n",
            "I0601 12:16:22.462230 140438660523904 learning.py:507] global step 7727: loss = 0.0741 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7728: loss = 0.0245 (0.176 sec/step)\n",
            "I0601 12:16:22.639980 140438660523904 learning.py:507] global step 7728: loss = 0.0245 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7729: loss = 0.0596 (0.165 sec/step)\n",
            "I0601 12:16:22.806257 140438660523904 learning.py:507] global step 7729: loss = 0.0596 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7730: loss = 0.1759 (0.192 sec/step)\n",
            "I0601 12:16:22.999231 140438660523904 learning.py:507] global step 7730: loss = 0.1759 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 7731: loss = 0.0585 (0.166 sec/step)\n",
            "I0601 12:16:23.167004 140438660523904 learning.py:507] global step 7731: loss = 0.0585 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7732: loss = 0.1832 (0.189 sec/step)\n",
            "I0601 12:16:23.357327 140438660523904 learning.py:507] global step 7732: loss = 0.1832 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 7733: loss = 0.2063 (0.173 sec/step)\n",
            "I0601 12:16:23.531506 140438660523904 learning.py:507] global step 7733: loss = 0.2063 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7734: loss = 0.1682 (0.164 sec/step)\n",
            "I0601 12:16:23.696553 140438660523904 learning.py:507] global step 7734: loss = 0.1682 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7735: loss = 0.1974 (0.183 sec/step)\n",
            "I0601 12:16:23.880829 140438660523904 learning.py:507] global step 7735: loss = 0.1974 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7736: loss = 0.2074 (0.188 sec/step)\n",
            "I0601 12:16:24.069866 140438660523904 learning.py:507] global step 7736: loss = 0.2074 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7737: loss = 0.0526 (0.172 sec/step)\n",
            "I0601 12:16:24.243688 140438660523904 learning.py:507] global step 7737: loss = 0.0526 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7738: loss = 0.0887 (0.164 sec/step)\n",
            "I0601 12:16:24.409243 140438660523904 learning.py:507] global step 7738: loss = 0.0887 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7739: loss = 0.1716 (0.173 sec/step)\n",
            "I0601 12:16:24.583096 140438660523904 learning.py:507] global step 7739: loss = 0.1716 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7740: loss = 0.0746 (0.191 sec/step)\n",
            "I0601 12:16:24.775832 140438660523904 learning.py:507] global step 7740: loss = 0.0746 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 7741: loss = 0.3811 (0.162 sec/step)\n",
            "I0601 12:16:24.939356 140438660523904 learning.py:507] global step 7741: loss = 0.3811 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7742: loss = 0.2012 (0.190 sec/step)\n",
            "I0601 12:16:25.130379 140438660523904 learning.py:507] global step 7742: loss = 0.2012 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 7743: loss = 0.1244 (0.168 sec/step)\n",
            "I0601 12:16:25.300198 140438660523904 learning.py:507] global step 7743: loss = 0.1244 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7744: loss = 0.1328 (0.184 sec/step)\n",
            "I0601 12:16:25.485752 140438660523904 learning.py:507] global step 7744: loss = 0.1328 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7745: loss = 4.3094 (0.179 sec/step)\n",
            "I0601 12:16:25.666541 140438660523904 learning.py:507] global step 7745: loss = 4.3094 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7746: loss = 0.3398 (0.175 sec/step)\n",
            "I0601 12:16:25.842649 140438660523904 learning.py:507] global step 7746: loss = 0.3398 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7747: loss = 0.1385 (0.166 sec/step)\n",
            "I0601 12:16:26.010197 140438660523904 learning.py:507] global step 7747: loss = 0.1385 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7748: loss = 0.2941 (0.173 sec/step)\n",
            "I0601 12:16:26.185009 140438660523904 learning.py:507] global step 7748: loss = 0.2941 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7749: loss = 0.1386 (0.178 sec/step)\n",
            "I0601 12:16:26.364958 140438660523904 learning.py:507] global step 7749: loss = 0.1386 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7750: loss = 0.1804 (0.188 sec/step)\n",
            "I0601 12:16:26.554172 140438660523904 learning.py:507] global step 7750: loss = 0.1804 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7751: loss = 0.1432 (0.186 sec/step)\n",
            "I0601 12:16:26.741264 140438660523904 learning.py:507] global step 7751: loss = 0.1432 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7752: loss = 0.0390 (0.149 sec/step)\n",
            "I0601 12:16:26.891607 140438660523904 learning.py:507] global step 7752: loss = 0.0390 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 7753: loss = 0.1244 (0.184 sec/step)\n",
            "I0601 12:16:27.076768 140438660523904 learning.py:507] global step 7753: loss = 0.1244 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7754: loss = 0.3226 (0.169 sec/step)\n",
            "I0601 12:16:27.246641 140438660523904 learning.py:507] global step 7754: loss = 0.3226 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7755: loss = 0.0890 (0.177 sec/step)\n",
            "I0601 12:16:27.425340 140438660523904 learning.py:507] global step 7755: loss = 0.0890 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7756: loss = 0.0552 (0.140 sec/step)\n",
            "I0601 12:16:27.566459 140438660523904 learning.py:507] global step 7756: loss = 0.0552 (0.140 sec/step)\n",
            "INFO:tensorflow:global step 7757: loss = 0.0621 (0.198 sec/step)\n",
            "I0601 12:16:27.765547 140438660523904 learning.py:507] global step 7757: loss = 0.0621 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 7758: loss = 0.0624 (0.163 sec/step)\n",
            "I0601 12:16:27.930427 140438660523904 learning.py:507] global step 7758: loss = 0.0624 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7759: loss = 0.2399 (0.173 sec/step)\n",
            "I0601 12:16:28.105489 140438660523904 learning.py:507] global step 7759: loss = 0.2399 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7760: loss = 0.1411 (0.187 sec/step)\n",
            "I0601 12:16:28.294323 140438660523904 learning.py:507] global step 7760: loss = 0.1411 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7761: loss = 4.6045 (0.172 sec/step)\n",
            "I0601 12:16:28.467481 140438660523904 learning.py:507] global step 7761: loss = 4.6045 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7762: loss = 0.0263 (0.171 sec/step)\n",
            "I0601 12:16:28.640367 140438660523904 learning.py:507] global step 7762: loss = 0.0263 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7763: loss = 0.0688 (0.166 sec/step)\n",
            "I0601 12:16:28.807570 140438660523904 learning.py:507] global step 7763: loss = 0.0688 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7764: loss = 0.1188 (0.158 sec/step)\n",
            "I0601 12:16:28.966820 140438660523904 learning.py:507] global step 7764: loss = 0.1188 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7765: loss = 0.1969 (0.194 sec/step)\n",
            "I0601 12:16:29.161916 140438660523904 learning.py:507] global step 7765: loss = 0.1969 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 7766: loss = 0.1128 (0.181 sec/step)\n",
            "I0601 12:16:29.344416 140438660523904 learning.py:507] global step 7766: loss = 0.1128 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7767: loss = 0.1458 (0.167 sec/step)\n",
            "I0601 12:16:29.512409 140438660523904 learning.py:507] global step 7767: loss = 0.1458 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7768: loss = 0.1441 (0.172 sec/step)\n",
            "I0601 12:16:29.685847 140438660523904 learning.py:507] global step 7768: loss = 0.1441 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7769: loss = 0.4677 (0.159 sec/step)\n",
            "I0601 12:16:29.846730 140438660523904 learning.py:507] global step 7769: loss = 0.4677 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7770: loss = 0.1751 (0.170 sec/step)\n",
            "I0601 12:16:30.018174 140438660523904 learning.py:507] global step 7770: loss = 0.1751 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7771: loss = 0.1447 (0.157 sec/step)\n",
            "I0601 12:16:30.176639 140438660523904 learning.py:507] global step 7771: loss = 0.1447 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7772: loss = 0.2035 (0.167 sec/step)\n",
            "I0601 12:16:30.345615 140438660523904 learning.py:507] global step 7772: loss = 0.2035 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7773: loss = 0.1052 (0.177 sec/step)\n",
            "I0601 12:16:30.523632 140438660523904 learning.py:507] global step 7773: loss = 0.1052 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7774: loss = 0.0969 (0.182 sec/step)\n",
            "I0601 12:16:30.707616 140438660523904 learning.py:507] global step 7774: loss = 0.0969 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7775: loss = 0.1421 (0.168 sec/step)\n",
            "I0601 12:16:30.877589 140438660523904 learning.py:507] global step 7775: loss = 0.1421 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7776: loss = 0.0544 (0.185 sec/step)\n",
            "I0601 12:16:31.064545 140438660523904 learning.py:507] global step 7776: loss = 0.0544 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7777: loss = 0.2783 (0.164 sec/step)\n",
            "I0601 12:16:31.230118 140438660523904 learning.py:507] global step 7777: loss = 0.2783 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7778: loss = 0.0964 (0.166 sec/step)\n",
            "I0601 12:16:31.397338 140438660523904 learning.py:507] global step 7778: loss = 0.0964 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7779: loss = 0.1171 (0.176 sec/step)\n",
            "I0601 12:16:31.574804 140438660523904 learning.py:507] global step 7779: loss = 0.1171 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7780: loss = 0.0422 (0.160 sec/step)\n",
            "I0601 12:16:31.735953 140438660523904 learning.py:507] global step 7780: loss = 0.0422 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7781: loss = 0.3584 (0.177 sec/step)\n",
            "I0601 12:16:31.913948 140438660523904 learning.py:507] global step 7781: loss = 0.3584 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7782: loss = 0.0995 (0.193 sec/step)\n",
            "I0601 12:16:32.108353 140438660523904 learning.py:507] global step 7782: loss = 0.0995 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7783: loss = 0.1196 (0.179 sec/step)\n",
            "I0601 12:16:32.288957 140438660523904 learning.py:507] global step 7783: loss = 0.1196 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7784: loss = 0.1609 (0.170 sec/step)\n",
            "I0601 12:16:32.460436 140438660523904 learning.py:507] global step 7784: loss = 0.1609 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7785: loss = 0.1438 (0.168 sec/step)\n",
            "I0601 12:16:32.630441 140438660523904 learning.py:507] global step 7785: loss = 0.1438 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7786: loss = 0.0399 (0.166 sec/step)\n",
            "I0601 12:16:32.798299 140438660523904 learning.py:507] global step 7786: loss = 0.0399 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7787: loss = 0.1642 (0.197 sec/step)\n",
            "I0601 12:16:32.996778 140438660523904 learning.py:507] global step 7787: loss = 0.1642 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 7788: loss = 0.0598 (0.165 sec/step)\n",
            "I0601 12:16:33.163261 140438660523904 learning.py:507] global step 7788: loss = 0.0598 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7789: loss = 0.0643 (0.160 sec/step)\n",
            "I0601 12:16:33.324567 140438660523904 learning.py:507] global step 7789: loss = 0.0643 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7790: loss = 0.2658 (0.174 sec/step)\n",
            "I0601 12:16:33.499721 140438660523904 learning.py:507] global step 7790: loss = 0.2658 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7791: loss = 0.1222 (0.181 sec/step)\n",
            "I0601 12:16:33.681814 140438660523904 learning.py:507] global step 7791: loss = 0.1222 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7792: loss = 0.0435 (0.157 sec/step)\n",
            "I0601 12:16:33.840475 140438660523904 learning.py:507] global step 7792: loss = 0.0435 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7793: loss = 0.0697 (0.163 sec/step)\n",
            "I0601 12:16:34.004715 140438660523904 learning.py:507] global step 7793: loss = 0.0697 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7794: loss = 0.1167 (0.156 sec/step)\n",
            "I0601 12:16:34.162060 140438660523904 learning.py:507] global step 7794: loss = 0.1167 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7795: loss = 0.2140 (0.183 sec/step)\n",
            "I0601 12:16:34.346207 140438660523904 learning.py:507] global step 7795: loss = 0.2140 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7796: loss = 0.1215 (0.195 sec/step)\n",
            "I0601 12:16:34.542525 140438660523904 learning.py:507] global step 7796: loss = 0.1215 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 7797: loss = 0.2824 (0.176 sec/step)\n",
            "I0601 12:16:34.719556 140438660523904 learning.py:507] global step 7797: loss = 0.2824 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7798: loss = 0.1042 (0.174 sec/step)\n",
            "I0601 12:16:34.895567 140438660523904 learning.py:507] global step 7798: loss = 0.1042 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7799: loss = 0.1332 (0.164 sec/step)\n",
            "I0601 12:16:35.061549 140438660523904 learning.py:507] global step 7799: loss = 0.1332 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7800: loss = 0.1033 (0.168 sec/step)\n",
            "I0601 12:16:35.232082 140438660523904 learning.py:507] global step 7800: loss = 0.1033 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7801: loss = 0.0364 (0.144 sec/step)\n",
            "I0601 12:16:35.379129 140438660523904 learning.py:507] global step 7801: loss = 0.0364 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 7802: loss = 0.1535 (0.185 sec/step)\n",
            "I0601 12:16:35.565296 140438660523904 learning.py:507] global step 7802: loss = 0.1535 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7803: loss = 0.1980 (0.167 sec/step)\n",
            "I0601 12:16:35.733476 140438660523904 learning.py:507] global step 7803: loss = 0.1980 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7804: loss = 0.1173 (0.179 sec/step)\n",
            "I0601 12:16:35.913605 140438660523904 learning.py:507] global step 7804: loss = 0.1173 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7805: loss = 0.0824 (0.185 sec/step)\n",
            "I0601 12:16:36.099608 140438660523904 learning.py:507] global step 7805: loss = 0.0824 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7806: loss = 0.0808 (0.188 sec/step)\n",
            "I0601 12:16:36.289161 140438660523904 learning.py:507] global step 7806: loss = 0.0808 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7807: loss = 0.1494 (0.193 sec/step)\n",
            "I0601 12:16:36.484413 140438660523904 learning.py:507] global step 7807: loss = 0.1494 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7808: loss = 0.0959 (0.165 sec/step)\n",
            "I0601 12:16:36.651439 140438660523904 learning.py:507] global step 7808: loss = 0.0959 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7809: loss = 0.0593 (0.159 sec/step)\n",
            "I0601 12:16:36.811748 140438660523904 learning.py:507] global step 7809: loss = 0.0593 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7810: loss = 0.0657 (0.166 sec/step)\n",
            "I0601 12:16:36.979459 140438660523904 learning.py:507] global step 7810: loss = 0.0657 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7811: loss = 0.1886 (0.184 sec/step)\n",
            "I0601 12:16:37.164932 140438660523904 learning.py:507] global step 7811: loss = 0.1886 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7812: loss = 0.0986 (0.177 sec/step)\n",
            "I0601 12:16:37.343242 140438660523904 learning.py:507] global step 7812: loss = 0.0986 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7813: loss = 0.1029 (0.177 sec/step)\n",
            "I0601 12:16:37.521187 140438660523904 learning.py:507] global step 7813: loss = 0.1029 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7814: loss = 0.1435 (0.197 sec/step)\n",
            "I0601 12:16:37.719149 140438660523904 learning.py:507] global step 7814: loss = 0.1435 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 7815: loss = 0.1379 (0.159 sec/step)\n",
            "I0601 12:16:37.879147 140438660523904 learning.py:507] global step 7815: loss = 0.1379 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7816: loss = 0.1923 (0.178 sec/step)\n",
            "I0601 12:16:38.058323 140438660523904 learning.py:507] global step 7816: loss = 0.1923 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7817: loss = 0.1380 (0.160 sec/step)\n",
            "I0601 12:16:38.219860 140438660523904 learning.py:507] global step 7817: loss = 0.1380 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7818: loss = 0.1731 (0.173 sec/step)\n",
            "I0601 12:16:38.394006 140438660523904 learning.py:507] global step 7818: loss = 0.1731 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7819: loss = 0.0251 (0.168 sec/step)\n",
            "I0601 12:16:38.563276 140438660523904 learning.py:507] global step 7819: loss = 0.0251 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7820: loss = 0.1876 (0.184 sec/step)\n",
            "I0601 12:16:38.748403 140438660523904 learning.py:507] global step 7820: loss = 0.1876 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 7821: loss = 0.0725 (0.180 sec/step)\n",
            "I0601 12:16:38.930278 140438660523904 learning.py:507] global step 7821: loss = 0.0725 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7822: loss = 0.2556 (0.174 sec/step)\n",
            "I0601 12:16:39.105665 140438660523904 learning.py:507] global step 7822: loss = 0.2556 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7823: loss = 0.1800 (0.179 sec/step)\n",
            "I0601 12:16:39.286206 140438660523904 learning.py:507] global step 7823: loss = 0.1800 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7824: loss = 0.0507 (0.136 sec/step)\n",
            "I0601 12:16:39.423709 140438660523904 learning.py:507] global step 7824: loss = 0.0507 (0.136 sec/step)\n",
            "INFO:tensorflow:global step 7825: loss = 0.0360 (0.155 sec/step)\n",
            "I0601 12:16:39.580475 140438660523904 learning.py:507] global step 7825: loss = 0.0360 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7826: loss = 0.0813 (0.157 sec/step)\n",
            "I0601 12:16:39.738649 140438660523904 learning.py:507] global step 7826: loss = 0.0813 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7827: loss = 0.0413 (0.148 sec/step)\n",
            "I0601 12:16:39.888333 140438660523904 learning.py:507] global step 7827: loss = 0.0413 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 7828: loss = 0.2006 (0.157 sec/step)\n",
            "I0601 12:16:40.046821 140438660523904 learning.py:507] global step 7828: loss = 0.2006 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7829: loss = 0.2867 (0.173 sec/step)\n",
            "I0601 12:16:40.220683 140438660523904 learning.py:507] global step 7829: loss = 0.2867 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7830: loss = 0.0587 (0.160 sec/step)\n",
            "I0601 12:16:40.381757 140438660523904 learning.py:507] global step 7830: loss = 0.0587 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7831: loss = 0.0900 (0.169 sec/step)\n",
            "I0601 12:16:40.551864 140438660523904 learning.py:507] global step 7831: loss = 0.0900 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7832: loss = 0.1690 (0.173 sec/step)\n",
            "I0601 12:16:40.726305 140438660523904 learning.py:507] global step 7832: loss = 0.1690 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7833: loss = 0.0606 (0.173 sec/step)\n",
            "I0601 12:16:40.900587 140438660523904 learning.py:507] global step 7833: loss = 0.0606 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7834: loss = 0.0517 (0.175 sec/step)\n",
            "I0601 12:16:41.076947 140438660523904 learning.py:507] global step 7834: loss = 0.0517 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7835: loss = 0.1106 (0.180 sec/step)\n",
            "I0601 12:16:41.258787 140438660523904 learning.py:507] global step 7835: loss = 0.1106 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7836: loss = 0.1460 (0.171 sec/step)\n",
            "I0601 12:16:41.431308 140438660523904 learning.py:507] global step 7836: loss = 0.1460 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7837: loss = 0.0947 (0.171 sec/step)\n",
            "I0601 12:16:41.603607 140438660523904 learning.py:507] global step 7837: loss = 0.0947 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7838: loss = 0.2450 (0.186 sec/step)\n",
            "I0601 12:16:41.791311 140438660523904 learning.py:507] global step 7838: loss = 0.2450 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7839: loss = 0.0276 (0.159 sec/step)\n",
            "I0601 12:16:41.951529 140438660523904 learning.py:507] global step 7839: loss = 0.0276 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7840: loss = 0.2261 (0.193 sec/step)\n",
            "I0601 12:16:42.145570 140438660523904 learning.py:507] global step 7840: loss = 0.2261 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7841: loss = 0.0359 (0.207 sec/step)\n",
            "I0601 12:16:42.353875 140438660523904 learning.py:507] global step 7841: loss = 0.0359 (0.207 sec/step)\n",
            "INFO:tensorflow:global step 7842: loss = 0.0660 (0.167 sec/step)\n",
            "I0601 12:16:42.522498 140438660523904 learning.py:507] global step 7842: loss = 0.0660 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7843: loss = 0.0695 (0.179 sec/step)\n",
            "I0601 12:16:42.703052 140438660523904 learning.py:507] global step 7843: loss = 0.0695 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7844: loss = 0.0612 (0.160 sec/step)\n",
            "I0601 12:16:42.865094 140438660523904 learning.py:507] global step 7844: loss = 0.0612 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7845: loss = 0.0528 (0.198 sec/step)\n",
            "I0601 12:16:43.065091 140438660523904 learning.py:507] global step 7845: loss = 0.0528 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 7846: loss = 4.4173 (0.194 sec/step)\n",
            "I0601 12:16:43.260279 140438660523904 learning.py:507] global step 7846: loss = 4.4173 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 7847: loss = 0.3144 (0.198 sec/step)\n",
            "I0601 12:16:43.460167 140438660523904 learning.py:507] global step 7847: loss = 0.3144 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 7848: loss = 0.0565 (0.152 sec/step)\n",
            "I0601 12:16:43.613832 140438660523904 learning.py:507] global step 7848: loss = 0.0565 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 7849: loss = 0.0787 (0.157 sec/step)\n",
            "I0601 12:16:43.772852 140438660523904 learning.py:507] global step 7849: loss = 0.0787 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7850: loss = 0.0900 (0.176 sec/step)\n",
            "I0601 12:16:43.950376 140438660523904 learning.py:507] global step 7850: loss = 0.0900 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7851: loss = 0.1648 (0.179 sec/step)\n",
            "I0601 12:16:44.130335 140438660523904 learning.py:507] global step 7851: loss = 0.1648 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7852: loss = 0.4080 (0.179 sec/step)\n",
            "I0601 12:16:44.310306 140438660523904 learning.py:507] global step 7852: loss = 0.4080 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7853: loss = 4.2749 (0.172 sec/step)\n",
            "I0601 12:16:44.483901 140438660523904 learning.py:507] global step 7853: loss = 4.2749 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7854: loss = 0.0528 (0.158 sec/step)\n",
            "I0601 12:16:44.643507 140438660523904 learning.py:507] global step 7854: loss = 0.0528 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7855: loss = 0.1914 (0.182 sec/step)\n",
            "I0601 12:16:44.827268 140438660523904 learning.py:507] global step 7855: loss = 0.1914 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7856: loss = 0.3118 (0.175 sec/step)\n",
            "I0601 12:16:45.003544 140438660523904 learning.py:507] global step 7856: loss = 0.3118 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7857: loss = 0.1061 (0.177 sec/step)\n",
            "I0601 12:16:45.182025 140438660523904 learning.py:507] global step 7857: loss = 0.1061 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7858: loss = 0.0749 (0.178 sec/step)\n",
            "I0601 12:16:45.363060 140438660523904 learning.py:507] global step 7858: loss = 0.0749 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7859: loss = 0.2564 (0.178 sec/step)\n",
            "I0601 12:16:45.542453 140438660523904 learning.py:507] global step 7859: loss = 0.2564 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7860: loss = 0.0515 (0.175 sec/step)\n",
            "I0601 12:16:45.719058 140438660523904 learning.py:507] global step 7860: loss = 0.0515 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7861: loss = 0.2369 (0.168 sec/step)\n",
            "I0601 12:16:45.888113 140438660523904 learning.py:507] global step 7861: loss = 0.2369 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7862: loss = 0.1199 (0.159 sec/step)\n",
            "I0601 12:16:46.048649 140438660523904 learning.py:507] global step 7862: loss = 0.1199 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7863: loss = 0.1919 (0.179 sec/step)\n",
            "I0601 12:16:46.229125 140438660523904 learning.py:507] global step 7863: loss = 0.1919 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7864: loss = 0.0764 (0.176 sec/step)\n",
            "I0601 12:16:46.406572 140438660523904 learning.py:507] global step 7864: loss = 0.0764 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7865: loss = 0.2601 (0.201 sec/step)\n",
            "I0601 12:16:46.609217 140438660523904 learning.py:507] global step 7865: loss = 0.2601 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 7866: loss = 0.0635 (0.181 sec/step)\n",
            "I0601 12:16:46.791920 140438660523904 learning.py:507] global step 7866: loss = 0.0635 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7867: loss = 0.1078 (0.163 sec/step)\n",
            "I0601 12:16:46.956423 140438660523904 learning.py:507] global step 7867: loss = 0.1078 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7868: loss = 0.3223 (0.190 sec/step)\n",
            "I0601 12:16:47.147559 140438660523904 learning.py:507] global step 7868: loss = 0.3223 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 7869: loss = 0.1291 (0.173 sec/step)\n",
            "I0601 12:16:47.322051 140438660523904 learning.py:507] global step 7869: loss = 0.1291 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7870: loss = 0.3347 (0.178 sec/step)\n",
            "I0601 12:16:47.501329 140438660523904 learning.py:507] global step 7870: loss = 0.3347 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7871: loss = 0.3824 (0.173 sec/step)\n",
            "I0601 12:16:47.675981 140438660523904 learning.py:507] global step 7871: loss = 0.3824 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7872: loss = 0.0969 (0.158 sec/step)\n",
            "I0601 12:16:47.835067 140438660523904 learning.py:507] global step 7872: loss = 0.0969 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7873: loss = 0.3596 (0.164 sec/step)\n",
            "I0601 12:16:48.000046 140438660523904 learning.py:507] global step 7873: loss = 0.3596 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7874: loss = 0.1040 (0.174 sec/step)\n",
            "I0601 12:16:48.176014 140438660523904 learning.py:507] global step 7874: loss = 0.1040 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7875: loss = 0.1160 (0.161 sec/step)\n",
            "I0601 12:16:48.338320 140438660523904 learning.py:507] global step 7875: loss = 0.1160 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7876: loss = 0.0881 (0.163 sec/step)\n",
            "I0601 12:16:48.503308 140438660523904 learning.py:507] global step 7876: loss = 0.0881 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7877: loss = 0.0844 (0.170 sec/step)\n",
            "I0601 12:16:48.674987 140438660523904 learning.py:507] global step 7877: loss = 0.0844 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7878: loss = 0.2691 (0.156 sec/step)\n",
            "I0601 12:16:48.832222 140438660523904 learning.py:507] global step 7878: loss = 0.2691 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7879: loss = 0.1135 (0.162 sec/step)\n",
            "I0601 12:16:48.995970 140438660523904 learning.py:507] global step 7879: loss = 0.1135 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7880: loss = 0.1733 (0.205 sec/step)\n",
            "I0601 12:16:49.202681 140438660523904 learning.py:507] global step 7880: loss = 0.1733 (0.205 sec/step)\n",
            "INFO:tensorflow:global step 7881: loss = 0.0402 (0.162 sec/step)\n",
            "I0601 12:16:49.366300 140438660523904 learning.py:507] global step 7881: loss = 0.0402 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7882: loss = 0.0535 (0.173 sec/step)\n",
            "I0601 12:16:49.540617 140438660523904 learning.py:507] global step 7882: loss = 0.0535 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7883: loss = 0.1073 (0.180 sec/step)\n",
            "I0601 12:16:49.722321 140438660523904 learning.py:507] global step 7883: loss = 0.1073 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7884: loss = 0.0499 (0.187 sec/step)\n",
            "I0601 12:16:49.911003 140438660523904 learning.py:507] global step 7884: loss = 0.0499 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7885: loss = 0.5103 (0.163 sec/step)\n",
            "I0601 12:16:50.075679 140438660523904 learning.py:507] global step 7885: loss = 0.5103 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7886: loss = 0.0668 (0.182 sec/step)\n",
            "I0601 12:16:50.259605 140438660523904 learning.py:507] global step 7886: loss = 0.0668 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7887: loss = 0.1140 (0.157 sec/step)\n",
            "I0601 12:16:50.418554 140438660523904 learning.py:507] global step 7887: loss = 0.1140 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7888: loss = 0.0809 (0.174 sec/step)\n",
            "I0601 12:16:50.594230 140438660523904 learning.py:507] global step 7888: loss = 0.0809 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7889: loss = 0.1077 (0.178 sec/step)\n",
            "I0601 12:16:50.773776 140438660523904 learning.py:507] global step 7889: loss = 0.1077 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7890: loss = 0.0909 (0.167 sec/step)\n",
            "I0601 12:16:50.942472 140438660523904 learning.py:507] global step 7890: loss = 0.0909 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7891: loss = 0.0636 (0.156 sec/step)\n",
            "I0601 12:16:51.099769 140438660523904 learning.py:507] global step 7891: loss = 0.0636 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7892: loss = 0.1118 (0.169 sec/step)\n",
            "I0601 12:16:51.270305 140438660523904 learning.py:507] global step 7892: loss = 0.1118 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7893: loss = 0.0599 (0.165 sec/step)\n",
            "I0601 12:16:51.436496 140438660523904 learning.py:507] global step 7893: loss = 0.0599 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7894: loss = 0.3440 (0.193 sec/step)\n",
            "I0601 12:16:51.630736 140438660523904 learning.py:507] global step 7894: loss = 0.3440 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 7895: loss = 0.0797 (0.182 sec/step)\n",
            "I0601 12:16:51.815123 140438660523904 learning.py:507] global step 7895: loss = 0.0797 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7896: loss = 0.0571 (0.179 sec/step)\n",
            "I0601 12:16:51.995744 140438660523904 learning.py:507] global step 7896: loss = 0.0571 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7897: loss = 0.2410 (0.166 sec/step)\n",
            "I0601 12:16:52.163221 140438660523904 learning.py:507] global step 7897: loss = 0.2410 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7898: loss = 0.2000 (0.172 sec/step)\n",
            "I0601 12:16:52.336082 140438660523904 learning.py:507] global step 7898: loss = 0.2000 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7899: loss = 0.0451 (0.151 sec/step)\n",
            "I0601 12:16:52.488366 140438660523904 learning.py:507] global step 7899: loss = 0.0451 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 7900: loss = 0.2143 (0.174 sec/step)\n",
            "I0601 12:16:52.663948 140438660523904 learning.py:507] global step 7900: loss = 0.2143 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7901: loss = 0.2381 (0.160 sec/step)\n",
            "I0601 12:16:52.825418 140438660523904 learning.py:507] global step 7901: loss = 0.2381 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7902: loss = 0.3545 (0.165 sec/step)\n",
            "I0601 12:16:52.992217 140438660523904 learning.py:507] global step 7902: loss = 0.3545 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7903: loss = 0.2065 (0.160 sec/step)\n",
            "I0601 12:16:53.154071 140438660523904 learning.py:507] global step 7903: loss = 0.2065 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7904: loss = 0.1924 (0.191 sec/step)\n",
            "I0601 12:16:53.346341 140438660523904 learning.py:507] global step 7904: loss = 0.1924 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 7905: loss = 0.2316 (0.185 sec/step)\n",
            "I0601 12:16:53.532618 140438660523904 learning.py:507] global step 7905: loss = 0.2316 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7906: loss = 4.2062 (0.200 sec/step)\n",
            "I0601 12:16:53.734621 140438660523904 learning.py:507] global step 7906: loss = 4.2062 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 7907: loss = 0.1151 (0.196 sec/step)\n",
            "I0601 12:16:53.932128 140438660523904 learning.py:507] global step 7907: loss = 0.1151 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 7908: loss = 0.0339 (0.175 sec/step)\n",
            "I0601 12:16:54.108412 140438660523904 learning.py:507] global step 7908: loss = 0.0339 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7909: loss = 0.2325 (0.199 sec/step)\n",
            "I0601 12:16:54.309048 140438660523904 learning.py:507] global step 7909: loss = 0.2325 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 7910: loss = 0.1915 (0.175 sec/step)\n",
            "I0601 12:16:54.485386 140438660523904 learning.py:507] global step 7910: loss = 0.1915 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7911: loss = 0.2319 (0.175 sec/step)\n",
            "I0601 12:16:54.661466 140438660523904 learning.py:507] global step 7911: loss = 0.2319 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 7912: loss = 0.0785 (0.164 sec/step)\n",
            "I0601 12:16:54.827426 140438660523904 learning.py:507] global step 7912: loss = 0.0785 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7913: loss = 0.0394 (0.173 sec/step)\n",
            "I0601 12:16:55.001637 140438660523904 learning.py:507] global step 7913: loss = 0.0394 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7914: loss = 0.1993 (0.179 sec/step)\n",
            "I0601 12:16:55.182283 140438660523904 learning.py:507] global step 7914: loss = 0.1993 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7915: loss = 0.1884 (0.182 sec/step)\n",
            "I0601 12:16:55.365383 140438660523904 learning.py:507] global step 7915: loss = 0.1884 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7916: loss = 0.0921 (0.185 sec/step)\n",
            "I0601 12:16:55.552026 140438660523904 learning.py:507] global step 7916: loss = 0.0921 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7917: loss = 0.0404 (0.186 sec/step)\n",
            "I0601 12:16:55.739632 140438660523904 learning.py:507] global step 7917: loss = 0.0404 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7918: loss = 0.0821 (0.163 sec/step)\n",
            "I0601 12:16:55.904440 140438660523904 learning.py:507] global step 7918: loss = 0.0821 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 7919: loss = 0.1090 (0.176 sec/step)\n",
            "I0601 12:16:56.081660 140438660523904 learning.py:507] global step 7919: loss = 0.1090 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7920: loss = 0.0649 (0.187 sec/step)\n",
            "I0601 12:16:56.270131 140438660523904 learning.py:507] global step 7920: loss = 0.0649 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 7921: loss = 0.2869 (0.176 sec/step)\n",
            "I0601 12:16:56.447099 140438660523904 learning.py:507] global step 7921: loss = 0.2869 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7922: loss = 0.0759 (0.182 sec/step)\n",
            "I0601 12:16:56.630259 140438660523904 learning.py:507] global step 7922: loss = 0.0759 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7923: loss = 0.1746 (0.176 sec/step)\n",
            "I0601 12:16:56.807152 140438660523904 learning.py:507] global step 7923: loss = 0.1746 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7924: loss = 0.2670 (0.162 sec/step)\n",
            "I0601 12:16:56.970808 140438660523904 learning.py:507] global step 7924: loss = 0.2670 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7925: loss = 0.2054 (0.183 sec/step)\n",
            "I0601 12:16:57.155112 140438660523904 learning.py:507] global step 7925: loss = 0.2054 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7926: loss = 0.1103 (0.152 sec/step)\n",
            "I0601 12:16:57.308668 140438660523904 learning.py:507] global step 7926: loss = 0.1103 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 7927: loss = 0.2728 (0.171 sec/step)\n",
            "I0601 12:16:57.480787 140438660523904 learning.py:507] global step 7927: loss = 0.2728 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7928: loss = 0.2023 (0.165 sec/step)\n",
            "I0601 12:16:57.647319 140438660523904 learning.py:507] global step 7928: loss = 0.2023 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 7929: loss = 0.1241 (0.174 sec/step)\n",
            "I0601 12:16:57.823239 140438660523904 learning.py:507] global step 7929: loss = 0.1241 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7930: loss = 0.1832 (0.166 sec/step)\n",
            "I0601 12:16:57.990238 140438660523904 learning.py:507] global step 7930: loss = 0.1832 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7931: loss = 0.0909 (0.183 sec/step)\n",
            "I0601 12:16:58.174340 140438660523904 learning.py:507] global step 7931: loss = 0.0909 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 7932: loss = 0.0281 (0.188 sec/step)\n",
            "I0601 12:16:58.363999 140438660523904 learning.py:507] global step 7932: loss = 0.0281 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 7933: loss = 0.1618 (0.164 sec/step)\n",
            "I0601 12:16:58.529366 140438660523904 learning.py:507] global step 7933: loss = 0.1618 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7934: loss = 0.0833 (0.170 sec/step)\n",
            "I0601 12:16:58.700733 140438660523904 learning.py:507] global step 7934: loss = 0.0833 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7935: loss = 0.1706 (0.162 sec/step)\n",
            "I0601 12:16:58.864073 140438660523904 learning.py:507] global step 7935: loss = 0.1706 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7936: loss = 0.2620 (0.171 sec/step)\n",
            "I0601 12:16:59.036851 140438660523904 learning.py:507] global step 7936: loss = 0.2620 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 7937: loss = 0.2706 (0.181 sec/step)\n",
            "I0601 12:16:59.219025 140438660523904 learning.py:507] global step 7937: loss = 0.2706 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7938: loss = 0.4086 (0.164 sec/step)\n",
            "I0601 12:16:59.384736 140438660523904 learning.py:507] global step 7938: loss = 0.4086 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7939: loss = 0.0728 (0.166 sec/step)\n",
            "I0601 12:16:59.552011 140438660523904 learning.py:507] global step 7939: loss = 0.0728 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7940: loss = 0.0870 (0.200 sec/step)\n",
            "I0601 12:16:59.753586 140438660523904 learning.py:507] global step 7940: loss = 0.0870 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 7941: loss = 0.1216 (0.160 sec/step)\n",
            "I0601 12:16:59.914818 140438660523904 learning.py:507] global step 7941: loss = 0.1216 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 7942: loss = 0.1792 (0.164 sec/step)\n",
            "I0601 12:17:00.079601 140438660523904 learning.py:507] global step 7942: loss = 0.1792 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 7943: loss = 0.1785 (0.168 sec/step)\n",
            "I0601 12:17:00.249077 140438660523904 learning.py:507] global step 7943: loss = 0.1785 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7944: loss = 0.0449 (0.178 sec/step)\n",
            "I0601 12:17:00.428197 140438660523904 learning.py:507] global step 7944: loss = 0.0449 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7945: loss = 0.1520 (0.158 sec/step)\n",
            "I0601 12:17:00.587102 140438660523904 learning.py:507] global step 7945: loss = 0.1520 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 7946: loss = 0.0808 (0.190 sec/step)\n",
            "I0601 12:17:00.778578 140438660523904 learning.py:507] global step 7946: loss = 0.0808 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 7947: loss = 0.2530 (0.170 sec/step)\n",
            "I0601 12:17:00.950775 140438660523904 learning.py:507] global step 7947: loss = 0.2530 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7948: loss = 0.0355 (0.162 sec/step)\n",
            "I0601 12:17:01.114531 140438660523904 learning.py:507] global step 7948: loss = 0.0355 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 7949: loss = 0.0356 (0.172 sec/step)\n",
            "I0601 12:17:01.288024 140438660523904 learning.py:507] global step 7949: loss = 0.0356 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7950: loss = 0.0593 (0.178 sec/step)\n",
            "I0601 12:17:01.467499 140438660523904 learning.py:507] global step 7950: loss = 0.0593 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7951: loss = 0.0684 (0.177 sec/step)\n",
            "I0601 12:17:01.645855 140438660523904 learning.py:507] global step 7951: loss = 0.0684 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7952: loss = 0.4288 (0.180 sec/step)\n",
            "I0601 12:17:01.827801 140438660523904 learning.py:507] global step 7952: loss = 0.4288 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7953: loss = 0.2277 (0.170 sec/step)\n",
            "I0601 12:17:01.998836 140438660523904 learning.py:507] global step 7953: loss = 0.2277 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7954: loss = 0.1228 (0.214 sec/step)\n",
            "I0601 12:17:02.215119 140438660523904 learning.py:507] global step 7954: loss = 0.1228 (0.214 sec/step)\n",
            "INFO:tensorflow:global step 7955: loss = 0.1120 (0.151 sec/step)\n",
            "I0601 12:17:02.373235 140438660523904 learning.py:507] global step 7955: loss = 0.1120 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 7956: loss = 0.1420 (0.157 sec/step)\n",
            "I0601 12:17:02.531410 140438660523904 learning.py:507] global step 7956: loss = 0.1420 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7957: loss = 0.2185 (0.177 sec/step)\n",
            "I0601 12:17:02.710288 140438660523904 learning.py:507] global step 7957: loss = 0.2185 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7958: loss = 0.2074 (0.176 sec/step)\n",
            "I0601 12:17:02.888328 140438660523904 learning.py:507] global step 7958: loss = 0.2074 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7959: loss = 0.0693 (0.181 sec/step)\n",
            "I0601 12:17:03.070637 140438660523904 learning.py:507] global step 7959: loss = 0.0693 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7960: loss = 0.0868 (0.217 sec/step)\n",
            "I0601 12:17:03.289304 140438660523904 learning.py:507] global step 7960: loss = 0.0868 (0.217 sec/step)\n",
            "INFO:tensorflow:global step 7961: loss = 0.0807 (0.180 sec/step)\n",
            "I0601 12:17:03.471133 140438660523904 learning.py:507] global step 7961: loss = 0.0807 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 7962: loss = 0.3184 (0.181 sec/step)\n",
            "I0601 12:17:03.654095 140438660523904 learning.py:507] global step 7962: loss = 0.3184 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7963: loss = 0.0805 (0.169 sec/step)\n",
            "I0601 12:17:03.824718 140438660523904 learning.py:507] global step 7963: loss = 0.0805 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7964: loss = 0.2927 (0.191 sec/step)\n",
            "I0601 12:17:04.016956 140438660523904 learning.py:507] global step 7964: loss = 0.2927 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 7965: loss = 0.0971 (0.156 sec/step)\n",
            "I0601 12:17:04.173891 140438660523904 learning.py:507] global step 7965: loss = 0.0971 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 7966: loss = 0.0601 (0.157 sec/step)\n",
            "I0601 12:17:04.332715 140438660523904 learning.py:507] global step 7966: loss = 0.0601 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 7967: loss = 0.0694 (0.161 sec/step)\n",
            "I0601 12:17:04.494794 140438660523904 learning.py:507] global step 7967: loss = 0.0694 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 7968: loss = 0.1312 (0.174 sec/step)\n",
            "I0601 12:17:04.671201 140438660523904 learning.py:507] global step 7968: loss = 0.1312 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7969: loss = 0.0536 (0.172 sec/step)\n",
            "I0601 12:17:04.844544 140438660523904 learning.py:507] global step 7969: loss = 0.0536 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7970: loss = 0.1082 (0.168 sec/step)\n",
            "I0601 12:17:05.014429 140438660523904 learning.py:507] global step 7970: loss = 0.1082 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 7971: loss = 0.0710 (0.153 sec/step)\n",
            "I0601 12:17:05.169566 140438660523904 learning.py:507] global step 7971: loss = 0.0710 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 7972: loss = 0.3538 (0.182 sec/step)\n",
            "I0601 12:17:05.353177 140438660523904 learning.py:507] global step 7972: loss = 0.3538 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 7973: loss = 0.0266 (0.173 sec/step)\n",
            "I0601 12:17:05.527456 140438660523904 learning.py:507] global step 7973: loss = 0.0266 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 7974: loss = 0.0847 (0.186 sec/step)\n",
            "I0601 12:17:05.714562 140438660523904 learning.py:507] global step 7974: loss = 0.0847 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 7975: loss = 0.2145 (0.159 sec/step)\n",
            "I0601 12:17:05.874960 140438660523904 learning.py:507] global step 7975: loss = 0.2145 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 7976: loss = 0.1460 (0.178 sec/step)\n",
            "I0601 12:17:06.055770 140438660523904 learning.py:507] global step 7976: loss = 0.1460 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7977: loss = 0.0366 (0.181 sec/step)\n",
            "I0601 12:17:06.238089 140438660523904 learning.py:507] global step 7977: loss = 0.0366 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 7978: loss = 0.3690 (0.192 sec/step)\n",
            "I0601 12:17:06.431557 140438660523904 learning.py:507] global step 7978: loss = 0.3690 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 7979: loss = 0.2647 (0.170 sec/step)\n",
            "I0601 12:17:06.603283 140438660523904 learning.py:507] global step 7979: loss = 0.2647 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7980: loss = 0.0847 (0.178 sec/step)\n",
            "I0601 12:17:06.782390 140438660523904 learning.py:507] global step 7980: loss = 0.0847 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 7981: loss = 0.0992 (0.166 sec/step)\n",
            "I0601 12:17:06.949503 140438660523904 learning.py:507] global step 7981: loss = 0.0992 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7982: loss = 0.0514 (0.174 sec/step)\n",
            "I0601 12:17:07.125164 140438660523904 learning.py:507] global step 7982: loss = 0.0514 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 7983: loss = 0.2464 (0.177 sec/step)\n",
            "I0601 12:17:07.303992 140438660523904 learning.py:507] global step 7983: loss = 0.2464 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7984: loss = 0.1540 (0.167 sec/step)\n",
            "I0601 12:17:07.472127 140438660523904 learning.py:507] global step 7984: loss = 0.1540 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7985: loss = 0.0789 (0.154 sec/step)\n",
            "I0601 12:17:07.627214 140438660523904 learning.py:507] global step 7985: loss = 0.0789 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 7986: loss = 0.0839 (0.155 sec/step)\n",
            "I0601 12:17:07.784032 140438660523904 learning.py:507] global step 7986: loss = 0.0839 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 7987: loss = 0.0510 (0.167 sec/step)\n",
            "I0601 12:17:07.952009 140438660523904 learning.py:507] global step 7987: loss = 0.0510 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7988: loss = 0.1694 (0.172 sec/step)\n",
            "I0601 12:17:08.124887 140438660523904 learning.py:507] global step 7988: loss = 0.1694 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 7989: loss = 0.2395 (0.179 sec/step)\n",
            "I0601 12:17:08.305820 140438660523904 learning.py:507] global step 7989: loss = 0.2395 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7990: loss = 0.0843 (0.201 sec/step)\n",
            "I0601 12:17:08.508363 140438660523904 learning.py:507] global step 7990: loss = 0.0843 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 7991: loss = 0.1426 (0.179 sec/step)\n",
            "I0601 12:17:08.688878 140438660523904 learning.py:507] global step 7991: loss = 0.1426 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 7992: loss = 0.1807 (0.169 sec/step)\n",
            "I0601 12:17:08.859978 140438660523904 learning.py:507] global step 7992: loss = 0.1807 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 7993: loss = 0.2009 (0.170 sec/step)\n",
            "I0601 12:17:09.031244 140438660523904 learning.py:507] global step 7993: loss = 0.2009 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 7994: loss = 0.0780 (0.166 sec/step)\n",
            "I0601 12:17:09.198994 140438660523904 learning.py:507] global step 7994: loss = 0.0780 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 7995: loss = 0.0429 (0.185 sec/step)\n",
            "I0601 12:17:09.385164 140438660523904 learning.py:507] global step 7995: loss = 0.0429 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 7996: loss = 0.0709 (0.176 sec/step)\n",
            "I0601 12:17:09.562721 140438660523904 learning.py:507] global step 7996: loss = 0.0709 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 7997: loss = 0.0969 (0.167 sec/step)\n",
            "I0601 12:17:09.733072 140438660523904 learning.py:507] global step 7997: loss = 0.0969 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 7998: loss = 0.1030 (0.177 sec/step)\n",
            "I0601 12:17:09.912414 140438660523904 learning.py:507] global step 7998: loss = 0.1030 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 7999: loss = 0.1707 (0.181 sec/step)\n",
            "I0601 12:17:10.094617 140438660523904 learning.py:507] global step 7999: loss = 0.1707 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8000: loss = 0.1236 (0.179 sec/step)\n",
            "I0601 12:17:10.275343 140438660523904 learning.py:507] global step 8000: loss = 0.1236 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8001: loss = 0.0859 (0.201 sec/step)\n",
            "I0601 12:17:10.477550 140438660523904 learning.py:507] global step 8001: loss = 0.0859 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 8002: loss = 0.3052 (0.175 sec/step)\n",
            "I0601 12:17:10.654066 140438660523904 learning.py:507] global step 8002: loss = 0.3052 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8003: loss = 0.2377 (0.214 sec/step)\n",
            "I0601 12:17:10.869405 140438660523904 learning.py:507] global step 8003: loss = 0.2377 (0.214 sec/step)\n",
            "INFO:tensorflow:global step 8004: loss = 0.1536 (0.173 sec/step)\n",
            "I0601 12:17:11.043224 140438660523904 learning.py:507] global step 8004: loss = 0.1536 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8005: loss = 0.0785 (0.190 sec/step)\n",
            "I0601 12:17:11.234409 140438660523904 learning.py:507] global step 8005: loss = 0.0785 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8006: loss = 0.0668 (0.178 sec/step)\n",
            "I0601 12:17:11.414157 140438660523904 learning.py:507] global step 8006: loss = 0.0668 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8007: loss = 0.1649 (0.175 sec/step)\n",
            "I0601 12:17:11.590353 140438660523904 learning.py:507] global step 8007: loss = 0.1649 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8008: loss = 0.0311 (0.172 sec/step)\n",
            "I0601 12:17:11.763819 140438660523904 learning.py:507] global step 8008: loss = 0.0311 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8009: loss = 0.0727 (0.189 sec/step)\n",
            "I0601 12:17:11.954450 140438660523904 learning.py:507] global step 8009: loss = 0.0727 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8010: loss = 0.1377 (0.191 sec/step)\n",
            "I0601 12:17:12.147278 140438660523904 learning.py:507] global step 8010: loss = 0.1377 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8011: loss = 0.1641 (0.161 sec/step)\n",
            "I0601 12:17:12.309453 140438660523904 learning.py:507] global step 8011: loss = 0.1641 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8012: loss = 0.2134 (0.166 sec/step)\n",
            "I0601 12:17:12.476945 140438660523904 learning.py:507] global step 8012: loss = 0.2134 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8013: loss = 0.0801 (0.175 sec/step)\n",
            "I0601 12:17:12.653559 140438660523904 learning.py:507] global step 8013: loss = 0.0801 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8014: loss = 0.0972 (0.185 sec/step)\n",
            "I0601 12:17:12.839744 140438660523904 learning.py:507] global step 8014: loss = 0.0972 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8015: loss = 0.1131 (0.158 sec/step)\n",
            "I0601 12:17:12.999191 140438660523904 learning.py:507] global step 8015: loss = 0.1131 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8016: loss = 0.3890 (0.175 sec/step)\n",
            "I0601 12:17:13.175240 140438660523904 learning.py:507] global step 8016: loss = 0.3890 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8017: loss = 0.0515 (0.167 sec/step)\n",
            "I0601 12:17:13.343508 140438660523904 learning.py:507] global step 8017: loss = 0.0515 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8018: loss = 0.2550 (0.176 sec/step)\n",
            "I0601 12:17:13.521345 140438660523904 learning.py:507] global step 8018: loss = 0.2550 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8019: loss = 0.0465 (0.196 sec/step)\n",
            "I0601 12:17:13.719071 140438660523904 learning.py:507] global step 8019: loss = 0.0465 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 8020: loss = 0.2355 (0.152 sec/step)\n",
            "I0601 12:17:13.872482 140438660523904 learning.py:507] global step 8020: loss = 0.2355 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8021: loss = 0.1087 (0.151 sec/step)\n",
            "I0601 12:17:14.024676 140438660523904 learning.py:507] global step 8021: loss = 0.1087 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8022: loss = 0.1471 (0.154 sec/step)\n",
            "I0601 12:17:14.180778 140438660523904 learning.py:507] global step 8022: loss = 0.1471 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8023: loss = 0.1572 (0.167 sec/step)\n",
            "I0601 12:17:14.349104 140438660523904 learning.py:507] global step 8023: loss = 0.1572 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8024: loss = 0.0305 (0.177 sec/step)\n",
            "I0601 12:17:14.527541 140438660523904 learning.py:507] global step 8024: loss = 0.0305 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8025: loss = 0.0536 (0.170 sec/step)\n",
            "I0601 12:17:14.699172 140438660523904 learning.py:507] global step 8025: loss = 0.0536 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8026: loss = 0.1218 (0.194 sec/step)\n",
            "I0601 12:17:14.894220 140438660523904 learning.py:507] global step 8026: loss = 0.1218 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8027: loss = 0.2558 (0.175 sec/step)\n",
            "I0601 12:17:15.070824 140438660523904 learning.py:507] global step 8027: loss = 0.2558 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8028: loss = 0.1126 (0.170 sec/step)\n",
            "I0601 12:17:15.241812 140438660523904 learning.py:507] global step 8028: loss = 0.1126 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8029: loss = 0.1808 (0.156 sec/step)\n",
            "I0601 12:17:15.399396 140438660523904 learning.py:507] global step 8029: loss = 0.1808 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8030: loss = 0.0635 (0.147 sec/step)\n",
            "I0601 12:17:15.547533 140438660523904 learning.py:507] global step 8030: loss = 0.0635 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 8031: loss = 0.1492 (0.192 sec/step)\n",
            "I0601 12:17:15.740891 140438660523904 learning.py:507] global step 8031: loss = 0.1492 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8032: loss = 0.0634 (0.183 sec/step)\n",
            "I0601 12:17:15.925189 140438660523904 learning.py:507] global step 8032: loss = 0.0634 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8033: loss = 0.0720 (0.161 sec/step)\n",
            "I0601 12:17:16.087734 140438660523904 learning.py:507] global step 8033: loss = 0.0720 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8034: loss = 0.1165 (0.162 sec/step)\n",
            "I0601 12:17:16.251248 140438660523904 learning.py:507] global step 8034: loss = 0.1165 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8035: loss = 0.0677 (0.187 sec/step)\n",
            "I0601 12:17:16.439585 140438660523904 learning.py:507] global step 8035: loss = 0.0677 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8036: loss = 0.1296 (0.174 sec/step)\n",
            "I0601 12:17:16.614641 140438660523904 learning.py:507] global step 8036: loss = 0.1296 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8037: loss = 0.4303 (0.176 sec/step)\n",
            "I0601 12:17:16.792360 140438660523904 learning.py:507] global step 8037: loss = 0.4303 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8038: loss = 0.0916 (0.192 sec/step)\n",
            "I0601 12:17:16.985774 140438660523904 learning.py:507] global step 8038: loss = 0.0916 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8039: loss = 0.0378 (0.165 sec/step)\n",
            "I0601 12:17:17.151875 140438660523904 learning.py:507] global step 8039: loss = 0.0378 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8040: loss = 0.1335 (0.168 sec/step)\n",
            "I0601 12:17:17.320995 140438660523904 learning.py:507] global step 8040: loss = 0.1335 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8041: loss = 0.0559 (0.167 sec/step)\n",
            "I0601 12:17:17.489442 140438660523904 learning.py:507] global step 8041: loss = 0.0559 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8042: loss = 0.0774 (0.173 sec/step)\n",
            "I0601 12:17:17.663543 140438660523904 learning.py:507] global step 8042: loss = 0.0774 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8043: loss = 0.0889 (0.163 sec/step)\n",
            "I0601 12:17:17.827955 140438660523904 learning.py:507] global step 8043: loss = 0.0889 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8044: loss = 0.3260 (0.212 sec/step)\n",
            "I0601 12:17:18.041765 140438660523904 learning.py:507] global step 8044: loss = 0.3260 (0.212 sec/step)\n",
            "INFO:tensorflow:global step 8045: loss = 0.0711 (0.167 sec/step)\n",
            "I0601 12:17:18.210256 140438660523904 learning.py:507] global step 8045: loss = 0.0711 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8046: loss = 0.1801 (0.158 sec/step)\n",
            "I0601 12:17:18.369418 140438660523904 learning.py:507] global step 8046: loss = 0.1801 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8047: loss = 0.0758 (0.169 sec/step)\n",
            "I0601 12:17:18.539838 140438660523904 learning.py:507] global step 8047: loss = 0.0758 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8048: loss = 0.0790 (0.167 sec/step)\n",
            "I0601 12:17:18.708408 140438660523904 learning.py:507] global step 8048: loss = 0.0790 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8049: loss = 0.0611 (0.157 sec/step)\n",
            "I0601 12:17:18.866526 140438660523904 learning.py:507] global step 8049: loss = 0.0611 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8050: loss = 0.0797 (0.177 sec/step)\n",
            "I0601 12:17:19.045269 140438660523904 learning.py:507] global step 8050: loss = 0.0797 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8051: loss = 0.0656 (0.177 sec/step)\n",
            "I0601 12:17:19.223532 140438660523904 learning.py:507] global step 8051: loss = 0.0656 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8052: loss = 0.1784 (0.172 sec/step)\n",
            "I0601 12:17:19.397212 140438660523904 learning.py:507] global step 8052: loss = 0.1784 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8053: loss = 0.1127 (0.166 sec/step)\n",
            "I0601 12:17:19.564659 140438660523904 learning.py:507] global step 8053: loss = 0.1127 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8054: loss = 0.1673 (0.183 sec/step)\n",
            "I0601 12:17:19.748885 140438660523904 learning.py:507] global step 8054: loss = 0.1673 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8055: loss = 0.1232 (0.176 sec/step)\n",
            "I0601 12:17:19.926687 140438660523904 learning.py:507] global step 8055: loss = 0.1232 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8056: loss = 0.0661 (0.183 sec/step)\n",
            "I0601 12:17:20.111072 140438660523904 learning.py:507] global step 8056: loss = 0.0661 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8057: loss = 0.0450 (0.178 sec/step)\n",
            "I0601 12:17:20.290326 140438660523904 learning.py:507] global step 8057: loss = 0.0450 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8058: loss = 0.0782 (0.182 sec/step)\n",
            "I0601 12:17:20.473557 140438660523904 learning.py:507] global step 8058: loss = 0.0782 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8059: loss = 0.0463 (0.154 sec/step)\n",
            "I0601 12:17:20.629243 140438660523904 learning.py:507] global step 8059: loss = 0.0463 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8060: loss = 0.1807 (0.183 sec/step)\n",
            "I0601 12:17:20.813999 140438660523904 learning.py:507] global step 8060: loss = 0.1807 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8061: loss = 0.0670 (0.179 sec/step)\n",
            "I0601 12:17:20.994071 140438660523904 learning.py:507] global step 8061: loss = 0.0670 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8062: loss = 0.1640 (0.169 sec/step)\n",
            "I0601 12:17:21.164530 140438660523904 learning.py:507] global step 8062: loss = 0.1640 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8063: loss = 0.1154 (0.175 sec/step)\n",
            "I0601 12:17:21.340607 140438660523904 learning.py:507] global step 8063: loss = 0.1154 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8064: loss = 0.0273 (0.175 sec/step)\n",
            "I0601 12:17:21.516718 140438660523904 learning.py:507] global step 8064: loss = 0.0273 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8065: loss = 4.2027 (0.226 sec/step)\n",
            "I0601 12:17:21.744284 140438660523904 learning.py:507] global step 8065: loss = 4.2027 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8066: loss = 0.1531 (0.163 sec/step)\n",
            "I0601 12:17:21.908599 140438660523904 learning.py:507] global step 8066: loss = 0.1531 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8067: loss = 0.1391 (0.194 sec/step)\n",
            "I0601 12:17:22.104376 140438660523904 learning.py:507] global step 8067: loss = 0.1391 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8068: loss = 0.0399 (0.157 sec/step)\n",
            "I0601 12:17:22.263016 140438660523904 learning.py:507] global step 8068: loss = 0.0399 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8069: loss = 0.2131 (0.163 sec/step)\n",
            "I0601 12:17:22.427836 140438660523904 learning.py:507] global step 8069: loss = 0.2131 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8070: loss = 0.3442 (0.168 sec/step)\n",
            "I0601 12:17:22.597644 140438660523904 learning.py:507] global step 8070: loss = 0.3442 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8071: loss = 0.2461 (0.194 sec/step)\n",
            "I0601 12:17:22.792876 140438660523904 learning.py:507] global step 8071: loss = 0.2461 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8072: loss = 0.1174 (0.182 sec/step)\n",
            "I0601 12:17:22.976455 140438660523904 learning.py:507] global step 8072: loss = 0.1174 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8073: loss = 0.4701 (0.167 sec/step)\n",
            "I0601 12:17:23.144670 140438660523904 learning.py:507] global step 8073: loss = 0.4701 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8074: loss = 0.0913 (0.162 sec/step)\n",
            "I0601 12:17:23.307750 140438660523904 learning.py:507] global step 8074: loss = 0.0913 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8075: loss = 0.0312 (0.169 sec/step)\n",
            "I0601 12:17:23.477835 140438660523904 learning.py:507] global step 8075: loss = 0.0312 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8076: loss = 0.0473 (0.190 sec/step)\n",
            "I0601 12:17:23.669975 140438660523904 learning.py:507] global step 8076: loss = 0.0473 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8077: loss = 0.0934 (0.176 sec/step)\n",
            "I0601 12:17:23.847036 140438660523904 learning.py:507] global step 8077: loss = 0.0934 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8078: loss = 0.0790 (0.187 sec/step)\n",
            "I0601 12:17:24.035858 140438660523904 learning.py:507] global step 8078: loss = 0.0790 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8079: loss = 0.0876 (0.180 sec/step)\n",
            "I0601 12:17:24.217128 140438660523904 learning.py:507] global step 8079: loss = 0.0876 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8080: loss = 0.0955 (0.183 sec/step)\n",
            "I0601 12:17:24.401366 140438660523904 learning.py:507] global step 8080: loss = 0.0955 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8081: loss = 0.2797 (0.188 sec/step)\n",
            "I0601 12:17:24.590724 140438660523904 learning.py:507] global step 8081: loss = 0.2797 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8082: loss = 0.2120 (0.186 sec/step)\n",
            "I0601 12:17:24.777909 140438660523904 learning.py:507] global step 8082: loss = 0.2120 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8083: loss = 0.1276 (0.155 sec/step)\n",
            "I0601 12:17:24.933847 140438660523904 learning.py:507] global step 8083: loss = 0.1276 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8084: loss = 0.0281 (0.160 sec/step)\n",
            "I0601 12:17:25.094891 140438660523904 learning.py:507] global step 8084: loss = 0.0281 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8085: loss = 0.2501 (0.164 sec/step)\n",
            "I0601 12:17:25.261125 140438660523904 learning.py:507] global step 8085: loss = 0.2501 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8086: loss = 0.1443 (0.176 sec/step)\n",
            "I0601 12:17:25.438885 140438660523904 learning.py:507] global step 8086: loss = 0.1443 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8087: loss = 0.1439 (0.175 sec/step)\n",
            "I0601 12:17:25.615262 140438660523904 learning.py:507] global step 8087: loss = 0.1439 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8088: loss = 0.0182 (0.160 sec/step)\n",
            "I0601 12:17:25.776971 140438660523904 learning.py:507] global step 8088: loss = 0.0182 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8089: loss = 0.0464 (0.144 sec/step)\n",
            "I0601 12:17:25.922099 140438660523904 learning.py:507] global step 8089: loss = 0.0464 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 8090: loss = 0.0911 (0.186 sec/step)\n",
            "I0601 12:17:26.109368 140438660523904 learning.py:507] global step 8090: loss = 0.0911 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8091: loss = 0.1782 (0.174 sec/step)\n",
            "I0601 12:17:26.285211 140438660523904 learning.py:507] global step 8091: loss = 0.1782 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8092: loss = 0.0524 (0.146 sec/step)\n",
            "I0601 12:17:26.432740 140438660523904 learning.py:507] global step 8092: loss = 0.0524 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 8093: loss = 0.1570 (0.166 sec/step)\n",
            "I0601 12:17:26.600540 140438660523904 learning.py:507] global step 8093: loss = 0.1570 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8094: loss = 4.3146 (0.177 sec/step)\n",
            "I0601 12:17:26.779046 140438660523904 learning.py:507] global step 8094: loss = 4.3146 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8095: loss = 0.1498 (0.186 sec/step)\n",
            "I0601 12:17:26.966186 140438660523904 learning.py:507] global step 8095: loss = 0.1498 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8096: loss = 4.0773 (0.172 sec/step)\n",
            "I0601 12:17:27.139935 140438660523904 learning.py:507] global step 8096: loss = 4.0773 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8097: loss = 0.0439 (0.158 sec/step)\n",
            "I0601 12:17:27.299317 140438660523904 learning.py:507] global step 8097: loss = 0.0439 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8098: loss = 0.2062 (0.260 sec/step)\n",
            "I0601 12:17:27.564299 140438660523904 learning.py:507] global step 8098: loss = 0.2062 (0.260 sec/step)\n",
            "INFO:tensorflow:global step 8099: loss = 0.1042 (0.230 sec/step)\n",
            "I0601 12:17:27.837899 140438660523904 learning.py:507] global step 8099: loss = 0.1042 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8100: loss = 0.0188 (0.310 sec/step)\n",
            "I0601 12:17:28.150361 140438660523904 learning.py:507] global step 8100: loss = 0.0188 (0.310 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8100.\n",
            "I0601 12:17:28.358179 140435003524864 supervisor.py:1050] Recording summary at step 8100.\n",
            "INFO:tensorflow:global step 8101: loss = 0.3846 (0.243 sec/step)\n",
            "I0601 12:17:28.394668 140438660523904 learning.py:507] global step 8101: loss = 0.3846 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8102: loss = 0.1022 (0.174 sec/step)\n",
            "I0601 12:17:28.570025 140438660523904 learning.py:507] global step 8102: loss = 0.1022 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8103: loss = 0.1009 (0.178 sec/step)\n",
            "I0601 12:17:28.749133 140438660523904 learning.py:507] global step 8103: loss = 0.1009 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8104: loss = 0.0989 (0.150 sec/step)\n",
            "I0601 12:17:28.901628 140438660523904 learning.py:507] global step 8104: loss = 0.0989 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8105: loss = 0.0301 (0.193 sec/step)\n",
            "I0601 12:17:29.096491 140438660523904 learning.py:507] global step 8105: loss = 0.0301 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8106: loss = 0.0359 (0.168 sec/step)\n",
            "I0601 12:17:29.266087 140438660523904 learning.py:507] global step 8106: loss = 0.0359 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8107: loss = 0.0230 (0.171 sec/step)\n",
            "I0601 12:17:29.438571 140438660523904 learning.py:507] global step 8107: loss = 0.0230 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8108: loss = 0.0621 (0.163 sec/step)\n",
            "I0601 12:17:29.602798 140438660523904 learning.py:507] global step 8108: loss = 0.0621 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8109: loss = 0.2087 (0.176 sec/step)\n",
            "I0601 12:17:29.780111 140438660523904 learning.py:507] global step 8109: loss = 0.2087 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8110: loss = 0.2386 (0.155 sec/step)\n",
            "I0601 12:17:29.936129 140438660523904 learning.py:507] global step 8110: loss = 0.2386 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8111: loss = 0.1301 (0.181 sec/step)\n",
            "I0601 12:17:30.118308 140438660523904 learning.py:507] global step 8111: loss = 0.1301 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8112: loss = 0.1325 (0.179 sec/step)\n",
            "I0601 12:17:30.298655 140438660523904 learning.py:507] global step 8112: loss = 0.1325 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8113: loss = 0.2668 (0.178 sec/step)\n",
            "I0601 12:17:30.477713 140438660523904 learning.py:507] global step 8113: loss = 0.2668 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8114: loss = 0.0297 (0.151 sec/step)\n",
            "I0601 12:17:30.630092 140438660523904 learning.py:507] global step 8114: loss = 0.0297 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8115: loss = 0.1856 (0.173 sec/step)\n",
            "I0601 12:17:30.804817 140438660523904 learning.py:507] global step 8115: loss = 0.1856 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8116: loss = 0.0548 (0.148 sec/step)\n",
            "I0601 12:17:30.954607 140438660523904 learning.py:507] global step 8116: loss = 0.0548 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 8117: loss = 0.0727 (0.174 sec/step)\n",
            "I0601 12:17:31.130015 140438660523904 learning.py:507] global step 8117: loss = 0.0727 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8118: loss = 0.0637 (0.166 sec/step)\n",
            "I0601 12:17:31.297782 140438660523904 learning.py:507] global step 8118: loss = 0.0637 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8119: loss = 0.0483 (0.163 sec/step)\n",
            "I0601 12:17:31.461777 140438660523904 learning.py:507] global step 8119: loss = 0.0483 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8120: loss = 0.0544 (0.161 sec/step)\n",
            "I0601 12:17:31.624091 140438660523904 learning.py:507] global step 8120: loss = 0.0544 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8121: loss = 0.4634 (0.169 sec/step)\n",
            "I0601 12:17:31.794559 140438660523904 learning.py:507] global step 8121: loss = 0.4634 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8122: loss = 0.2773 (0.167 sec/step)\n",
            "I0601 12:17:31.962738 140438660523904 learning.py:507] global step 8122: loss = 0.2773 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8123: loss = 0.0990 (0.177 sec/step)\n",
            "I0601 12:17:32.141173 140438660523904 learning.py:507] global step 8123: loss = 0.0990 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8124: loss = 0.2371 (0.174 sec/step)\n",
            "I0601 12:17:32.316137 140438660523904 learning.py:507] global step 8124: loss = 0.2371 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8125: loss = 0.1354 (0.188 sec/step)\n",
            "I0601 12:17:32.505648 140438660523904 learning.py:507] global step 8125: loss = 0.1354 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8126: loss = 0.2421 (0.176 sec/step)\n",
            "I0601 12:17:32.683182 140438660523904 learning.py:507] global step 8126: loss = 0.2421 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8127: loss = 0.0971 (0.158 sec/step)\n",
            "I0601 12:17:32.843049 140438660523904 learning.py:507] global step 8127: loss = 0.0971 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8128: loss = 0.0249 (0.177 sec/step)\n",
            "I0601 12:17:33.021336 140438660523904 learning.py:507] global step 8128: loss = 0.0249 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8129: loss = 0.1468 (0.160 sec/step)\n",
            "I0601 12:17:33.182624 140438660523904 learning.py:507] global step 8129: loss = 0.1468 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8130: loss = 0.2260 (0.200 sec/step)\n",
            "I0601 12:17:33.384285 140438660523904 learning.py:507] global step 8130: loss = 0.2260 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 8131: loss = 0.0386 (0.171 sec/step)\n",
            "I0601 12:17:33.556200 140438660523904 learning.py:507] global step 8131: loss = 0.0386 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8132: loss = 0.1071 (0.190 sec/step)\n",
            "I0601 12:17:33.747016 140438660523904 learning.py:507] global step 8132: loss = 0.1071 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8133: loss = 0.1121 (0.159 sec/step)\n",
            "I0601 12:17:33.907044 140438660523904 learning.py:507] global step 8133: loss = 0.1121 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8134: loss = 0.0770 (0.160 sec/step)\n",
            "I0601 12:17:34.068712 140438660523904 learning.py:507] global step 8134: loss = 0.0770 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8135: loss = 0.2782 (0.189 sec/step)\n",
            "I0601 12:17:34.258827 140438660523904 learning.py:507] global step 8135: loss = 0.2782 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8136: loss = 0.4926 (0.178 sec/step)\n",
            "I0601 12:17:34.438434 140438660523904 learning.py:507] global step 8136: loss = 0.4926 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8137: loss = 0.0454 (0.176 sec/step)\n",
            "I0601 12:17:34.616344 140438660523904 learning.py:507] global step 8137: loss = 0.0454 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8138: loss = 0.1572 (0.177 sec/step)\n",
            "I0601 12:17:34.794861 140438660523904 learning.py:507] global step 8138: loss = 0.1572 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8139: loss = 0.3919 (0.177 sec/step)\n",
            "I0601 12:17:34.973293 140438660523904 learning.py:507] global step 8139: loss = 0.3919 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8140: loss = 0.1188 (0.170 sec/step)\n",
            "I0601 12:17:35.145083 140438660523904 learning.py:507] global step 8140: loss = 0.1188 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8141: loss = 0.2964 (0.183 sec/step)\n",
            "I0601 12:17:35.329753 140438660523904 learning.py:507] global step 8141: loss = 0.2964 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8142: loss = 0.1461 (0.175 sec/step)\n",
            "I0601 12:17:35.506421 140438660523904 learning.py:507] global step 8142: loss = 0.1461 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8143: loss = 0.1179 (0.164 sec/step)\n",
            "I0601 12:17:35.671520 140438660523904 learning.py:507] global step 8143: loss = 0.1179 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8144: loss = 0.1955 (0.168 sec/step)\n",
            "I0601 12:17:35.840802 140438660523904 learning.py:507] global step 8144: loss = 0.1955 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8145: loss = 0.2290 (0.182 sec/step)\n",
            "I0601 12:17:36.024673 140438660523904 learning.py:507] global step 8145: loss = 0.2290 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8146: loss = 0.1013 (0.199 sec/step)\n",
            "I0601 12:17:36.224622 140438660523904 learning.py:507] global step 8146: loss = 0.1013 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 8147: loss = 0.2389 (0.178 sec/step)\n",
            "I0601 12:17:36.404526 140438660523904 learning.py:507] global step 8147: loss = 0.2389 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8148: loss = 0.2630 (0.164 sec/step)\n",
            "I0601 12:17:36.569627 140438660523904 learning.py:507] global step 8148: loss = 0.2630 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8149: loss = 0.1320 (0.171 sec/step)\n",
            "I0601 12:17:36.742214 140438660523904 learning.py:507] global step 8149: loss = 0.1320 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8150: loss = 0.4310 (0.183 sec/step)\n",
            "I0601 12:17:36.927192 140438660523904 learning.py:507] global step 8150: loss = 0.4310 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8151: loss = 0.3379 (0.193 sec/step)\n",
            "I0601 12:17:37.121585 140438660523904 learning.py:507] global step 8151: loss = 0.3379 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8152: loss = 0.0737 (0.150 sec/step)\n",
            "I0601 12:17:37.272892 140438660523904 learning.py:507] global step 8152: loss = 0.0737 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8153: loss = 0.4334 (0.163 sec/step)\n",
            "I0601 12:17:37.437543 140438660523904 learning.py:507] global step 8153: loss = 0.4334 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8154: loss = 0.0744 (0.155 sec/step)\n",
            "I0601 12:17:37.594336 140438660523904 learning.py:507] global step 8154: loss = 0.0744 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8155: loss = 0.3720 (0.185 sec/step)\n",
            "I0601 12:17:37.781052 140438660523904 learning.py:507] global step 8155: loss = 0.3720 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8156: loss = 0.2038 (0.171 sec/step)\n",
            "I0601 12:17:37.952996 140438660523904 learning.py:507] global step 8156: loss = 0.2038 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8157: loss = 0.1340 (0.157 sec/step)\n",
            "I0601 12:17:38.111343 140438660523904 learning.py:507] global step 8157: loss = 0.1340 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8158: loss = 0.1054 (0.168 sec/step)\n",
            "I0601 12:17:38.281014 140438660523904 learning.py:507] global step 8158: loss = 0.1054 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8159: loss = 0.0948 (0.186 sec/step)\n",
            "I0601 12:17:38.468376 140438660523904 learning.py:507] global step 8159: loss = 0.0948 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8160: loss = 0.0931 (0.170 sec/step)\n",
            "I0601 12:17:38.639697 140438660523904 learning.py:507] global step 8160: loss = 0.0931 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8161: loss = 0.1462 (0.206 sec/step)\n",
            "I0601 12:17:38.847503 140438660523904 learning.py:507] global step 8161: loss = 0.1462 (0.206 sec/step)\n",
            "INFO:tensorflow:global step 8162: loss = 0.1284 (0.172 sec/step)\n",
            "I0601 12:17:39.021554 140438660523904 learning.py:507] global step 8162: loss = 0.1284 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8163: loss = 0.1444 (0.189 sec/step)\n",
            "I0601 12:17:39.212416 140438660523904 learning.py:507] global step 8163: loss = 0.1444 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8164: loss = 0.2200 (0.178 sec/step)\n",
            "I0601 12:17:39.392060 140438660523904 learning.py:507] global step 8164: loss = 0.2200 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8165: loss = 0.0806 (0.170 sec/step)\n",
            "I0601 12:17:39.563820 140438660523904 learning.py:507] global step 8165: loss = 0.0806 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8166: loss = 0.0663 (0.165 sec/step)\n",
            "I0601 12:17:39.729992 140438660523904 learning.py:507] global step 8166: loss = 0.0663 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8167: loss = 0.0928 (0.166 sec/step)\n",
            "I0601 12:17:39.897193 140438660523904 learning.py:507] global step 8167: loss = 0.0928 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8168: loss = 0.5341 (0.160 sec/step)\n",
            "I0601 12:17:40.058838 140438660523904 learning.py:507] global step 8168: loss = 0.5341 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8169: loss = 0.2122 (0.222 sec/step)\n",
            "I0601 12:17:40.282033 140438660523904 learning.py:507] global step 8169: loss = 0.2122 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8170: loss = 0.0383 (0.146 sec/step)\n",
            "I0601 12:17:40.429419 140438660523904 learning.py:507] global step 8170: loss = 0.0383 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 8171: loss = 0.0407 (0.157 sec/step)\n",
            "I0601 12:17:40.588859 140438660523904 learning.py:507] global step 8171: loss = 0.0407 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8172: loss = 0.0207 (0.175 sec/step)\n",
            "I0601 12:17:40.764960 140438660523904 learning.py:507] global step 8172: loss = 0.0207 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8173: loss = 0.0350 (0.191 sec/step)\n",
            "I0601 12:17:40.957800 140438660523904 learning.py:507] global step 8173: loss = 0.0350 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8174: loss = 0.0888 (0.173 sec/step)\n",
            "I0601 12:17:41.131628 140438660523904 learning.py:507] global step 8174: loss = 0.0888 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8175: loss = 0.0814 (0.180 sec/step)\n",
            "I0601 12:17:41.312689 140438660523904 learning.py:507] global step 8175: loss = 0.0814 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8176: loss = 0.0247 (0.186 sec/step)\n",
            "I0601 12:17:41.499781 140438660523904 learning.py:507] global step 8176: loss = 0.0247 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8177: loss = 0.0283 (0.174 sec/step)\n",
            "I0601 12:17:41.675266 140438660523904 learning.py:507] global step 8177: loss = 0.0283 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8178: loss = 0.0709 (0.180 sec/step)\n",
            "I0601 12:17:41.856821 140438660523904 learning.py:507] global step 8178: loss = 0.0709 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8179: loss = 0.0657 (0.158 sec/step)\n",
            "I0601 12:17:42.016138 140438660523904 learning.py:507] global step 8179: loss = 0.0657 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8180: loss = 0.0249 (0.149 sec/step)\n",
            "I0601 12:17:42.166724 140438660523904 learning.py:507] global step 8180: loss = 0.0249 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 8181: loss = 0.1587 (0.179 sec/step)\n",
            "I0601 12:17:42.347264 140438660523904 learning.py:507] global step 8181: loss = 0.1587 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8182: loss = 0.1323 (0.184 sec/step)\n",
            "I0601 12:17:42.533026 140438660523904 learning.py:507] global step 8182: loss = 0.1323 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8183: loss = 0.1195 (0.212 sec/step)\n",
            "I0601 12:17:42.746206 140438660523904 learning.py:507] global step 8183: loss = 0.1195 (0.212 sec/step)\n",
            "INFO:tensorflow:global step 8184: loss = 0.0813 (0.181 sec/step)\n",
            "I0601 12:17:42.928533 140438660523904 learning.py:507] global step 8184: loss = 0.0813 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8185: loss = 0.0913 (0.184 sec/step)\n",
            "I0601 12:17:43.114237 140438660523904 learning.py:507] global step 8185: loss = 0.0913 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8186: loss = 0.0831 (0.157 sec/step)\n",
            "I0601 12:17:43.272382 140438660523904 learning.py:507] global step 8186: loss = 0.0831 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8187: loss = 0.1249 (0.186 sec/step)\n",
            "I0601 12:17:43.459763 140438660523904 learning.py:507] global step 8187: loss = 0.1249 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8188: loss = 0.3478 (0.186 sec/step)\n",
            "I0601 12:17:43.646935 140438660523904 learning.py:507] global step 8188: loss = 0.3478 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8189: loss = 0.0812 (0.203 sec/step)\n",
            "I0601 12:17:43.851587 140438660523904 learning.py:507] global step 8189: loss = 0.0812 (0.203 sec/step)\n",
            "INFO:tensorflow:global step 8190: loss = 0.1019 (0.180 sec/step)\n",
            "I0601 12:17:44.033319 140438660523904 learning.py:507] global step 8190: loss = 0.1019 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8191: loss = 0.0300 (0.192 sec/step)\n",
            "I0601 12:17:44.226221 140438660523904 learning.py:507] global step 8191: loss = 0.0300 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8192: loss = 0.2883 (0.189 sec/step)\n",
            "I0601 12:17:44.416733 140438660523904 learning.py:507] global step 8192: loss = 0.2883 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8193: loss = 0.3972 (0.166 sec/step)\n",
            "I0601 12:17:44.584693 140438660523904 learning.py:507] global step 8193: loss = 0.3972 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8194: loss = 0.3146 (0.167 sec/step)\n",
            "I0601 12:17:44.752817 140438660523904 learning.py:507] global step 8194: loss = 0.3146 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8195: loss = 0.1045 (0.178 sec/step)\n",
            "I0601 12:17:44.932579 140438660523904 learning.py:507] global step 8195: loss = 0.1045 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8196: loss = 0.1200 (0.172 sec/step)\n",
            "I0601 12:17:45.106495 140438660523904 learning.py:507] global step 8196: loss = 0.1200 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8197: loss = 0.0890 (0.153 sec/step)\n",
            "I0601 12:17:45.261335 140438660523904 learning.py:507] global step 8197: loss = 0.0890 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8198: loss = 4.7232 (0.183 sec/step)\n",
            "I0601 12:17:45.445715 140438660523904 learning.py:507] global step 8198: loss = 4.7232 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8199: loss = 0.4007 (0.156 sec/step)\n",
            "I0601 12:17:45.603468 140438660523904 learning.py:507] global step 8199: loss = 0.4007 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8200: loss = 0.1382 (0.177 sec/step)\n",
            "I0601 12:17:45.781593 140438660523904 learning.py:507] global step 8200: loss = 0.1382 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8201: loss = 0.1136 (0.171 sec/step)\n",
            "I0601 12:17:45.954070 140438660523904 learning.py:507] global step 8201: loss = 0.1136 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8202: loss = 0.0304 (0.171 sec/step)\n",
            "I0601 12:17:46.126729 140438660523904 learning.py:507] global step 8202: loss = 0.0304 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8203: loss = 0.1454 (0.174 sec/step)\n",
            "I0601 12:17:46.303275 140438660523904 learning.py:507] global step 8203: loss = 0.1454 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8204: loss = 0.0941 (0.177 sec/step)\n",
            "I0601 12:17:46.482502 140438660523904 learning.py:507] global step 8204: loss = 0.0941 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8205: loss = 0.1044 (0.151 sec/step)\n",
            "I0601 12:17:46.635599 140438660523904 learning.py:507] global step 8205: loss = 0.1044 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8206: loss = 0.0717 (0.164 sec/step)\n",
            "I0601 12:17:46.801804 140438660523904 learning.py:507] global step 8206: loss = 0.0717 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8207: loss = 0.2753 (0.161 sec/step)\n",
            "I0601 12:17:46.963990 140438660523904 learning.py:507] global step 8207: loss = 0.2753 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8208: loss = 0.0828 (0.187 sec/step)\n",
            "I0601 12:17:47.151860 140438660523904 learning.py:507] global step 8208: loss = 0.0828 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8209: loss = 0.1080 (0.166 sec/step)\n",
            "I0601 12:17:47.319571 140438660523904 learning.py:507] global step 8209: loss = 0.1080 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8210: loss = 0.2995 (0.205 sec/step)\n",
            "I0601 12:17:47.526305 140438660523904 learning.py:507] global step 8210: loss = 0.2995 (0.205 sec/step)\n",
            "INFO:tensorflow:global step 8211: loss = 0.0736 (0.163 sec/step)\n",
            "I0601 12:17:47.690542 140438660523904 learning.py:507] global step 8211: loss = 0.0736 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8212: loss = 0.3300 (0.170 sec/step)\n",
            "I0601 12:17:47.862413 140438660523904 learning.py:507] global step 8212: loss = 0.3300 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8213: loss = 0.2578 (0.159 sec/step)\n",
            "I0601 12:17:48.023219 140438660523904 learning.py:507] global step 8213: loss = 0.2578 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8214: loss = 0.0635 (0.149 sec/step)\n",
            "I0601 12:17:48.173542 140438660523904 learning.py:507] global step 8214: loss = 0.0635 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 8215: loss = 0.2852 (0.160 sec/step)\n",
            "I0601 12:17:48.335688 140438660523904 learning.py:507] global step 8215: loss = 0.2852 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8216: loss = 0.1990 (0.197 sec/step)\n",
            "I0601 12:17:48.534793 140438660523904 learning.py:507] global step 8216: loss = 0.1990 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 8217: loss = 0.1815 (0.145 sec/step)\n",
            "I0601 12:17:48.681050 140438660523904 learning.py:507] global step 8217: loss = 0.1815 (0.145 sec/step)\n",
            "INFO:tensorflow:global step 8218: loss = 0.3395 (0.188 sec/step)\n",
            "I0601 12:17:48.870282 140438660523904 learning.py:507] global step 8218: loss = 0.3395 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8219: loss = 0.0815 (0.173 sec/step)\n",
            "I0601 12:17:49.044523 140438660523904 learning.py:507] global step 8219: loss = 0.0815 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8220: loss = 0.1035 (0.176 sec/step)\n",
            "I0601 12:17:49.222378 140438660523904 learning.py:507] global step 8220: loss = 0.1035 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8221: loss = 0.0379 (0.164 sec/step)\n",
            "I0601 12:17:49.387784 140438660523904 learning.py:507] global step 8221: loss = 0.0379 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8222: loss = 0.0734 (0.166 sec/step)\n",
            "I0601 12:17:49.555201 140438660523904 learning.py:507] global step 8222: loss = 0.0734 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8223: loss = 0.0827 (0.168 sec/step)\n",
            "I0601 12:17:49.724950 140438660523904 learning.py:507] global step 8223: loss = 0.0827 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8224: loss = 0.1585 (0.181 sec/step)\n",
            "I0601 12:17:49.907217 140438660523904 learning.py:507] global step 8224: loss = 0.1585 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8225: loss = 0.1497 (0.163 sec/step)\n",
            "I0601 12:17:50.071964 140438660523904 learning.py:507] global step 8225: loss = 0.1497 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8226: loss = 0.1133 (0.156 sec/step)\n",
            "I0601 12:17:50.229310 140438660523904 learning.py:507] global step 8226: loss = 0.1133 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8227: loss = 0.2340 (0.226 sec/step)\n",
            "I0601 12:17:50.456516 140438660523904 learning.py:507] global step 8227: loss = 0.2340 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8228: loss = 0.0928 (0.179 sec/step)\n",
            "I0601 12:17:50.636749 140438660523904 learning.py:507] global step 8228: loss = 0.0928 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8229: loss = 0.0833 (0.162 sec/step)\n",
            "I0601 12:17:50.800411 140438660523904 learning.py:507] global step 8229: loss = 0.0833 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8230: loss = 0.0533 (0.172 sec/step)\n",
            "I0601 12:17:50.974075 140438660523904 learning.py:507] global step 8230: loss = 0.0533 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8231: loss = 0.3587 (0.179 sec/step)\n",
            "I0601 12:17:51.154379 140438660523904 learning.py:507] global step 8231: loss = 0.3587 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8232: loss = 0.2471 (0.173 sec/step)\n",
            "I0601 12:17:51.328310 140438660523904 learning.py:507] global step 8232: loss = 0.2471 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8233: loss = 0.2405 (0.173 sec/step)\n",
            "I0601 12:17:51.502489 140438660523904 learning.py:507] global step 8233: loss = 0.2405 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8234: loss = 0.1445 (0.174 sec/step)\n",
            "I0601 12:17:51.678134 140438660523904 learning.py:507] global step 8234: loss = 0.1445 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8235: loss = 0.1057 (0.166 sec/step)\n",
            "I0601 12:17:51.846955 140438660523904 learning.py:507] global step 8235: loss = 0.1057 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8236: loss = 0.0852 (0.180 sec/step)\n",
            "I0601 12:17:52.027834 140438660523904 learning.py:507] global step 8236: loss = 0.0852 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8237: loss = 0.3660 (0.168 sec/step)\n",
            "I0601 12:17:52.197420 140438660523904 learning.py:507] global step 8237: loss = 0.3660 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8238: loss = 0.1296 (0.148 sec/step)\n",
            "I0601 12:17:52.346989 140438660523904 learning.py:507] global step 8238: loss = 0.1296 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 8239: loss = 0.1900 (0.188 sec/step)\n",
            "I0601 12:17:52.536075 140438660523904 learning.py:507] global step 8239: loss = 0.1900 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8240: loss = 0.1609 (0.189 sec/step)\n",
            "I0601 12:17:52.726628 140438660523904 learning.py:507] global step 8240: loss = 0.1609 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8241: loss = 0.2186 (0.177 sec/step)\n",
            "I0601 12:17:52.905441 140438660523904 learning.py:507] global step 8241: loss = 0.2186 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8242: loss = 0.1802 (0.159 sec/step)\n",
            "I0601 12:17:53.066468 140438660523904 learning.py:507] global step 8242: loss = 0.1802 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8243: loss = 0.4135 (0.176 sec/step)\n",
            "I0601 12:17:53.243812 140438660523904 learning.py:507] global step 8243: loss = 0.4135 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8244: loss = 0.0840 (0.133 sec/step)\n",
            "I0601 12:17:53.377661 140438660523904 learning.py:507] global step 8244: loss = 0.0840 (0.133 sec/step)\n",
            "INFO:tensorflow:global step 8245: loss = 0.0753 (0.194 sec/step)\n",
            "I0601 12:17:53.573551 140438660523904 learning.py:507] global step 8245: loss = 0.0753 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8246: loss = 0.0950 (0.150 sec/step)\n",
            "I0601 12:17:53.725213 140438660523904 learning.py:507] global step 8246: loss = 0.0950 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8247: loss = 0.0433 (0.170 sec/step)\n",
            "I0601 12:17:53.897103 140438660523904 learning.py:507] global step 8247: loss = 0.0433 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8248: loss = 0.0834 (0.153 sec/step)\n",
            "I0601 12:17:54.051121 140438660523904 learning.py:507] global step 8248: loss = 0.0834 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8249: loss = 0.1511 (0.202 sec/step)\n",
            "I0601 12:17:54.255061 140438660523904 learning.py:507] global step 8249: loss = 0.1511 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 8250: loss = 0.2213 (0.176 sec/step)\n",
            "I0601 12:17:54.432281 140438660523904 learning.py:507] global step 8250: loss = 0.2213 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8251: loss = 0.1818 (0.176 sec/step)\n",
            "I0601 12:17:54.609816 140438660523904 learning.py:507] global step 8251: loss = 0.1818 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8252: loss = 0.2882 (0.193 sec/step)\n",
            "I0601 12:17:54.804108 140438660523904 learning.py:507] global step 8252: loss = 0.2882 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8253: loss = 0.1088 (0.152 sec/step)\n",
            "I0601 12:17:54.957288 140438660523904 learning.py:507] global step 8253: loss = 0.1088 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8254: loss = 0.1283 (0.172 sec/step)\n",
            "I0601 12:17:55.131172 140438660523904 learning.py:507] global step 8254: loss = 0.1283 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8255: loss = 0.1097 (0.166 sec/step)\n",
            "I0601 12:17:55.298668 140438660523904 learning.py:507] global step 8255: loss = 0.1097 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8256: loss = 0.0654 (0.185 sec/step)\n",
            "I0601 12:17:55.484665 140438660523904 learning.py:507] global step 8256: loss = 0.0654 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8257: loss = 0.1741 (0.175 sec/step)\n",
            "I0601 12:17:55.661491 140438660523904 learning.py:507] global step 8257: loss = 0.1741 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8258: loss = 0.1540 (0.185 sec/step)\n",
            "I0601 12:17:55.848189 140438660523904 learning.py:507] global step 8258: loss = 0.1540 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8259: loss = 0.2643 (0.174 sec/step)\n",
            "I0601 12:17:56.023989 140438660523904 learning.py:507] global step 8259: loss = 0.2643 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8260: loss = 0.2013 (0.163 sec/step)\n",
            "I0601 12:17:56.188658 140438660523904 learning.py:507] global step 8260: loss = 0.2013 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8261: loss = 0.1195 (0.171 sec/step)\n",
            "I0601 12:17:56.360627 140438660523904 learning.py:507] global step 8261: loss = 0.1195 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8262: loss = 0.1637 (0.204 sec/step)\n",
            "I0601 12:17:56.566450 140438660523904 learning.py:507] global step 8262: loss = 0.1637 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 8263: loss = 0.0196 (0.168 sec/step)\n",
            "I0601 12:17:56.735751 140438660523904 learning.py:507] global step 8263: loss = 0.0196 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8264: loss = 0.0274 (0.182 sec/step)\n",
            "I0601 12:17:56.919392 140438660523904 learning.py:507] global step 8264: loss = 0.0274 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8265: loss = 0.0623 (0.168 sec/step)\n",
            "I0601 12:17:57.088878 140438660523904 learning.py:507] global step 8265: loss = 0.0623 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8266: loss = 0.1486 (0.172 sec/step)\n",
            "I0601 12:17:57.262319 140438660523904 learning.py:507] global step 8266: loss = 0.1486 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8267: loss = 0.0921 (0.162 sec/step)\n",
            "I0601 12:17:57.426125 140438660523904 learning.py:507] global step 8267: loss = 0.0921 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8268: loss = 0.1927 (0.173 sec/step)\n",
            "I0601 12:17:57.600745 140438660523904 learning.py:507] global step 8268: loss = 0.1927 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8269: loss = 0.0511 (0.167 sec/step)\n",
            "I0601 12:17:57.768984 140438660523904 learning.py:507] global step 8269: loss = 0.0511 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8270: loss = 0.0976 (0.173 sec/step)\n",
            "I0601 12:17:57.943004 140438660523904 learning.py:507] global step 8270: loss = 0.0976 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8271: loss = 0.1081 (0.165 sec/step)\n",
            "I0601 12:17:58.109526 140438660523904 learning.py:507] global step 8271: loss = 0.1081 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8272: loss = 0.2024 (0.164 sec/step)\n",
            "I0601 12:17:58.274752 140438660523904 learning.py:507] global step 8272: loss = 0.2024 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8273: loss = 0.1813 (0.159 sec/step)\n",
            "I0601 12:17:58.435109 140438660523904 learning.py:507] global step 8273: loss = 0.1813 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8274: loss = 0.1231 (0.183 sec/step)\n",
            "I0601 12:17:58.620003 140438660523904 learning.py:507] global step 8274: loss = 0.1231 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8275: loss = 0.0892 (0.167 sec/step)\n",
            "I0601 12:17:58.788440 140438660523904 learning.py:507] global step 8275: loss = 0.0892 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8276: loss = 0.0863 (0.178 sec/step)\n",
            "I0601 12:17:58.967521 140438660523904 learning.py:507] global step 8276: loss = 0.0863 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8277: loss = 0.1161 (0.158 sec/step)\n",
            "I0601 12:17:59.126970 140438660523904 learning.py:507] global step 8277: loss = 0.1161 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8278: loss = 0.1473 (0.176 sec/step)\n",
            "I0601 12:17:59.304165 140438660523904 learning.py:507] global step 8278: loss = 0.1473 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8279: loss = 0.0711 (0.171 sec/step)\n",
            "I0601 12:17:59.476503 140438660523904 learning.py:507] global step 8279: loss = 0.0711 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8280: loss = 0.0479 (0.169 sec/step)\n",
            "I0601 12:17:59.646673 140438660523904 learning.py:507] global step 8280: loss = 0.0479 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8281: loss = 0.1655 (0.151 sec/step)\n",
            "I0601 12:17:59.798675 140438660523904 learning.py:507] global step 8281: loss = 0.1655 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8282: loss = 0.0178 (0.170 sec/step)\n",
            "I0601 12:17:59.969706 140438660523904 learning.py:507] global step 8282: loss = 0.0178 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8283: loss = 0.0814 (0.163 sec/step)\n",
            "I0601 12:18:00.134658 140438660523904 learning.py:507] global step 8283: loss = 0.0814 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8284: loss = 0.2330 (0.179 sec/step)\n",
            "I0601 12:18:00.314728 140438660523904 learning.py:507] global step 8284: loss = 0.2330 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8285: loss = 0.1073 (0.173 sec/step)\n",
            "I0601 12:18:00.489080 140438660523904 learning.py:507] global step 8285: loss = 0.1073 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8286: loss = 0.0846 (0.166 sec/step)\n",
            "I0601 12:18:00.656502 140438660523904 learning.py:507] global step 8286: loss = 0.0846 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8287: loss = 0.0441 (0.170 sec/step)\n",
            "I0601 12:18:00.828282 140438660523904 learning.py:507] global step 8287: loss = 0.0441 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8288: loss = 0.1687 (0.188 sec/step)\n",
            "I0601 12:18:01.017498 140438660523904 learning.py:507] global step 8288: loss = 0.1687 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8289: loss = 0.0325 (0.165 sec/step)\n",
            "I0601 12:18:01.183450 140438660523904 learning.py:507] global step 8289: loss = 0.0325 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8290: loss = 0.1693 (0.171 sec/step)\n",
            "I0601 12:18:01.356086 140438660523904 learning.py:507] global step 8290: loss = 0.1693 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8291: loss = 0.3041 (0.176 sec/step)\n",
            "I0601 12:18:01.533645 140438660523904 learning.py:507] global step 8291: loss = 0.3041 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8292: loss = 0.1382 (0.154 sec/step)\n",
            "I0601 12:18:01.689277 140438660523904 learning.py:507] global step 8292: loss = 0.1382 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8293: loss = 0.0328 (0.181 sec/step)\n",
            "I0601 12:18:01.871454 140438660523904 learning.py:507] global step 8293: loss = 0.0328 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8294: loss = 0.1597 (0.196 sec/step)\n",
            "I0601 12:18:02.068491 140438660523904 learning.py:507] global step 8294: loss = 0.1597 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 8295: loss = 0.1158 (0.165 sec/step)\n",
            "I0601 12:18:02.234945 140438660523904 learning.py:507] global step 8295: loss = 0.1158 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8296: loss = 0.2453 (0.179 sec/step)\n",
            "I0601 12:18:02.415365 140438660523904 learning.py:507] global step 8296: loss = 0.2453 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8297: loss = 0.1011 (0.175 sec/step)\n",
            "I0601 12:18:02.591947 140438660523904 learning.py:507] global step 8297: loss = 0.1011 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8298: loss = 0.1492 (0.172 sec/step)\n",
            "I0601 12:18:02.765810 140438660523904 learning.py:507] global step 8298: loss = 0.1492 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8299: loss = 0.0690 (0.177 sec/step)\n",
            "I0601 12:18:02.944185 140438660523904 learning.py:507] global step 8299: loss = 0.0690 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8300: loss = 0.1181 (0.177 sec/step)\n",
            "I0601 12:18:03.122611 140438660523904 learning.py:507] global step 8300: loss = 0.1181 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8301: loss = 0.2156 (0.177 sec/step)\n",
            "I0601 12:18:03.301071 140438660523904 learning.py:507] global step 8301: loss = 0.2156 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8302: loss = 0.0499 (0.184 sec/step)\n",
            "I0601 12:18:03.486629 140438660523904 learning.py:507] global step 8302: loss = 0.0499 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8303: loss = 0.0418 (0.150 sec/step)\n",
            "I0601 12:18:03.637852 140438660523904 learning.py:507] global step 8303: loss = 0.0418 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8304: loss = 0.0770 (0.184 sec/step)\n",
            "I0601 12:18:03.823493 140438660523904 learning.py:507] global step 8304: loss = 0.0770 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8305: loss = 0.2543 (0.194 sec/step)\n",
            "I0601 12:18:04.018858 140438660523904 learning.py:507] global step 8305: loss = 0.2543 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8306: loss = 0.0827 (0.155 sec/step)\n",
            "I0601 12:18:04.175607 140438660523904 learning.py:507] global step 8306: loss = 0.0827 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8307: loss = 0.2629 (0.170 sec/step)\n",
            "I0601 12:18:04.346686 140438660523904 learning.py:507] global step 8307: loss = 0.2629 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8308: loss = 0.1063 (0.181 sec/step)\n",
            "I0601 12:18:04.528793 140438660523904 learning.py:507] global step 8308: loss = 0.1063 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8309: loss = 0.1538 (0.173 sec/step)\n",
            "I0601 12:18:04.702776 140438660523904 learning.py:507] global step 8309: loss = 0.1538 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8310: loss = 0.0900 (0.213 sec/step)\n",
            "I0601 12:18:04.917280 140438660523904 learning.py:507] global step 8310: loss = 0.0900 (0.213 sec/step)\n",
            "INFO:tensorflow:global step 8311: loss = 0.0691 (0.195 sec/step)\n",
            "I0601 12:18:05.113843 140438660523904 learning.py:507] global step 8311: loss = 0.0691 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8312: loss = 0.0472 (0.163 sec/step)\n",
            "I0601 12:18:05.277983 140438660523904 learning.py:507] global step 8312: loss = 0.0472 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8313: loss = 4.5130 (0.182 sec/step)\n",
            "I0601 12:18:05.461388 140438660523904 learning.py:507] global step 8313: loss = 4.5130 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8314: loss = 0.1317 (0.187 sec/step)\n",
            "I0601 12:18:05.650089 140438660523904 learning.py:507] global step 8314: loss = 0.1317 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8315: loss = 0.0975 (0.200 sec/step)\n",
            "I0601 12:18:05.851471 140438660523904 learning.py:507] global step 8315: loss = 0.0975 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 8316: loss = 0.1507 (0.155 sec/step)\n",
            "I0601 12:18:06.007574 140438660523904 learning.py:507] global step 8316: loss = 0.1507 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8317: loss = 0.1663 (0.162 sec/step)\n",
            "I0601 12:18:06.170955 140438660523904 learning.py:507] global step 8317: loss = 0.1663 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8318: loss = 0.0575 (0.165 sec/step)\n",
            "I0601 12:18:06.336871 140438660523904 learning.py:507] global step 8318: loss = 0.0575 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8319: loss = 0.1493 (0.182 sec/step)\n",
            "I0601 12:18:06.520495 140438660523904 learning.py:507] global step 8319: loss = 0.1493 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8320: loss = 0.1154 (0.184 sec/step)\n",
            "I0601 12:18:06.705659 140438660523904 learning.py:507] global step 8320: loss = 0.1154 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8321: loss = 0.0855 (0.170 sec/step)\n",
            "I0601 12:18:06.877604 140438660523904 learning.py:507] global step 8321: loss = 0.0855 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8322: loss = 0.0625 (0.170 sec/step)\n",
            "I0601 12:18:07.048780 140438660523904 learning.py:507] global step 8322: loss = 0.0625 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8323: loss = 0.1076 (0.165 sec/step)\n",
            "I0601 12:18:07.214716 140438660523904 learning.py:507] global step 8323: loss = 0.1076 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8324: loss = 0.0539 (0.175 sec/step)\n",
            "I0601 12:18:07.391026 140438660523904 learning.py:507] global step 8324: loss = 0.0539 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8325: loss = 0.2183 (0.195 sec/step)\n",
            "I0601 12:18:07.587312 140438660523904 learning.py:507] global step 8325: loss = 0.2183 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8326: loss = 0.1108 (0.194 sec/step)\n",
            "I0601 12:18:07.782815 140438660523904 learning.py:507] global step 8326: loss = 0.1108 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8327: loss = 0.0348 (0.141 sec/step)\n",
            "I0601 12:18:07.925091 140438660523904 learning.py:507] global step 8327: loss = 0.0348 (0.141 sec/step)\n",
            "INFO:tensorflow:global step 8328: loss = 0.0784 (0.154 sec/step)\n",
            "I0601 12:18:08.080729 140438660523904 learning.py:507] global step 8328: loss = 0.0784 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8329: loss = 0.1724 (0.181 sec/step)\n",
            "I0601 12:18:08.262951 140438660523904 learning.py:507] global step 8329: loss = 0.1724 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8330: loss = 0.0701 (0.197 sec/step)\n",
            "I0601 12:18:08.461347 140438660523904 learning.py:507] global step 8330: loss = 0.0701 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 8331: loss = 0.1265 (0.178 sec/step)\n",
            "I0601 12:18:08.641086 140438660523904 learning.py:507] global step 8331: loss = 0.1265 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8332: loss = 0.0899 (0.178 sec/step)\n",
            "I0601 12:18:08.820689 140438660523904 learning.py:507] global step 8332: loss = 0.0899 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8333: loss = 0.2759 (0.164 sec/step)\n",
            "I0601 12:18:08.986003 140438660523904 learning.py:507] global step 8333: loss = 0.2759 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8334: loss = 0.1396 (0.168 sec/step)\n",
            "I0601 12:18:09.155516 140438660523904 learning.py:507] global step 8334: loss = 0.1396 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8335: loss = 0.1690 (0.175 sec/step)\n",
            "I0601 12:18:09.331431 140438660523904 learning.py:507] global step 8335: loss = 0.1690 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8336: loss = 0.1844 (0.200 sec/step)\n",
            "I0601 12:18:09.532836 140438660523904 learning.py:507] global step 8336: loss = 0.1844 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 8337: loss = 0.2252 (0.174 sec/step)\n",
            "I0601 12:18:09.708703 140438660523904 learning.py:507] global step 8337: loss = 0.2252 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8338: loss = 0.0222 (0.167 sec/step)\n",
            "I0601 12:18:09.876947 140438660523904 learning.py:507] global step 8338: loss = 0.0222 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8339: loss = 0.0997 (0.172 sec/step)\n",
            "I0601 12:18:10.050733 140438660523904 learning.py:507] global step 8339: loss = 0.0997 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8340: loss = 0.0288 (0.188 sec/step)\n",
            "I0601 12:18:10.240042 140438660523904 learning.py:507] global step 8340: loss = 0.0288 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8341: loss = 0.0892 (0.189 sec/step)\n",
            "I0601 12:18:10.430611 140438660523904 learning.py:507] global step 8341: loss = 0.0892 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8342: loss = 0.1722 (0.169 sec/step)\n",
            "I0601 12:18:10.600823 140438660523904 learning.py:507] global step 8342: loss = 0.1722 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8343: loss = 0.0681 (0.181 sec/step)\n",
            "I0601 12:18:10.783512 140438660523904 learning.py:507] global step 8343: loss = 0.0681 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8344: loss = 0.3398 (0.155 sec/step)\n",
            "I0601 12:18:10.939388 140438660523904 learning.py:507] global step 8344: loss = 0.3398 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8345: loss = 0.1277 (0.179 sec/step)\n",
            "I0601 12:18:11.119800 140438660523904 learning.py:507] global step 8345: loss = 0.1277 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8346: loss = 0.1803 (0.157 sec/step)\n",
            "I0601 12:18:11.278675 140438660523904 learning.py:507] global step 8346: loss = 0.1803 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8347: loss = 0.0820 (0.193 sec/step)\n",
            "I0601 12:18:11.473160 140438660523904 learning.py:507] global step 8347: loss = 0.0820 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8348: loss = 0.0581 (0.151 sec/step)\n",
            "I0601 12:18:11.625908 140438660523904 learning.py:507] global step 8348: loss = 0.0581 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8349: loss = 0.1195 (0.175 sec/step)\n",
            "I0601 12:18:11.802582 140438660523904 learning.py:507] global step 8349: loss = 0.1195 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8350: loss = 0.1084 (0.167 sec/step)\n",
            "I0601 12:18:11.970897 140438660523904 learning.py:507] global step 8350: loss = 0.1084 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8351: loss = 0.0934 (0.166 sec/step)\n",
            "I0601 12:18:12.138144 140438660523904 learning.py:507] global step 8351: loss = 0.0934 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8352: loss = 0.2921 (0.158 sec/step)\n",
            "I0601 12:18:12.298027 140438660523904 learning.py:507] global step 8352: loss = 0.2921 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8353: loss = 4.5954 (0.171 sec/step)\n",
            "I0601 12:18:12.471026 140438660523904 learning.py:507] global step 8353: loss = 4.5954 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8354: loss = 0.0696 (0.160 sec/step)\n",
            "I0601 12:18:12.632368 140438660523904 learning.py:507] global step 8354: loss = 0.0696 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8355: loss = 0.1651 (0.180 sec/step)\n",
            "I0601 12:18:12.813711 140438660523904 learning.py:507] global step 8355: loss = 0.1651 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8356: loss = 0.0384 (0.150 sec/step)\n",
            "I0601 12:18:12.964580 140438660523904 learning.py:507] global step 8356: loss = 0.0384 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8357: loss = 0.1429 (0.171 sec/step)\n",
            "I0601 12:18:13.136819 140438660523904 learning.py:507] global step 8357: loss = 0.1429 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8358: loss = 0.4442 (0.169 sec/step)\n",
            "I0601 12:18:13.307686 140438660523904 learning.py:507] global step 8358: loss = 0.4442 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8359: loss = 0.1008 (0.166 sec/step)\n",
            "I0601 12:18:13.475533 140438660523904 learning.py:507] global step 8359: loss = 0.1008 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8360: loss = 0.0345 (0.201 sec/step)\n",
            "I0601 12:18:13.677662 140438660523904 learning.py:507] global step 8360: loss = 0.0345 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 8361: loss = 0.0971 (0.173 sec/step)\n",
            "I0601 12:18:13.851710 140438660523904 learning.py:507] global step 8361: loss = 0.0971 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8362: loss = 0.1686 (0.164 sec/step)\n",
            "I0601 12:18:14.017257 140438660523904 learning.py:507] global step 8362: loss = 0.1686 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8363: loss = 0.0581 (0.171 sec/step)\n",
            "I0601 12:18:14.190429 140438660523904 learning.py:507] global step 8363: loss = 0.0581 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8364: loss = 0.2670 (0.176 sec/step)\n",
            "I0601 12:18:14.367304 140438660523904 learning.py:507] global step 8364: loss = 0.2670 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8365: loss = 0.0714 (0.182 sec/step)\n",
            "I0601 12:18:14.550642 140438660523904 learning.py:507] global step 8365: loss = 0.0714 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8366: loss = 0.1482 (0.163 sec/step)\n",
            "I0601 12:18:14.715585 140438660523904 learning.py:507] global step 8366: loss = 0.1482 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8367: loss = 0.0884 (0.158 sec/step)\n",
            "I0601 12:18:14.874655 140438660523904 learning.py:507] global step 8367: loss = 0.0884 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8368: loss = 0.0784 (0.155 sec/step)\n",
            "I0601 12:18:15.031139 140438660523904 learning.py:507] global step 8368: loss = 0.0784 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8369: loss = 0.2945 (0.166 sec/step)\n",
            "I0601 12:18:15.198939 140438660523904 learning.py:507] global step 8369: loss = 0.2945 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8370: loss = 0.0482 (0.163 sec/step)\n",
            "I0601 12:18:15.363700 140438660523904 learning.py:507] global step 8370: loss = 0.0482 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8371: loss = 0.3591 (0.173 sec/step)\n",
            "I0601 12:18:15.538446 140438660523904 learning.py:507] global step 8371: loss = 0.3591 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8372: loss = 0.1244 (0.167 sec/step)\n",
            "I0601 12:18:15.706661 140438660523904 learning.py:507] global step 8372: loss = 0.1244 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8373: loss = 0.0989 (0.167 sec/step)\n",
            "I0601 12:18:15.874963 140438660523904 learning.py:507] global step 8373: loss = 0.0989 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8374: loss = 0.0887 (0.180 sec/step)\n",
            "I0601 12:18:16.056946 140438660523904 learning.py:507] global step 8374: loss = 0.0887 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8375: loss = 0.2132 (0.165 sec/step)\n",
            "I0601 12:18:16.223479 140438660523904 learning.py:507] global step 8375: loss = 0.2132 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8376: loss = 0.1943 (0.186 sec/step)\n",
            "I0601 12:18:16.411628 140438660523904 learning.py:507] global step 8376: loss = 0.1943 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8377: loss = 0.1273 (0.199 sec/step)\n",
            "I0601 12:18:16.611807 140438660523904 learning.py:507] global step 8377: loss = 0.1273 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 8378: loss = 0.4127 (0.191 sec/step)\n",
            "I0601 12:18:16.803963 140438660523904 learning.py:507] global step 8378: loss = 0.4127 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8379: loss = 0.0229 (0.162 sec/step)\n",
            "I0601 12:18:16.966961 140438660523904 learning.py:507] global step 8379: loss = 0.0229 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8380: loss = 0.3366 (0.174 sec/step)\n",
            "I0601 12:18:17.142640 140438660523904 learning.py:507] global step 8380: loss = 0.3366 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8381: loss = 0.1307 (0.167 sec/step)\n",
            "I0601 12:18:17.310636 140438660523904 learning.py:507] global step 8381: loss = 0.1307 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8382: loss = 0.0877 (0.150 sec/step)\n",
            "I0601 12:18:17.462302 140438660523904 learning.py:507] global step 8382: loss = 0.0877 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8383: loss = 0.0597 (0.168 sec/step)\n",
            "I0601 12:18:17.632298 140438660523904 learning.py:507] global step 8383: loss = 0.0597 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8384: loss = 0.0444 (0.174 sec/step)\n",
            "I0601 12:18:17.808235 140438660523904 learning.py:507] global step 8384: loss = 0.0444 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8385: loss = 0.1900 (0.178 sec/step)\n",
            "I0601 12:18:17.988252 140438660523904 learning.py:507] global step 8385: loss = 0.1900 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8386: loss = 0.2277 (0.166 sec/step)\n",
            "I0601 12:18:18.155429 140438660523904 learning.py:507] global step 8386: loss = 0.2277 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8387: loss = 0.1224 (0.169 sec/step)\n",
            "I0601 12:18:18.325663 140438660523904 learning.py:507] global step 8387: loss = 0.1224 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8388: loss = 0.1253 (0.174 sec/step)\n",
            "I0601 12:18:18.501473 140438660523904 learning.py:507] global step 8388: loss = 0.1253 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8389: loss = 0.1106 (0.165 sec/step)\n",
            "I0601 12:18:18.667917 140438660523904 learning.py:507] global step 8389: loss = 0.1106 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8390: loss = 0.0452 (0.181 sec/step)\n",
            "I0601 12:18:18.850370 140438660523904 learning.py:507] global step 8390: loss = 0.0452 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8391: loss = 0.1262 (0.230 sec/step)\n",
            "I0601 12:18:19.082419 140438660523904 learning.py:507] global step 8391: loss = 0.1262 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8392: loss = 0.1554 (0.187 sec/step)\n",
            "I0601 12:18:19.270709 140438660523904 learning.py:507] global step 8392: loss = 0.1554 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8393: loss = 0.0629 (0.186 sec/step)\n",
            "I0601 12:18:19.458589 140438660523904 learning.py:507] global step 8393: loss = 0.0629 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8394: loss = 0.3181 (0.161 sec/step)\n",
            "I0601 12:18:19.620604 140438660523904 learning.py:507] global step 8394: loss = 0.3181 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8395: loss = 0.0936 (0.171 sec/step)\n",
            "I0601 12:18:19.792770 140438660523904 learning.py:507] global step 8395: loss = 0.0936 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8396: loss = 0.0568 (0.167 sec/step)\n",
            "I0601 12:18:19.961051 140438660523904 learning.py:507] global step 8396: loss = 0.0568 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8397: loss = 0.1508 (0.173 sec/step)\n",
            "I0601 12:18:20.135623 140438660523904 learning.py:507] global step 8397: loss = 0.1508 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8398: loss = 0.0540 (0.166 sec/step)\n",
            "I0601 12:18:20.303482 140438660523904 learning.py:507] global step 8398: loss = 0.0540 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8399: loss = 0.1854 (0.175 sec/step)\n",
            "I0601 12:18:20.480349 140438660523904 learning.py:507] global step 8399: loss = 0.1854 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8400: loss = 0.0876 (0.173 sec/step)\n",
            "I0601 12:18:20.654522 140438660523904 learning.py:507] global step 8400: loss = 0.0876 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8401: loss = 0.3277 (0.171 sec/step)\n",
            "I0601 12:18:20.827036 140438660523904 learning.py:507] global step 8401: loss = 0.3277 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8402: loss = 0.1177 (0.180 sec/step)\n",
            "I0601 12:18:21.008538 140438660523904 learning.py:507] global step 8402: loss = 0.1177 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8403: loss = 0.1216 (0.158 sec/step)\n",
            "I0601 12:18:21.168248 140438660523904 learning.py:507] global step 8403: loss = 0.1216 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8404: loss = 0.1670 (0.160 sec/step)\n",
            "I0601 12:18:21.329315 140438660523904 learning.py:507] global step 8404: loss = 0.1670 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8405: loss = 0.1940 (0.143 sec/step)\n",
            "I0601 12:18:21.474196 140438660523904 learning.py:507] global step 8405: loss = 0.1940 (0.143 sec/step)\n",
            "INFO:tensorflow:global step 8406: loss = 0.1744 (0.158 sec/step)\n",
            "I0601 12:18:21.633109 140438660523904 learning.py:507] global step 8406: loss = 0.1744 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8407: loss = 0.3202 (0.180 sec/step)\n",
            "I0601 12:18:21.814976 140438660523904 learning.py:507] global step 8407: loss = 0.3202 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8408: loss = 0.0461 (0.152 sec/step)\n",
            "I0601 12:18:21.968827 140438660523904 learning.py:507] global step 8408: loss = 0.0461 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8409: loss = 0.1298 (0.155 sec/step)\n",
            "I0601 12:18:22.125767 140438660523904 learning.py:507] global step 8409: loss = 0.1298 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8410: loss = 0.0648 (0.184 sec/step)\n",
            "I0601 12:18:22.310728 140438660523904 learning.py:507] global step 8410: loss = 0.0648 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8411: loss = 0.0877 (0.163 sec/step)\n",
            "I0601 12:18:22.475309 140438660523904 learning.py:507] global step 8411: loss = 0.0877 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8412: loss = 0.1823 (0.150 sec/step)\n",
            "I0601 12:18:22.627009 140438660523904 learning.py:507] global step 8412: loss = 0.1823 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8413: loss = 0.2564 (0.175 sec/step)\n",
            "I0601 12:18:22.803131 140438660523904 learning.py:507] global step 8413: loss = 0.2564 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8414: loss = 0.1906 (0.182 sec/step)\n",
            "I0601 12:18:22.986618 140438660523904 learning.py:507] global step 8414: loss = 0.1906 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8415: loss = 0.0457 (0.163 sec/step)\n",
            "I0601 12:18:23.151590 140438660523904 learning.py:507] global step 8415: loss = 0.0457 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8416: loss = 0.1573 (0.169 sec/step)\n",
            "I0601 12:18:23.322550 140438660523904 learning.py:507] global step 8416: loss = 0.1573 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8417: loss = 0.1093 (0.158 sec/step)\n",
            "I0601 12:18:23.481845 140438660523904 learning.py:507] global step 8417: loss = 0.1093 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8418: loss = 0.0981 (0.171 sec/step)\n",
            "I0601 12:18:23.654041 140438660523904 learning.py:507] global step 8418: loss = 0.0981 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8419: loss = 0.0606 (0.178 sec/step)\n",
            "I0601 12:18:23.833742 140438660523904 learning.py:507] global step 8419: loss = 0.0606 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8420: loss = 0.0632 (0.218 sec/step)\n",
            "I0601 12:18:24.053019 140438660523904 learning.py:507] global step 8420: loss = 0.0632 (0.218 sec/step)\n",
            "INFO:tensorflow:global step 8421: loss = 0.1767 (0.169 sec/step)\n",
            "I0601 12:18:24.223561 140438660523904 learning.py:507] global step 8421: loss = 0.1767 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8422: loss = 0.1118 (0.172 sec/step)\n",
            "I0601 12:18:24.397129 140438660523904 learning.py:507] global step 8422: loss = 0.1118 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8423: loss = 0.0322 (0.150 sec/step)\n",
            "I0601 12:18:24.548228 140438660523904 learning.py:507] global step 8423: loss = 0.0322 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8424: loss = 0.0780 (0.175 sec/step)\n",
            "I0601 12:18:24.724844 140438660523904 learning.py:507] global step 8424: loss = 0.0780 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8425: loss = 0.1465 (0.153 sec/step)\n",
            "I0601 12:18:24.882732 140438660523904 learning.py:507] global step 8425: loss = 0.1465 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8426: loss = 4.7209 (0.180 sec/step)\n",
            "I0601 12:18:25.064167 140438660523904 learning.py:507] global step 8426: loss = 4.7209 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8427: loss = 0.1468 (0.157 sec/step)\n",
            "I0601 12:18:25.222947 140438660523904 learning.py:507] global step 8427: loss = 0.1468 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8428: loss = 0.0971 (0.169 sec/step)\n",
            "I0601 12:18:25.393331 140438660523904 learning.py:507] global step 8428: loss = 0.0971 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8429: loss = 0.0563 (0.168 sec/step)\n",
            "I0601 12:18:25.563005 140438660523904 learning.py:507] global step 8429: loss = 0.0563 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8430: loss = 0.1322 (0.192 sec/step)\n",
            "I0601 12:18:25.756938 140438660523904 learning.py:507] global step 8430: loss = 0.1322 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8431: loss = 0.2620 (0.184 sec/step)\n",
            "I0601 12:18:25.942541 140438660523904 learning.py:507] global step 8431: loss = 0.2620 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8432: loss = 0.0894 (0.176 sec/step)\n",
            "I0601 12:18:26.119961 140438660523904 learning.py:507] global step 8432: loss = 0.0894 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8433: loss = 0.0318 (0.181 sec/step)\n",
            "I0601 12:18:26.302306 140438660523904 learning.py:507] global step 8433: loss = 0.0318 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8434: loss = 0.0670 (0.173 sec/step)\n",
            "I0601 12:18:26.476529 140438660523904 learning.py:507] global step 8434: loss = 0.0670 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8435: loss = 0.0980 (0.163 sec/step)\n",
            "I0601 12:18:26.641602 140438660523904 learning.py:507] global step 8435: loss = 0.0980 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8436: loss = 0.0451 (0.185 sec/step)\n",
            "I0601 12:18:26.827973 140438660523904 learning.py:507] global step 8436: loss = 0.0451 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8437: loss = 0.2611 (0.164 sec/step)\n",
            "I0601 12:18:26.992895 140438660523904 learning.py:507] global step 8437: loss = 0.2611 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8438: loss = 0.1201 (0.171 sec/step)\n",
            "I0601 12:18:27.164823 140438660523904 learning.py:507] global step 8438: loss = 0.1201 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8439: loss = 0.1526 (0.176 sec/step)\n",
            "I0601 12:18:27.342050 140438660523904 learning.py:507] global step 8439: loss = 0.1526 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8440: loss = 0.0844 (0.159 sec/step)\n",
            "I0601 12:18:27.502466 140438660523904 learning.py:507] global step 8440: loss = 0.0844 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8441: loss = 0.0360 (0.173 sec/step)\n",
            "I0601 12:18:27.676538 140438660523904 learning.py:507] global step 8441: loss = 0.0360 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8442: loss = 0.0554 (0.177 sec/step)\n",
            "I0601 12:18:27.854529 140438660523904 learning.py:507] global step 8442: loss = 0.0554 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8443: loss = 0.0901 (0.183 sec/step)\n",
            "I0601 12:18:28.038483 140438660523904 learning.py:507] global step 8443: loss = 0.0901 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8444: loss = 0.3393 (0.175 sec/step)\n",
            "I0601 12:18:28.214693 140438660523904 learning.py:507] global step 8444: loss = 0.3393 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8445: loss = 0.4875 (0.204 sec/step)\n",
            "I0601 12:18:28.419631 140438660523904 learning.py:507] global step 8445: loss = 0.4875 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 8446: loss = 0.0449 (0.176 sec/step)\n",
            "I0601 12:18:28.596992 140438660523904 learning.py:507] global step 8446: loss = 0.0449 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8447: loss = 0.0451 (0.190 sec/step)\n",
            "I0601 12:18:28.788731 140438660523904 learning.py:507] global step 8447: loss = 0.0451 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8448: loss = 0.2090 (0.179 sec/step)\n",
            "I0601 12:18:28.969122 140438660523904 learning.py:507] global step 8448: loss = 0.2090 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8449: loss = 0.0255 (0.176 sec/step)\n",
            "I0601 12:18:29.146407 140438660523904 learning.py:507] global step 8449: loss = 0.0255 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8450: loss = 0.1199 (0.153 sec/step)\n",
            "I0601 12:18:29.300547 140438660523904 learning.py:507] global step 8450: loss = 0.1199 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8451: loss = 0.0946 (0.179 sec/step)\n",
            "I0601 12:18:29.481121 140438660523904 learning.py:507] global step 8451: loss = 0.0946 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8452: loss = 0.2872 (0.167 sec/step)\n",
            "I0601 12:18:29.649320 140438660523904 learning.py:507] global step 8452: loss = 0.2872 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8453: loss = 0.1694 (0.160 sec/step)\n",
            "I0601 12:18:29.810384 140438660523904 learning.py:507] global step 8453: loss = 0.1694 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8454: loss = 0.1228 (0.171 sec/step)\n",
            "I0601 12:18:29.983011 140438660523904 learning.py:507] global step 8454: loss = 0.1228 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8455: loss = 0.0483 (0.164 sec/step)\n",
            "I0601 12:18:30.148562 140438660523904 learning.py:507] global step 8455: loss = 0.0483 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8456: loss = 0.2026 (0.146 sec/step)\n",
            "I0601 12:18:30.296372 140438660523904 learning.py:507] global step 8456: loss = 0.2026 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 8457: loss = 0.1172 (0.176 sec/step)\n",
            "I0601 12:18:30.474023 140438660523904 learning.py:507] global step 8457: loss = 0.1172 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8458: loss = 0.0288 (0.143 sec/step)\n",
            "I0601 12:18:30.618175 140438660523904 learning.py:507] global step 8458: loss = 0.0288 (0.143 sec/step)\n",
            "INFO:tensorflow:global step 8459: loss = 0.1213 (0.196 sec/step)\n",
            "I0601 12:18:30.815562 140438660523904 learning.py:507] global step 8459: loss = 0.1213 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 8460: loss = 0.1706 (0.179 sec/step)\n",
            "I0601 12:18:30.996010 140438660523904 learning.py:507] global step 8460: loss = 0.1706 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8461: loss = 0.2153 (0.186 sec/step)\n",
            "I0601 12:18:31.183483 140438660523904 learning.py:507] global step 8461: loss = 0.2153 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8462: loss = 0.0845 (0.169 sec/step)\n",
            "I0601 12:18:31.353581 140438660523904 learning.py:507] global step 8462: loss = 0.0845 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8463: loss = 0.3184 (0.186 sec/step)\n",
            "I0601 12:18:31.541609 140438660523904 learning.py:507] global step 8463: loss = 0.3184 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8464: loss = 0.1596 (0.171 sec/step)\n",
            "I0601 12:18:31.713741 140438660523904 learning.py:507] global step 8464: loss = 0.1596 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8465: loss = 0.1496 (0.171 sec/step)\n",
            "I0601 12:18:31.886630 140438660523904 learning.py:507] global step 8465: loss = 0.1496 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8466: loss = 0.0888 (0.160 sec/step)\n",
            "I0601 12:18:32.048089 140438660523904 learning.py:507] global step 8466: loss = 0.0888 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8467: loss = 0.1068 (0.168 sec/step)\n",
            "I0601 12:18:32.217088 140438660523904 learning.py:507] global step 8467: loss = 0.1068 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8468: loss = 0.2238 (0.154 sec/step)\n",
            "I0601 12:18:32.372281 140438660523904 learning.py:507] global step 8468: loss = 0.2238 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8469: loss = 0.3122 (0.173 sec/step)\n",
            "I0601 12:18:32.546498 140438660523904 learning.py:507] global step 8469: loss = 0.3122 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8470: loss = 0.1882 (0.188 sec/step)\n",
            "I0601 12:18:32.736401 140438660523904 learning.py:507] global step 8470: loss = 0.1882 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8471: loss = 0.0560 (0.173 sec/step)\n",
            "I0601 12:18:32.910650 140438660523904 learning.py:507] global step 8471: loss = 0.0560 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8472: loss = 0.0983 (0.171 sec/step)\n",
            "I0601 12:18:33.082937 140438660523904 learning.py:507] global step 8472: loss = 0.0983 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8473: loss = 0.0359 (0.190 sec/step)\n",
            "I0601 12:18:33.274350 140438660523904 learning.py:507] global step 8473: loss = 0.0359 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8474: loss = 0.0339 (0.154 sec/step)\n",
            "I0601 12:18:33.429844 140438660523904 learning.py:507] global step 8474: loss = 0.0339 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8475: loss = 0.0224 (0.175 sec/step)\n",
            "I0601 12:18:33.606925 140438660523904 learning.py:507] global step 8475: loss = 0.0224 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8476: loss = 0.3966 (0.175 sec/step)\n",
            "I0601 12:18:33.783352 140438660523904 learning.py:507] global step 8476: loss = 0.3966 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8477: loss = 0.0417 (0.158 sec/step)\n",
            "I0601 12:18:33.943024 140438660523904 learning.py:507] global step 8477: loss = 0.0417 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8478: loss = 0.2663 (0.195 sec/step)\n",
            "I0601 12:18:34.139084 140438660523904 learning.py:507] global step 8478: loss = 0.2663 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8479: loss = 0.1240 (0.189 sec/step)\n",
            "I0601 12:18:34.329435 140438660523904 learning.py:507] global step 8479: loss = 0.1240 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8480: loss = 0.1480 (0.176 sec/step)\n",
            "I0601 12:18:34.507111 140438660523904 learning.py:507] global step 8480: loss = 0.1480 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8481: loss = 0.0468 (0.186 sec/step)\n",
            "I0601 12:18:34.694231 140438660523904 learning.py:507] global step 8481: loss = 0.0468 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8482: loss = 0.0281 (0.178 sec/step)\n",
            "I0601 12:18:34.874546 140438660523904 learning.py:507] global step 8482: loss = 0.0281 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8483: loss = 0.0854 (0.162 sec/step)\n",
            "I0601 12:18:35.038336 140438660523904 learning.py:507] global step 8483: loss = 0.0854 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8484: loss = 0.0899 (0.204 sec/step)\n",
            "I0601 12:18:35.244117 140438660523904 learning.py:507] global step 8484: loss = 0.0899 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 8485: loss = 0.0366 (0.169 sec/step)\n",
            "I0601 12:18:35.414709 140438660523904 learning.py:507] global step 8485: loss = 0.0366 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8486: loss = 0.0753 (0.168 sec/step)\n",
            "I0601 12:18:35.583921 140438660523904 learning.py:507] global step 8486: loss = 0.0753 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8487: loss = 0.0339 (0.184 sec/step)\n",
            "I0601 12:18:35.769033 140438660523904 learning.py:507] global step 8487: loss = 0.0339 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8488: loss = 0.0987 (0.188 sec/step)\n",
            "I0601 12:18:35.958368 140438660523904 learning.py:507] global step 8488: loss = 0.0987 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8489: loss = 0.3464 (0.170 sec/step)\n",
            "I0601 12:18:36.130236 140438660523904 learning.py:507] global step 8489: loss = 0.3464 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8490: loss = 0.2068 (0.201 sec/step)\n",
            "I0601 12:18:36.335043 140438660523904 learning.py:507] global step 8490: loss = 0.2068 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 8491: loss = 0.2537 (0.198 sec/step)\n",
            "I0601 12:18:36.542771 140438660523904 learning.py:507] global step 8491: loss = 0.2537 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 8492: loss = 0.1065 (0.188 sec/step)\n",
            "I0601 12:18:36.732455 140438660523904 learning.py:507] global step 8492: loss = 0.1065 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8493: loss = 0.0656 (0.161 sec/step)\n",
            "I0601 12:18:36.895357 140438660523904 learning.py:507] global step 8493: loss = 0.0656 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8494: loss = 0.0227 (0.151 sec/step)\n",
            "I0601 12:18:37.047772 140438660523904 learning.py:507] global step 8494: loss = 0.0227 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8495: loss = 0.0411 (0.156 sec/step)\n",
            "I0601 12:18:37.205343 140438660523904 learning.py:507] global step 8495: loss = 0.0411 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8496: loss = 0.1316 (0.179 sec/step)\n",
            "I0601 12:18:37.386187 140438660523904 learning.py:507] global step 8496: loss = 0.1316 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8497: loss = 0.1365 (0.153 sec/step)\n",
            "I0601 12:18:37.540809 140438660523904 learning.py:507] global step 8497: loss = 0.1365 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8498: loss = 0.0890 (0.159 sec/step)\n",
            "I0601 12:18:37.700892 140438660523904 learning.py:507] global step 8498: loss = 0.0890 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8499: loss = 0.1029 (0.163 sec/step)\n",
            "I0601 12:18:37.865942 140438660523904 learning.py:507] global step 8499: loss = 0.1029 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8500: loss = 0.3744 (0.172 sec/step)\n",
            "I0601 12:18:38.040003 140438660523904 learning.py:507] global step 8500: loss = 0.3744 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8501: loss = 0.0889 (0.176 sec/step)\n",
            "I0601 12:18:38.217689 140438660523904 learning.py:507] global step 8501: loss = 0.0889 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8502: loss = 0.0484 (0.181 sec/step)\n",
            "I0601 12:18:38.400276 140438660523904 learning.py:507] global step 8502: loss = 0.0484 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8503: loss = 0.2878 (0.185 sec/step)\n",
            "I0601 12:18:38.586647 140438660523904 learning.py:507] global step 8503: loss = 0.2878 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8504: loss = 0.0810 (0.181 sec/step)\n",
            "I0601 12:18:38.769169 140438660523904 learning.py:507] global step 8504: loss = 0.0810 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8505: loss = 0.2523 (0.155 sec/step)\n",
            "I0601 12:18:38.925089 140438660523904 learning.py:507] global step 8505: loss = 0.2523 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8506: loss = 0.1222 (0.188 sec/step)\n",
            "I0601 12:18:39.114716 140438660523904 learning.py:507] global step 8506: loss = 0.1222 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8507: loss = 0.0700 (0.172 sec/step)\n",
            "I0601 12:18:39.288162 140438660523904 learning.py:507] global step 8507: loss = 0.0700 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8508: loss = 0.0152 (0.168 sec/step)\n",
            "I0601 12:18:39.457994 140438660523904 learning.py:507] global step 8508: loss = 0.0152 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8509: loss = 0.0946 (0.166 sec/step)\n",
            "I0601 12:18:39.625627 140438660523904 learning.py:507] global step 8509: loss = 0.0946 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8510: loss = 0.1448 (0.183 sec/step)\n",
            "I0601 12:18:39.810240 140438660523904 learning.py:507] global step 8510: loss = 0.1448 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8511: loss = 0.1275 (0.148 sec/step)\n",
            "I0601 12:18:39.960019 140438660523904 learning.py:507] global step 8511: loss = 0.1275 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 8512: loss = 0.2006 (0.175 sec/step)\n",
            "I0601 12:18:40.135866 140438660523904 learning.py:507] global step 8512: loss = 0.2006 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8513: loss = 0.0573 (0.138 sec/step)\n",
            "I0601 12:18:40.275809 140438660523904 learning.py:507] global step 8513: loss = 0.0573 (0.138 sec/step)\n",
            "INFO:tensorflow:global step 8514: loss = 0.1707 (0.164 sec/step)\n",
            "I0601 12:18:40.441194 140438660523904 learning.py:507] global step 8514: loss = 0.1707 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8515: loss = 0.0401 (0.147 sec/step)\n",
            "I0601 12:18:40.589697 140438660523904 learning.py:507] global step 8515: loss = 0.0401 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 8516: loss = 0.0488 (0.159 sec/step)\n",
            "I0601 12:18:40.750564 140438660523904 learning.py:507] global step 8516: loss = 0.0488 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8517: loss = 0.1429 (0.192 sec/step)\n",
            "I0601 12:18:40.943637 140438660523904 learning.py:507] global step 8517: loss = 0.1429 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8518: loss = 0.1064 (0.215 sec/step)\n",
            "I0601 12:18:41.159983 140438660523904 learning.py:507] global step 8518: loss = 0.1064 (0.215 sec/step)\n",
            "INFO:tensorflow:global step 8519: loss = 0.1110 (0.176 sec/step)\n",
            "I0601 12:18:41.337550 140438660523904 learning.py:507] global step 8519: loss = 0.1110 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8520: loss = 0.1582 (0.177 sec/step)\n",
            "I0601 12:18:41.515774 140438660523904 learning.py:507] global step 8520: loss = 0.1582 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8521: loss = 0.0792 (0.181 sec/step)\n",
            "I0601 12:18:41.697999 140438660523904 learning.py:507] global step 8521: loss = 0.0792 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8522: loss = 0.1233 (0.189 sec/step)\n",
            "I0601 12:18:41.887930 140438660523904 learning.py:507] global step 8522: loss = 0.1233 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8523: loss = 0.3264 (0.157 sec/step)\n",
            "I0601 12:18:42.046081 140438660523904 learning.py:507] global step 8523: loss = 0.3264 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8524: loss = 0.0790 (0.185 sec/step)\n",
            "I0601 12:18:42.232643 140438660523904 learning.py:507] global step 8524: loss = 0.0790 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8525: loss = 0.0949 (0.170 sec/step)\n",
            "I0601 12:18:42.403687 140438660523904 learning.py:507] global step 8525: loss = 0.0949 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8526: loss = 0.0354 (0.170 sec/step)\n",
            "I0601 12:18:42.574848 140438660523904 learning.py:507] global step 8526: loss = 0.0354 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8527: loss = 0.2653 (0.175 sec/step)\n",
            "I0601 12:18:42.751159 140438660523904 learning.py:507] global step 8527: loss = 0.2653 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8528: loss = 0.0900 (0.162 sec/step)\n",
            "I0601 12:18:42.915064 140438660523904 learning.py:507] global step 8528: loss = 0.0900 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8529: loss = 0.0671 (0.172 sec/step)\n",
            "I0601 12:18:43.088218 140438660523904 learning.py:507] global step 8529: loss = 0.0671 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8530: loss = 0.1017 (0.170 sec/step)\n",
            "I0601 12:18:43.259545 140438660523904 learning.py:507] global step 8530: loss = 0.1017 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8531: loss = 0.1339 (0.177 sec/step)\n",
            "I0601 12:18:43.437498 140438660523904 learning.py:507] global step 8531: loss = 0.1339 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8532: loss = 0.1512 (0.171 sec/step)\n",
            "I0601 12:18:43.609537 140438660523904 learning.py:507] global step 8532: loss = 0.1512 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8533: loss = 0.2204 (0.172 sec/step)\n",
            "I0601 12:18:43.782951 140438660523904 learning.py:507] global step 8533: loss = 0.2204 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8534: loss = 0.0903 (0.160 sec/step)\n",
            "I0601 12:18:43.944852 140438660523904 learning.py:507] global step 8534: loss = 0.0903 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8535: loss = 0.0513 (0.173 sec/step)\n",
            "I0601 12:18:44.119372 140438660523904 learning.py:507] global step 8535: loss = 0.0513 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8536: loss = 0.4315 (0.173 sec/step)\n",
            "I0601 12:18:44.293820 140438660523904 learning.py:507] global step 8536: loss = 0.4315 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8537: loss = 0.1737 (0.174 sec/step)\n",
            "I0601 12:18:44.468720 140438660523904 learning.py:507] global step 8537: loss = 0.1737 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8538: loss = 0.1122 (0.176 sec/step)\n",
            "I0601 12:18:44.646491 140438660523904 learning.py:507] global step 8538: loss = 0.1122 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8539: loss = 0.0628 (0.173 sec/step)\n",
            "I0601 12:18:44.821150 140438660523904 learning.py:507] global step 8539: loss = 0.0628 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8540: loss = 0.2359 (0.189 sec/step)\n",
            "I0601 12:18:45.011790 140438660523904 learning.py:507] global step 8540: loss = 0.2359 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8541: loss = 0.1518 (0.206 sec/step)\n",
            "I0601 12:18:45.219438 140438660523904 learning.py:507] global step 8541: loss = 0.1518 (0.206 sec/step)\n",
            "INFO:tensorflow:global step 8542: loss = 0.1542 (0.192 sec/step)\n",
            "I0601 12:18:45.413478 140438660523904 learning.py:507] global step 8542: loss = 0.1542 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8543: loss = 0.0681 (0.166 sec/step)\n",
            "I0601 12:18:45.580464 140438660523904 learning.py:507] global step 8543: loss = 0.0681 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8544: loss = 0.0590 (0.166 sec/step)\n",
            "I0601 12:18:45.747699 140438660523904 learning.py:507] global step 8544: loss = 0.0590 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8545: loss = 0.0598 (0.158 sec/step)\n",
            "I0601 12:18:45.907569 140438660523904 learning.py:507] global step 8545: loss = 0.0598 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8546: loss = 0.1018 (0.167 sec/step)\n",
            "I0601 12:18:46.075942 140438660523904 learning.py:507] global step 8546: loss = 0.1018 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8547: loss = 0.3091 (0.176 sec/step)\n",
            "I0601 12:18:46.253389 140438660523904 learning.py:507] global step 8547: loss = 0.3091 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8548: loss = 0.2661 (0.179 sec/step)\n",
            "I0601 12:18:46.433631 140438660523904 learning.py:507] global step 8548: loss = 0.2661 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8549: loss = 0.1129 (0.205 sec/step)\n",
            "I0601 12:18:46.640348 140438660523904 learning.py:507] global step 8549: loss = 0.1129 (0.205 sec/step)\n",
            "INFO:tensorflow:global step 8550: loss = 0.1928 (0.167 sec/step)\n",
            "I0601 12:18:46.808675 140438660523904 learning.py:507] global step 8550: loss = 0.1928 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8551: loss = 0.0567 (0.176 sec/step)\n",
            "I0601 12:18:46.985971 140438660523904 learning.py:507] global step 8551: loss = 0.0567 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8552: loss = 0.2241 (0.182 sec/step)\n",
            "I0601 12:18:47.169796 140438660523904 learning.py:507] global step 8552: loss = 0.2241 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8553: loss = 0.3787 (0.178 sec/step)\n",
            "I0601 12:18:47.349109 140438660523904 learning.py:507] global step 8553: loss = 0.3787 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8554: loss = 0.0294 (0.168 sec/step)\n",
            "I0601 12:18:47.518949 140438660523904 learning.py:507] global step 8554: loss = 0.0294 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8555: loss = 0.0736 (0.185 sec/step)\n",
            "I0601 12:18:47.705843 140438660523904 learning.py:507] global step 8555: loss = 0.0736 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8556: loss = 0.0511 (0.157 sec/step)\n",
            "I0601 12:18:47.863913 140438660523904 learning.py:507] global step 8556: loss = 0.0511 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8557: loss = 0.1089 (0.165 sec/step)\n",
            "I0601 12:18:48.030446 140438660523904 learning.py:507] global step 8557: loss = 0.1089 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8558: loss = 0.2408 (0.181 sec/step)\n",
            "I0601 12:18:48.213126 140438660523904 learning.py:507] global step 8558: loss = 0.2408 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8559: loss = 0.0563 (0.170 sec/step)\n",
            "I0601 12:18:48.385446 140438660523904 learning.py:507] global step 8559: loss = 0.0563 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8560: loss = 0.0344 (0.173 sec/step)\n",
            "I0601 12:18:48.559593 140438660523904 learning.py:507] global step 8560: loss = 0.0344 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8561: loss = 0.1622 (0.173 sec/step)\n",
            "I0601 12:18:48.733465 140438660523904 learning.py:507] global step 8561: loss = 0.1622 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8562: loss = 0.1058 (0.165 sec/step)\n",
            "I0601 12:18:48.899915 140438660523904 learning.py:507] global step 8562: loss = 0.1058 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8563: loss = 0.0770 (0.169 sec/step)\n",
            "I0601 12:18:49.069831 140438660523904 learning.py:507] global step 8563: loss = 0.0770 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8564: loss = 0.1760 (0.166 sec/step)\n",
            "I0601 12:18:49.237618 140438660523904 learning.py:507] global step 8564: loss = 0.1760 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8565: loss = 0.0437 (0.179 sec/step)\n",
            "I0601 12:18:49.418678 140438660523904 learning.py:507] global step 8565: loss = 0.0437 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8566: loss = 0.0190 (0.172 sec/step)\n",
            "I0601 12:18:49.592204 140438660523904 learning.py:507] global step 8566: loss = 0.0190 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8567: loss = 0.2151 (0.181 sec/step)\n",
            "I0601 12:18:49.774823 140438660523904 learning.py:507] global step 8567: loss = 0.2151 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8568: loss = 0.1299 (0.183 sec/step)\n",
            "I0601 12:18:49.959101 140438660523904 learning.py:507] global step 8568: loss = 0.1299 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8569: loss = 0.1407 (0.190 sec/step)\n",
            "I0601 12:18:50.151165 140438660523904 learning.py:507] global step 8569: loss = 0.1407 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8570: loss = 0.0214 (0.170 sec/step)\n",
            "I0601 12:18:50.322437 140438660523904 learning.py:507] global step 8570: loss = 0.0214 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8571: loss = 0.1746 (0.172 sec/step)\n",
            "I0601 12:18:50.496134 140438660523904 learning.py:507] global step 8571: loss = 0.1746 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8572: loss = 0.1788 (0.183 sec/step)\n",
            "I0601 12:18:50.680756 140438660523904 learning.py:507] global step 8572: loss = 0.1788 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8573: loss = 0.0154 (0.145 sec/step)\n",
            "I0601 12:18:50.826749 140438660523904 learning.py:507] global step 8573: loss = 0.0154 (0.145 sec/step)\n",
            "INFO:tensorflow:global step 8574: loss = 0.0463 (0.171 sec/step)\n",
            "I0601 12:18:50.999497 140438660523904 learning.py:507] global step 8574: loss = 0.0463 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8575: loss = 4.3589 (0.162 sec/step)\n",
            "I0601 12:18:51.163074 140438660523904 learning.py:507] global step 8575: loss = 4.3589 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8576: loss = 0.1043 (0.167 sec/step)\n",
            "I0601 12:18:51.331952 140438660523904 learning.py:507] global step 8576: loss = 0.1043 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8577: loss = 0.0491 (0.156 sec/step)\n",
            "I0601 12:18:51.489393 140438660523904 learning.py:507] global step 8577: loss = 0.0491 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8578: loss = 0.2761 (0.195 sec/step)\n",
            "I0601 12:18:51.685947 140438660523904 learning.py:507] global step 8578: loss = 0.2761 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8579: loss = 0.2157 (0.164 sec/step)\n",
            "I0601 12:18:51.851624 140438660523904 learning.py:507] global step 8579: loss = 0.2157 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8580: loss = 0.2114 (0.171 sec/step)\n",
            "I0601 12:18:52.024580 140438660523904 learning.py:507] global step 8580: loss = 0.2114 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8581: loss = 0.1383 (0.184 sec/step)\n",
            "I0601 12:18:52.210445 140438660523904 learning.py:507] global step 8581: loss = 0.1383 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8582: loss = 0.0352 (0.172 sec/step)\n",
            "I0601 12:18:52.385915 140438660523904 learning.py:507] global step 8582: loss = 0.0352 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8583: loss = 0.0745 (0.174 sec/step)\n",
            "I0601 12:18:52.562008 140438660523904 learning.py:507] global step 8583: loss = 0.0745 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8584: loss = 0.4247 (0.158 sec/step)\n",
            "I0601 12:18:52.721021 140438660523904 learning.py:507] global step 8584: loss = 0.4247 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8585: loss = 0.0812 (0.176 sec/step)\n",
            "I0601 12:18:52.898351 140438660523904 learning.py:507] global step 8585: loss = 0.0812 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8586: loss = 0.0230 (0.162 sec/step)\n",
            "I0601 12:18:53.061271 140438660523904 learning.py:507] global step 8586: loss = 0.0230 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8587: loss = 0.1047 (0.168 sec/step)\n",
            "I0601 12:18:53.230747 140438660523904 learning.py:507] global step 8587: loss = 0.1047 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8588: loss = 0.1307 (0.171 sec/step)\n",
            "I0601 12:18:53.402865 140438660523904 learning.py:507] global step 8588: loss = 0.1307 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8589: loss = 0.0202 (0.151 sec/step)\n",
            "I0601 12:18:53.555540 140438660523904 learning.py:507] global step 8589: loss = 0.0202 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8590: loss = 0.1831 (0.174 sec/step)\n",
            "I0601 12:18:53.730467 140438660523904 learning.py:507] global step 8590: loss = 0.1831 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8591: loss = 0.1115 (0.163 sec/step)\n",
            "I0601 12:18:53.894727 140438660523904 learning.py:507] global step 8591: loss = 0.1115 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8592: loss = 0.1170 (0.168 sec/step)\n",
            "I0601 12:18:54.064300 140438660523904 learning.py:507] global step 8592: loss = 0.1170 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8593: loss = 0.3491 (0.164 sec/step)\n",
            "I0601 12:18:54.229443 140438660523904 learning.py:507] global step 8593: loss = 0.3491 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8594: loss = 0.0773 (0.147 sec/step)\n",
            "I0601 12:18:54.377485 140438660523904 learning.py:507] global step 8594: loss = 0.0773 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 8595: loss = 0.1888 (0.180 sec/step)\n",
            "I0601 12:18:54.559183 140438660523904 learning.py:507] global step 8595: loss = 0.1888 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8596: loss = 0.1052 (0.172 sec/step)\n",
            "I0601 12:18:54.732899 140438660523904 learning.py:507] global step 8596: loss = 0.1052 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8597: loss = 0.1369 (0.170 sec/step)\n",
            "I0601 12:18:54.904804 140438660523904 learning.py:507] global step 8597: loss = 0.1369 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8598: loss = 0.1170 (0.159 sec/step)\n",
            "I0601 12:18:55.064924 140438660523904 learning.py:507] global step 8598: loss = 0.1170 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8599: loss = 0.0800 (0.186 sec/step)\n",
            "I0601 12:18:55.252389 140438660523904 learning.py:507] global step 8599: loss = 0.0800 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8600: loss = 0.0619 (0.194 sec/step)\n",
            "I0601 12:18:55.447843 140438660523904 learning.py:507] global step 8600: loss = 0.0619 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8601: loss = 0.1694 (0.163 sec/step)\n",
            "I0601 12:18:55.612043 140438660523904 learning.py:507] global step 8601: loss = 0.1694 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8602: loss = 0.0670 (0.180 sec/step)\n",
            "I0601 12:18:55.793356 140438660523904 learning.py:507] global step 8602: loss = 0.0670 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8603: loss = 0.0681 (0.169 sec/step)\n",
            "I0601 12:18:55.963290 140438660523904 learning.py:507] global step 8603: loss = 0.0681 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8604: loss = 0.0508 (0.172 sec/step)\n",
            "I0601 12:18:56.137535 140438660523904 learning.py:507] global step 8604: loss = 0.0508 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8605: loss = 0.0966 (0.158 sec/step)\n",
            "I0601 12:18:56.297153 140438660523904 learning.py:507] global step 8605: loss = 0.0966 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8606: loss = 0.1081 (0.184 sec/step)\n",
            "I0601 12:18:56.482379 140438660523904 learning.py:507] global step 8606: loss = 0.1081 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8607: loss = 0.2402 (0.171 sec/step)\n",
            "I0601 12:18:56.654430 140438660523904 learning.py:507] global step 8607: loss = 0.2402 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8608: loss = 0.2536 (0.201 sec/step)\n",
            "I0601 12:18:56.857053 140438660523904 learning.py:507] global step 8608: loss = 0.2536 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 8609: loss = 0.0837 (0.173 sec/step)\n",
            "I0601 12:18:57.031970 140438660523904 learning.py:507] global step 8609: loss = 0.0837 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8610: loss = 0.0419 (0.164 sec/step)\n",
            "I0601 12:18:57.197391 140438660523904 learning.py:507] global step 8610: loss = 0.0419 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8611: loss = 0.1934 (0.176 sec/step)\n",
            "I0601 12:18:57.375108 140438660523904 learning.py:507] global step 8611: loss = 0.1934 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8612: loss = 0.1392 (0.174 sec/step)\n",
            "I0601 12:18:57.550475 140438660523904 learning.py:507] global step 8612: loss = 0.1392 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8613: loss = 0.0485 (0.149 sec/step)\n",
            "I0601 12:18:57.700556 140438660523904 learning.py:507] global step 8613: loss = 0.0485 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 8614: loss = 0.0384 (0.142 sec/step)\n",
            "I0601 12:18:57.843835 140438660523904 learning.py:507] global step 8614: loss = 0.0384 (0.142 sec/step)\n",
            "INFO:tensorflow:global step 8615: loss = 0.0635 (0.156 sec/step)\n",
            "I0601 12:18:58.000638 140438660523904 learning.py:507] global step 8615: loss = 0.0635 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8616: loss = 0.0692 (0.171 sec/step)\n",
            "I0601 12:18:58.173365 140438660523904 learning.py:507] global step 8616: loss = 0.0692 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8617: loss = 0.0298 (0.183 sec/step)\n",
            "I0601 12:18:58.357726 140438660523904 learning.py:507] global step 8617: loss = 0.0298 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8618: loss = 0.1763 (0.186 sec/step)\n",
            "I0601 12:18:58.545351 140438660523904 learning.py:507] global step 8618: loss = 0.1763 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8619: loss = 0.0715 (0.178 sec/step)\n",
            "I0601 12:18:58.724393 140438660523904 learning.py:507] global step 8619: loss = 0.0715 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8620: loss = 0.0622 (0.183 sec/step)\n",
            "I0601 12:18:58.908741 140438660523904 learning.py:507] global step 8620: loss = 0.0622 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8621: loss = 0.0717 (0.156 sec/step)\n",
            "I0601 12:18:59.066118 140438660523904 learning.py:507] global step 8621: loss = 0.0717 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8622: loss = 0.0761 (0.162 sec/step)\n",
            "I0601 12:18:59.229109 140438660523904 learning.py:507] global step 8622: loss = 0.0761 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8623: loss = 0.0475 (0.200 sec/step)\n",
            "I0601 12:18:59.430253 140438660523904 learning.py:507] global step 8623: loss = 0.0475 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 8624: loss = 0.2625 (0.185 sec/step)\n",
            "I0601 12:18:59.616803 140438660523904 learning.py:507] global step 8624: loss = 0.2625 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8625: loss = 0.0991 (0.159 sec/step)\n",
            "I0601 12:18:59.777133 140438660523904 learning.py:507] global step 8625: loss = 0.0991 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8626: loss = 0.0594 (0.156 sec/step)\n",
            "I0601 12:18:59.934636 140438660523904 learning.py:507] global step 8626: loss = 0.0594 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8627: loss = 0.0221 (0.174 sec/step)\n",
            "I0601 12:19:00.110150 140438660523904 learning.py:507] global step 8627: loss = 0.0221 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8628: loss = 0.0430 (0.171 sec/step)\n",
            "I0601 12:19:00.282090 140438660523904 learning.py:507] global step 8628: loss = 0.0430 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8629: loss = 0.1356 (0.171 sec/step)\n",
            "I0601 12:19:00.454357 140438660523904 learning.py:507] global step 8629: loss = 0.1356 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8630: loss = 0.0826 (0.195 sec/step)\n",
            "I0601 12:19:00.650741 140438660523904 learning.py:507] global step 8630: loss = 0.0826 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8631: loss = 0.1884 (0.178 sec/step)\n",
            "I0601 12:19:00.830150 140438660523904 learning.py:507] global step 8631: loss = 0.1884 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8632: loss = 0.1388 (0.192 sec/step)\n",
            "I0601 12:19:01.023458 140438660523904 learning.py:507] global step 8632: loss = 0.1388 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8633: loss = 0.2647 (0.156 sec/step)\n",
            "I0601 12:19:01.180723 140438660523904 learning.py:507] global step 8633: loss = 0.2647 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8634: loss = 0.0755 (0.191 sec/step)\n",
            "I0601 12:19:01.373048 140438660523904 learning.py:507] global step 8634: loss = 0.0755 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8635: loss = 0.0614 (0.186 sec/step)\n",
            "I0601 12:19:01.560449 140438660523904 learning.py:507] global step 8635: loss = 0.0614 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8636: loss = 0.0581 (0.156 sec/step)\n",
            "I0601 12:19:01.718020 140438660523904 learning.py:507] global step 8636: loss = 0.0581 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8637: loss = 0.0670 (0.191 sec/step)\n",
            "I0601 12:19:01.911028 140438660523904 learning.py:507] global step 8637: loss = 0.0670 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8638: loss = 0.2421 (0.159 sec/step)\n",
            "I0601 12:19:02.071213 140438660523904 learning.py:507] global step 8638: loss = 0.2421 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8639: loss = 0.1152 (0.174 sec/step)\n",
            "I0601 12:19:02.246787 140438660523904 learning.py:507] global step 8639: loss = 0.1152 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8640: loss = 0.0713 (0.183 sec/step)\n",
            "I0601 12:19:02.430718 140438660523904 learning.py:507] global step 8640: loss = 0.0713 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8641: loss = 0.1429 (0.178 sec/step)\n",
            "I0601 12:19:02.609797 140438660523904 learning.py:507] global step 8641: loss = 0.1429 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8642: loss = 0.1283 (0.185 sec/step)\n",
            "I0601 12:19:02.795789 140438660523904 learning.py:507] global step 8642: loss = 0.1283 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8643: loss = 0.5399 (0.154 sec/step)\n",
            "I0601 12:19:02.951459 140438660523904 learning.py:507] global step 8643: loss = 0.5399 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8644: loss = 0.1226 (0.160 sec/step)\n",
            "I0601 12:19:03.113072 140438660523904 learning.py:507] global step 8644: loss = 0.1226 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8645: loss = 0.1490 (0.164 sec/step)\n",
            "I0601 12:19:03.278690 140438660523904 learning.py:507] global step 8645: loss = 0.1490 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8646: loss = 0.1392 (0.185 sec/step)\n",
            "I0601 12:19:03.464975 140438660523904 learning.py:507] global step 8646: loss = 0.1392 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8647: loss = 0.1293 (0.188 sec/step)\n",
            "I0601 12:19:03.654700 140438660523904 learning.py:507] global step 8647: loss = 0.1293 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8648: loss = 0.0393 (0.145 sec/step)\n",
            "I0601 12:19:03.801552 140438660523904 learning.py:507] global step 8648: loss = 0.0393 (0.145 sec/step)\n",
            "INFO:tensorflow:global step 8649: loss = 0.0288 (0.185 sec/step)\n",
            "I0601 12:19:03.988032 140438660523904 learning.py:507] global step 8649: loss = 0.0288 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8650: loss = 0.0388 (0.170 sec/step)\n",
            "I0601 12:19:04.159868 140438660523904 learning.py:507] global step 8650: loss = 0.0388 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8651: loss = 0.0555 (0.155 sec/step)\n",
            "I0601 12:19:04.316751 140438660523904 learning.py:507] global step 8651: loss = 0.0555 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8652: loss = 0.1101 (0.193 sec/step)\n",
            "I0601 12:19:04.511309 140438660523904 learning.py:507] global step 8652: loss = 0.1101 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8653: loss = 0.0629 (0.189 sec/step)\n",
            "I0601 12:19:04.701615 140438660523904 learning.py:507] global step 8653: loss = 0.0629 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8654: loss = 0.1584 (0.188 sec/step)\n",
            "I0601 12:19:04.891349 140438660523904 learning.py:507] global step 8654: loss = 0.1584 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8655: loss = 0.1320 (0.182 sec/step)\n",
            "I0601 12:19:05.074281 140438660523904 learning.py:507] global step 8655: loss = 0.1320 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8656: loss = 0.0827 (0.201 sec/step)\n",
            "I0601 12:19:05.276720 140438660523904 learning.py:507] global step 8656: loss = 0.0827 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 8657: loss = 0.0382 (0.144 sec/step)\n",
            "I0601 12:19:05.422563 140438660523904 learning.py:507] global step 8657: loss = 0.0382 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 8658: loss = 0.0518 (0.176 sec/step)\n",
            "I0601 12:19:05.600131 140438660523904 learning.py:507] global step 8658: loss = 0.0518 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8659: loss = 0.1785 (0.168 sec/step)\n",
            "I0601 12:19:05.770007 140438660523904 learning.py:507] global step 8659: loss = 0.1785 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8660: loss = 0.0719 (0.163 sec/step)\n",
            "I0601 12:19:05.934382 140438660523904 learning.py:507] global step 8660: loss = 0.0719 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8661: loss = 0.1942 (0.188 sec/step)\n",
            "I0601 12:19:06.123914 140438660523904 learning.py:507] global step 8661: loss = 0.1942 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8662: loss = 0.0656 (0.167 sec/step)\n",
            "I0601 12:19:06.292582 140438660523904 learning.py:507] global step 8662: loss = 0.0656 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8663: loss = 0.2804 (0.169 sec/step)\n",
            "I0601 12:19:06.463370 140438660523904 learning.py:507] global step 8663: loss = 0.2804 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8664: loss = 0.1076 (0.182 sec/step)\n",
            "I0601 12:19:06.646558 140438660523904 learning.py:507] global step 8664: loss = 0.1076 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8665: loss = 0.0788 (0.217 sec/step)\n",
            "I0601 12:19:06.865358 140438660523904 learning.py:507] global step 8665: loss = 0.0788 (0.217 sec/step)\n",
            "INFO:tensorflow:global step 8666: loss = 0.0895 (0.189 sec/step)\n",
            "I0601 12:19:07.055511 140438660523904 learning.py:507] global step 8666: loss = 0.0895 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8667: loss = 0.1618 (0.166 sec/step)\n",
            "I0601 12:19:07.223191 140438660523904 learning.py:507] global step 8667: loss = 0.1618 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8668: loss = 0.3030 (0.197 sec/step)\n",
            "I0601 12:19:07.421210 140438660523904 learning.py:507] global step 8668: loss = 0.3030 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 8669: loss = 0.0346 (0.166 sec/step)\n",
            "I0601 12:19:07.588526 140438660523904 learning.py:507] global step 8669: loss = 0.0346 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8670: loss = 0.2318 (0.185 sec/step)\n",
            "I0601 12:19:07.775005 140438660523904 learning.py:507] global step 8670: loss = 0.2318 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8671: loss = 0.1952 (0.175 sec/step)\n",
            "I0601 12:19:07.951828 140438660523904 learning.py:507] global step 8671: loss = 0.1952 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8672: loss = 0.3510 (0.168 sec/step)\n",
            "I0601 12:19:08.121637 140438660523904 learning.py:507] global step 8672: loss = 0.3510 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8673: loss = 0.0570 (0.179 sec/step)\n",
            "I0601 12:19:08.301924 140438660523904 learning.py:507] global step 8673: loss = 0.0570 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8674: loss = 0.2318 (0.177 sec/step)\n",
            "I0601 12:19:08.480993 140438660523904 learning.py:507] global step 8674: loss = 0.2318 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8675: loss = 0.1023 (0.176 sec/step)\n",
            "I0601 12:19:08.659281 140438660523904 learning.py:507] global step 8675: loss = 0.1023 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8676: loss = 0.3136 (0.183 sec/step)\n",
            "I0601 12:19:08.843687 140438660523904 learning.py:507] global step 8676: loss = 0.3136 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8677: loss = 0.0344 (0.144 sec/step)\n",
            "I0601 12:19:08.988926 140438660523904 learning.py:507] global step 8677: loss = 0.0344 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 8678: loss = 0.2223 (0.194 sec/step)\n",
            "I0601 12:19:09.183888 140438660523904 learning.py:507] global step 8678: loss = 0.2223 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8679: loss = 0.0435 (0.169 sec/step)\n",
            "I0601 12:19:09.353742 140438660523904 learning.py:507] global step 8679: loss = 0.0435 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8680: loss = 0.0869 (0.182 sec/step)\n",
            "I0601 12:19:09.537401 140438660523904 learning.py:507] global step 8680: loss = 0.0869 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8681: loss = 0.1456 (0.179 sec/step)\n",
            "I0601 12:19:09.717580 140438660523904 learning.py:507] global step 8681: loss = 0.1456 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8682: loss = 0.4250 (0.161 sec/step)\n",
            "I0601 12:19:09.880431 140438660523904 learning.py:507] global step 8682: loss = 0.4250 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8683: loss = 0.0294 (0.169 sec/step)\n",
            "I0601 12:19:10.051320 140438660523904 learning.py:507] global step 8683: loss = 0.0294 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8684: loss = 0.1645 (0.196 sec/step)\n",
            "I0601 12:19:10.249103 140438660523904 learning.py:507] global step 8684: loss = 0.1645 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 8685: loss = 0.1144 (0.170 sec/step)\n",
            "I0601 12:19:10.420122 140438660523904 learning.py:507] global step 8685: loss = 0.1144 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8686: loss = 0.0969 (0.156 sec/step)\n",
            "I0601 12:19:10.577781 140438660523904 learning.py:507] global step 8686: loss = 0.0969 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8687: loss = 0.2454 (0.176 sec/step)\n",
            "I0601 12:19:10.755654 140438660523904 learning.py:507] global step 8687: loss = 0.2454 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8688: loss = 0.0700 (0.157 sec/step)\n",
            "I0601 12:19:10.914287 140438660523904 learning.py:507] global step 8688: loss = 0.0700 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8689: loss = 0.1017 (0.156 sec/step)\n",
            "I0601 12:19:11.071526 140438660523904 learning.py:507] global step 8689: loss = 0.1017 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8690: loss = 0.1072 (0.170 sec/step)\n",
            "I0601 12:19:11.242917 140438660523904 learning.py:507] global step 8690: loss = 0.1072 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8691: loss = 0.0309 (0.171 sec/step)\n",
            "I0601 12:19:11.414815 140438660523904 learning.py:507] global step 8691: loss = 0.0309 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8692: loss = 0.1170 (0.181 sec/step)\n",
            "I0601 12:19:11.596800 140438660523904 learning.py:507] global step 8692: loss = 0.1170 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8693: loss = 0.1783 (0.167 sec/step)\n",
            "I0601 12:19:11.765548 140438660523904 learning.py:507] global step 8693: loss = 0.1783 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8694: loss = 0.0628 (0.165 sec/step)\n",
            "I0601 12:19:11.931687 140438660523904 learning.py:507] global step 8694: loss = 0.0628 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8695: loss = 0.0167 (0.151 sec/step)\n",
            "I0601 12:19:12.083811 140438660523904 learning.py:507] global step 8695: loss = 0.0167 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8696: loss = 0.0530 (0.171 sec/step)\n",
            "I0601 12:19:12.255842 140438660523904 learning.py:507] global step 8696: loss = 0.0530 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8697: loss = 0.0600 (0.148 sec/step)\n",
            "I0601 12:19:12.405136 140438660523904 learning.py:507] global step 8697: loss = 0.0600 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 8698: loss = 0.0336 (0.162 sec/step)\n",
            "I0601 12:19:12.569193 140438660523904 learning.py:507] global step 8698: loss = 0.0336 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8699: loss = 0.0881 (0.171 sec/step)\n",
            "I0601 12:19:12.742012 140438660523904 learning.py:507] global step 8699: loss = 0.0881 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8700: loss = 0.1521 (0.157 sec/step)\n",
            "I0601 12:19:12.900001 140438660523904 learning.py:507] global step 8700: loss = 0.1521 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8701: loss = 0.1230 (0.173 sec/step)\n",
            "I0601 12:19:13.074579 140438660523904 learning.py:507] global step 8701: loss = 0.1230 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8702: loss = 0.1101 (0.151 sec/step)\n",
            "I0601 12:19:13.227634 140438660523904 learning.py:507] global step 8702: loss = 0.1101 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8703: loss = 0.2481 (0.221 sec/step)\n",
            "I0601 12:19:13.450100 140438660523904 learning.py:507] global step 8703: loss = 0.2481 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8704: loss = 0.0660 (0.172 sec/step)\n",
            "I0601 12:19:13.623207 140438660523904 learning.py:507] global step 8704: loss = 0.0660 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8705: loss = 0.1749 (0.176 sec/step)\n",
            "I0601 12:19:13.801010 140438660523904 learning.py:507] global step 8705: loss = 0.1749 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8706: loss = 0.2041 (0.173 sec/step)\n",
            "I0601 12:19:13.975650 140438660523904 learning.py:507] global step 8706: loss = 0.2041 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8707: loss = 0.0404 (0.169 sec/step)\n",
            "I0601 12:19:14.146007 140438660523904 learning.py:507] global step 8707: loss = 0.0404 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8708: loss = 0.1408 (0.157 sec/step)\n",
            "I0601 12:19:14.304624 140438660523904 learning.py:507] global step 8708: loss = 0.1408 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8709: loss = 0.0379 (0.184 sec/step)\n",
            "I0601 12:19:14.490310 140438660523904 learning.py:507] global step 8709: loss = 0.0379 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8710: loss = 0.1548 (0.162 sec/step)\n",
            "I0601 12:19:14.653338 140438660523904 learning.py:507] global step 8710: loss = 0.1548 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8711: loss = 0.1887 (0.157 sec/step)\n",
            "I0601 12:19:14.812295 140438660523904 learning.py:507] global step 8711: loss = 0.1887 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 8712: loss = 0.0490 (0.175 sec/step)\n",
            "I0601 12:19:14.988540 140438660523904 learning.py:507] global step 8712: loss = 0.0490 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8713: loss = 0.2209 (0.163 sec/step)\n",
            "I0601 12:19:15.153451 140438660523904 learning.py:507] global step 8713: loss = 0.2209 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8714: loss = 0.0570 (0.168 sec/step)\n",
            "I0601 12:19:15.322697 140438660523904 learning.py:507] global step 8714: loss = 0.0570 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8715: loss = 0.0531 (0.168 sec/step)\n",
            "I0601 12:19:15.492387 140438660523904 learning.py:507] global step 8715: loss = 0.0531 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8716: loss = 0.1353 (0.195 sec/step)\n",
            "I0601 12:19:15.689134 140438660523904 learning.py:507] global step 8716: loss = 0.1353 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8717: loss = 0.2121 (0.175 sec/step)\n",
            "I0601 12:19:15.866141 140438660523904 learning.py:507] global step 8717: loss = 0.2121 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8718: loss = 0.0649 (0.188 sec/step)\n",
            "I0601 12:19:16.056072 140438660523904 learning.py:507] global step 8718: loss = 0.0649 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8719: loss = 0.1783 (0.166 sec/step)\n",
            "I0601 12:19:16.223667 140438660523904 learning.py:507] global step 8719: loss = 0.1783 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8720: loss = 0.0749 (0.193 sec/step)\n",
            "I0601 12:19:16.418406 140438660523904 learning.py:507] global step 8720: loss = 0.0749 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8721: loss = 0.1527 (0.169 sec/step)\n",
            "I0601 12:19:16.589121 140438660523904 learning.py:507] global step 8721: loss = 0.1527 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8722: loss = 0.0331 (0.169 sec/step)\n",
            "I0601 12:19:16.759341 140438660523904 learning.py:507] global step 8722: loss = 0.0331 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8723: loss = 0.2416 (0.176 sec/step)\n",
            "I0601 12:19:16.937180 140438660523904 learning.py:507] global step 8723: loss = 0.2416 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8724: loss = 0.1303 (0.172 sec/step)\n",
            "I0601 12:19:17.110661 140438660523904 learning.py:507] global step 8724: loss = 0.1303 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8725: loss = 0.1568 (0.156 sec/step)\n",
            "I0601 12:19:17.268195 140438660523904 learning.py:507] global step 8725: loss = 0.1568 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8726: loss = 0.1492 (0.171 sec/step)\n",
            "I0601 12:19:17.440696 140438660523904 learning.py:507] global step 8726: loss = 0.1492 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8727: loss = 0.3606 (0.171 sec/step)\n",
            "I0601 12:19:17.613489 140438660523904 learning.py:507] global step 8727: loss = 0.3606 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8728: loss = 0.1165 (0.183 sec/step)\n",
            "I0601 12:19:17.797327 140438660523904 learning.py:507] global step 8728: loss = 0.1165 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8729: loss = 0.3452 (0.177 sec/step)\n",
            "I0601 12:19:17.976071 140438660523904 learning.py:507] global step 8729: loss = 0.3452 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8730: loss = 0.0211 (0.167 sec/step)\n",
            "I0601 12:19:18.144202 140438660523904 learning.py:507] global step 8730: loss = 0.0211 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8731: loss = 0.0875 (0.188 sec/step)\n",
            "I0601 12:19:18.333355 140438660523904 learning.py:507] global step 8731: loss = 0.0875 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8732: loss = 0.2897 (0.163 sec/step)\n",
            "I0601 12:19:18.497572 140438660523904 learning.py:507] global step 8732: loss = 0.2897 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8733: loss = 0.1009 (0.172 sec/step)\n",
            "I0601 12:19:18.670518 140438660523904 learning.py:507] global step 8733: loss = 0.1009 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8734: loss = 0.1186 (0.204 sec/step)\n",
            "I0601 12:19:18.876863 140438660523904 learning.py:507] global step 8734: loss = 0.1186 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 8735: loss = 0.0702 (0.181 sec/step)\n",
            "I0601 12:19:19.059009 140438660523904 learning.py:507] global step 8735: loss = 0.0702 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8736: loss = 0.1768 (0.189 sec/step)\n",
            "I0601 12:19:19.249415 140438660523904 learning.py:507] global step 8736: loss = 0.1768 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8737: loss = 0.1578 (0.179 sec/step)\n",
            "I0601 12:19:19.430315 140438660523904 learning.py:507] global step 8737: loss = 0.1578 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8738: loss = 0.2206 (0.168 sec/step)\n",
            "I0601 12:19:19.600058 140438660523904 learning.py:507] global step 8738: loss = 0.2206 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8739: loss = 0.1955 (0.184 sec/step)\n",
            "I0601 12:19:19.784845 140438660523904 learning.py:507] global step 8739: loss = 0.1955 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8740: loss = 0.0656 (0.183 sec/step)\n",
            "I0601 12:19:19.968638 140438660523904 learning.py:507] global step 8740: loss = 0.0656 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8741: loss = 0.0663 (0.209 sec/step)\n",
            "I0601 12:19:20.179411 140438660523904 learning.py:507] global step 8741: loss = 0.0663 (0.209 sec/step)\n",
            "INFO:tensorflow:global step 8742: loss = 0.2570 (0.166 sec/step)\n",
            "I0601 12:19:20.346565 140438660523904 learning.py:507] global step 8742: loss = 0.2570 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8743: loss = 0.2536 (0.181 sec/step)\n",
            "I0601 12:19:20.529022 140438660523904 learning.py:507] global step 8743: loss = 0.2536 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8744: loss = 0.2783 (0.181 sec/step)\n",
            "I0601 12:19:20.714049 140438660523904 learning.py:507] global step 8744: loss = 0.2783 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8745: loss = 0.1958 (0.172 sec/step)\n",
            "I0601 12:19:20.887976 140438660523904 learning.py:507] global step 8745: loss = 0.1958 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8746: loss = 0.0260 (0.186 sec/step)\n",
            "I0601 12:19:21.075194 140438660523904 learning.py:507] global step 8746: loss = 0.0260 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8747: loss = 0.2235 (0.201 sec/step)\n",
            "I0601 12:19:21.277321 140438660523904 learning.py:507] global step 8747: loss = 0.2235 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 8748: loss = 0.1013 (0.178 sec/step)\n",
            "I0601 12:19:21.457126 140438660523904 learning.py:507] global step 8748: loss = 0.1013 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8749: loss = 0.0930 (0.179 sec/step)\n",
            "I0601 12:19:21.637575 140438660523904 learning.py:507] global step 8749: loss = 0.0930 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8750: loss = 0.1665 (0.170 sec/step)\n",
            "I0601 12:19:21.808307 140438660523904 learning.py:507] global step 8750: loss = 0.1665 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8751: loss = 0.2582 (0.171 sec/step)\n",
            "I0601 12:19:21.980198 140438660523904 learning.py:507] global step 8751: loss = 0.2582 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8752: loss = 0.3155 (0.167 sec/step)\n",
            "I0601 12:19:22.148465 140438660523904 learning.py:507] global step 8752: loss = 0.3155 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8753: loss = 0.3820 (0.176 sec/step)\n",
            "I0601 12:19:22.325913 140438660523904 learning.py:507] global step 8753: loss = 0.3820 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8754: loss = 0.1234 (0.179 sec/step)\n",
            "I0601 12:19:22.506613 140438660523904 learning.py:507] global step 8754: loss = 0.1234 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8755: loss = 0.1421 (0.182 sec/step)\n",
            "I0601 12:19:22.690220 140438660523904 learning.py:507] global step 8755: loss = 0.1421 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8756: loss = 0.1637 (0.182 sec/step)\n",
            "I0601 12:19:22.873523 140438660523904 learning.py:507] global step 8756: loss = 0.1637 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8757: loss = 0.0395 (0.155 sec/step)\n",
            "I0601 12:19:23.029970 140438660523904 learning.py:507] global step 8757: loss = 0.0395 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8758: loss = 0.1363 (0.173 sec/step)\n",
            "I0601 12:19:23.205007 140438660523904 learning.py:507] global step 8758: loss = 0.1363 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8759: loss = 0.0945 (0.176 sec/step)\n",
            "I0601 12:19:23.382848 140438660523904 learning.py:507] global step 8759: loss = 0.0945 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8760: loss = 0.1182 (0.170 sec/step)\n",
            "I0601 12:19:23.554777 140438660523904 learning.py:507] global step 8760: loss = 0.1182 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8761: loss = 0.1798 (0.165 sec/step)\n",
            "I0601 12:19:23.721624 140438660523904 learning.py:507] global step 8761: loss = 0.1798 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8762: loss = 0.1211 (0.184 sec/step)\n",
            "I0601 12:19:23.906939 140438660523904 learning.py:507] global step 8762: loss = 0.1211 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8763: loss = 0.1452 (0.160 sec/step)\n",
            "I0601 12:19:24.069036 140438660523904 learning.py:507] global step 8763: loss = 0.1452 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8764: loss = 0.0426 (0.173 sec/step)\n",
            "I0601 12:19:24.243146 140438660523904 learning.py:507] global step 8764: loss = 0.0426 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8765: loss = 0.4122 (0.172 sec/step)\n",
            "I0601 12:19:24.416810 140438660523904 learning.py:507] global step 8765: loss = 0.4122 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8766: loss = 0.0623 (0.223 sec/step)\n",
            "I0601 12:19:24.641085 140438660523904 learning.py:507] global step 8766: loss = 0.0623 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8767: loss = 0.1920 (0.173 sec/step)\n",
            "I0601 12:19:24.815780 140438660523904 learning.py:507] global step 8767: loss = 0.1920 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8768: loss = 0.0690 (0.162 sec/step)\n",
            "I0601 12:19:24.979317 140438660523904 learning.py:507] global step 8768: loss = 0.0690 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8769: loss = 0.2414 (0.173 sec/step)\n",
            "I0601 12:19:25.154014 140438660523904 learning.py:507] global step 8769: loss = 0.2414 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8770: loss = 0.1142 (0.191 sec/step)\n",
            "I0601 12:19:25.346399 140438660523904 learning.py:507] global step 8770: loss = 0.1142 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8771: loss = 0.1989 (0.151 sec/step)\n",
            "I0601 12:19:25.498640 140438660523904 learning.py:507] global step 8771: loss = 0.1989 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 8772: loss = 0.1949 (0.204 sec/step)\n",
            "I0601 12:19:25.703891 140438660523904 learning.py:507] global step 8772: loss = 0.1949 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 8773: loss = 0.1807 (0.178 sec/step)\n",
            "I0601 12:19:25.883219 140438660523904 learning.py:507] global step 8773: loss = 0.1807 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8774: loss = 0.1011 (0.162 sec/step)\n",
            "I0601 12:19:26.046353 140438660523904 learning.py:507] global step 8774: loss = 0.1011 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8775: loss = 0.1446 (0.171 sec/step)\n",
            "I0601 12:19:26.218595 140438660523904 learning.py:507] global step 8775: loss = 0.1446 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8776: loss = 0.1413 (0.180 sec/step)\n",
            "I0601 12:19:26.399891 140438660523904 learning.py:507] global step 8776: loss = 0.1413 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8777: loss = 0.0281 (0.154 sec/step)\n",
            "I0601 12:19:26.554715 140438660523904 learning.py:507] global step 8777: loss = 0.0281 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8778: loss = 0.2417 (0.164 sec/step)\n",
            "I0601 12:19:26.720343 140438660523904 learning.py:507] global step 8778: loss = 0.2417 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8779: loss = 0.2821 (0.197 sec/step)\n",
            "I0601 12:19:26.919169 140438660523904 learning.py:507] global step 8779: loss = 0.2821 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 8780: loss = 0.1105 (0.195 sec/step)\n",
            "I0601 12:19:27.116043 140438660523904 learning.py:507] global step 8780: loss = 0.1105 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8781: loss = 0.0781 (0.166 sec/step)\n",
            "I0601 12:19:27.283345 140438660523904 learning.py:507] global step 8781: loss = 0.0781 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8782: loss = 0.0866 (0.270 sec/step)\n",
            "I0601 12:19:27.557643 140438660523904 learning.py:507] global step 8782: loss = 0.0866 (0.270 sec/step)\n",
            "INFO:tensorflow:global step 8783: loss = 0.0147 (0.252 sec/step)\n",
            "I0601 12:19:27.819699 140438660523904 learning.py:507] global step 8783: loss = 0.0147 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8784: loss = 0.0507 (0.256 sec/step)\n",
            "I0601 12:19:28.119345 140438660523904 learning.py:507] global step 8784: loss = 0.0507 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 8785: loss = 0.1284 (0.215 sec/step)\n",
            "I0601 12:19:28.337757 140438660523904 learning.py:507] global step 8785: loss = 0.1284 (0.215 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8785.\n",
            "I0601 12:19:28.377950 140435003524864 supervisor.py:1050] Recording summary at step 8785.\n",
            "INFO:tensorflow:global step 8786: loss = 0.1334 (0.177 sec/step)\n",
            "I0601 12:19:28.516587 140438660523904 learning.py:507] global step 8786: loss = 0.1334 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8787: loss = 0.0330 (0.171 sec/step)\n",
            "I0601 12:19:28.689199 140438660523904 learning.py:507] global step 8787: loss = 0.0330 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8788: loss = 0.2305 (0.190 sec/step)\n",
            "I0601 12:19:28.880290 140438660523904 learning.py:507] global step 8788: loss = 0.2305 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 8789: loss = 4.1666 (0.184 sec/step)\n",
            "I0601 12:19:29.065133 140438660523904 learning.py:507] global step 8789: loss = 4.1666 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8790: loss = 0.1685 (0.181 sec/step)\n",
            "I0601 12:19:29.247283 140438660523904 learning.py:507] global step 8790: loss = 0.1685 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8791: loss = 0.0908 (0.174 sec/step)\n",
            "I0601 12:19:29.422696 140438660523904 learning.py:507] global step 8791: loss = 0.0908 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8792: loss = 0.2804 (0.191 sec/step)\n",
            "I0601 12:19:29.615160 140438660523904 learning.py:507] global step 8792: loss = 0.2804 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 8793: loss = 0.0162 (0.171 sec/step)\n",
            "I0601 12:19:29.787279 140438660523904 learning.py:507] global step 8793: loss = 0.0162 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8794: loss = 0.0857 (0.169 sec/step)\n",
            "I0601 12:19:29.957921 140438660523904 learning.py:507] global step 8794: loss = 0.0857 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 8795: loss = 0.1008 (0.189 sec/step)\n",
            "I0601 12:19:30.148470 140438660523904 learning.py:507] global step 8795: loss = 0.1008 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8796: loss = 0.0735 (0.161 sec/step)\n",
            "I0601 12:19:30.311216 140438660523904 learning.py:507] global step 8796: loss = 0.0735 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8797: loss = 0.0928 (0.189 sec/step)\n",
            "I0601 12:19:30.501630 140438660523904 learning.py:507] global step 8797: loss = 0.0928 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8798: loss = 0.4590 (0.166 sec/step)\n",
            "I0601 12:19:30.669100 140438660523904 learning.py:507] global step 8798: loss = 0.4590 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8799: loss = 0.1239 (0.173 sec/step)\n",
            "I0601 12:19:30.843408 140438660523904 learning.py:507] global step 8799: loss = 0.1239 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8800: loss = 0.1711 (0.175 sec/step)\n",
            "I0601 12:19:31.020221 140438660523904 learning.py:507] global step 8800: loss = 0.1711 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8801: loss = 0.1507 (0.174 sec/step)\n",
            "I0601 12:19:31.196208 140438660523904 learning.py:507] global step 8801: loss = 0.1507 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8802: loss = 0.1690 (0.175 sec/step)\n",
            "I0601 12:19:31.372643 140438660523904 learning.py:507] global step 8802: loss = 0.1690 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8803: loss = 0.0573 (0.172 sec/step)\n",
            "I0601 12:19:31.545942 140438660523904 learning.py:507] global step 8803: loss = 0.0573 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8804: loss = 0.1805 (0.165 sec/step)\n",
            "I0601 12:19:31.712360 140438660523904 learning.py:507] global step 8804: loss = 0.1805 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8805: loss = 0.0652 (0.176 sec/step)\n",
            "I0601 12:19:31.891078 140438660523904 learning.py:507] global step 8805: loss = 0.0652 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8806: loss = 0.0499 (0.170 sec/step)\n",
            "I0601 12:19:32.063850 140438660523904 learning.py:507] global step 8806: loss = 0.0499 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8807: loss = 0.1850 (0.174 sec/step)\n",
            "I0601 12:19:32.239584 140438660523904 learning.py:507] global step 8807: loss = 0.1850 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8808: loss = 0.0893 (0.185 sec/step)\n",
            "I0601 12:19:32.426083 140438660523904 learning.py:507] global step 8808: loss = 0.0893 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8809: loss = 0.0929 (0.182 sec/step)\n",
            "I0601 12:19:32.609985 140438660523904 learning.py:507] global step 8809: loss = 0.0929 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8810: loss = 0.2582 (0.171 sec/step)\n",
            "I0601 12:19:32.782616 140438660523904 learning.py:507] global step 8810: loss = 0.2582 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8811: loss = 0.0831 (0.173 sec/step)\n",
            "I0601 12:19:32.956468 140438660523904 learning.py:507] global step 8811: loss = 0.0831 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8812: loss = 0.0757 (0.187 sec/step)\n",
            "I0601 12:19:33.145171 140438660523904 learning.py:507] global step 8812: loss = 0.0757 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8813: loss = 0.1263 (0.171 sec/step)\n",
            "I0601 12:19:33.318109 140438660523904 learning.py:507] global step 8813: loss = 0.1263 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8814: loss = 0.4324 (0.165 sec/step)\n",
            "I0601 12:19:33.484470 140438660523904 learning.py:507] global step 8814: loss = 0.4324 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8815: loss = 0.0593 (0.176 sec/step)\n",
            "I0601 12:19:33.662053 140438660523904 learning.py:507] global step 8815: loss = 0.0593 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8816: loss = 0.1061 (0.168 sec/step)\n",
            "I0601 12:19:33.831626 140438660523904 learning.py:507] global step 8816: loss = 0.1061 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8817: loss = 0.2651 (0.195 sec/step)\n",
            "I0601 12:19:34.028090 140438660523904 learning.py:507] global step 8817: loss = 0.2651 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8818: loss = 0.0442 (0.175 sec/step)\n",
            "I0601 12:19:34.204042 140438660523904 learning.py:507] global step 8818: loss = 0.0442 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8819: loss = 0.2057 (0.207 sec/step)\n",
            "I0601 12:19:34.412610 140438660523904 learning.py:507] global step 8819: loss = 0.2057 (0.207 sec/step)\n",
            "INFO:tensorflow:global step 8820: loss = 0.0315 (0.161 sec/step)\n",
            "I0601 12:19:34.574620 140438660523904 learning.py:507] global step 8820: loss = 0.0315 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8821: loss = 0.1449 (0.185 sec/step)\n",
            "I0601 12:19:34.760650 140438660523904 learning.py:507] global step 8821: loss = 0.1449 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8822: loss = 0.0769 (0.213 sec/step)\n",
            "I0601 12:19:34.975595 140438660523904 learning.py:507] global step 8822: loss = 0.0769 (0.213 sec/step)\n",
            "INFO:tensorflow:global step 8823: loss = 0.0474 (0.159 sec/step)\n",
            "I0601 12:19:35.136284 140438660523904 learning.py:507] global step 8823: loss = 0.0474 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8824: loss = 0.1221 (0.165 sec/step)\n",
            "I0601 12:19:35.302519 140438660523904 learning.py:507] global step 8824: loss = 0.1221 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8825: loss = 0.2314 (0.172 sec/step)\n",
            "I0601 12:19:35.475633 140438660523904 learning.py:507] global step 8825: loss = 0.2314 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8826: loss = 0.0290 (0.172 sec/step)\n",
            "I0601 12:19:35.648628 140438660523904 learning.py:507] global step 8826: loss = 0.0290 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8827: loss = 0.1138 (0.182 sec/step)\n",
            "I0601 12:19:35.832316 140438660523904 learning.py:507] global step 8827: loss = 0.1138 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8828: loss = 0.0532 (0.216 sec/step)\n",
            "I0601 12:19:36.050019 140438660523904 learning.py:507] global step 8828: loss = 0.0532 (0.216 sec/step)\n",
            "INFO:tensorflow:global step 8829: loss = 0.2468 (0.185 sec/step)\n",
            "I0601 12:19:36.236063 140438660523904 learning.py:507] global step 8829: loss = 0.2468 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8830: loss = 0.1223 (0.173 sec/step)\n",
            "I0601 12:19:36.410647 140438660523904 learning.py:507] global step 8830: loss = 0.1223 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8831: loss = 0.1773 (0.196 sec/step)\n",
            "I0601 12:19:36.607929 140438660523904 learning.py:507] global step 8831: loss = 0.1773 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 8832: loss = 0.0647 (0.136 sec/step)\n",
            "I0601 12:19:36.745629 140438660523904 learning.py:507] global step 8832: loss = 0.0647 (0.136 sec/step)\n",
            "INFO:tensorflow:global step 8833: loss = 0.0235 (0.192 sec/step)\n",
            "I0601 12:19:36.939117 140438660523904 learning.py:507] global step 8833: loss = 0.0235 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8834: loss = 0.1526 (0.166 sec/step)\n",
            "I0601 12:19:37.106932 140438660523904 learning.py:507] global step 8834: loss = 0.1526 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8835: loss = 0.1723 (0.168 sec/step)\n",
            "I0601 12:19:37.277108 140438660523904 learning.py:507] global step 8835: loss = 0.1723 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8836: loss = 0.0369 (0.154 sec/step)\n",
            "I0601 12:19:37.433273 140438660523904 learning.py:507] global step 8836: loss = 0.0369 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 8837: loss = 0.1015 (0.167 sec/step)\n",
            "I0601 12:19:37.601480 140438660523904 learning.py:507] global step 8837: loss = 0.1015 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8838: loss = 0.0660 (0.200 sec/step)\n",
            "I0601 12:19:37.802788 140438660523904 learning.py:507] global step 8838: loss = 0.0660 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 8839: loss = 0.0963 (0.161 sec/step)\n",
            "I0601 12:19:37.965672 140438660523904 learning.py:507] global step 8839: loss = 0.0963 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8840: loss = 0.1206 (0.177 sec/step)\n",
            "I0601 12:19:38.143657 140438660523904 learning.py:507] global step 8840: loss = 0.1206 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8841: loss = 0.0500 (0.163 sec/step)\n",
            "I0601 12:19:38.308344 140438660523904 learning.py:507] global step 8841: loss = 0.0500 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8842: loss = 0.1174 (0.167 sec/step)\n",
            "I0601 12:19:38.476414 140438660523904 learning.py:507] global step 8842: loss = 0.1174 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8843: loss = 0.0964 (0.159 sec/step)\n",
            "I0601 12:19:38.636820 140438660523904 learning.py:507] global step 8843: loss = 0.0964 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8844: loss = 0.0616 (0.159 sec/step)\n",
            "I0601 12:19:38.797260 140438660523904 learning.py:507] global step 8844: loss = 0.0616 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8845: loss = 0.3077 (0.170 sec/step)\n",
            "I0601 12:19:38.968285 140438660523904 learning.py:507] global step 8845: loss = 0.3077 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8846: loss = 0.1453 (0.152 sec/step)\n",
            "I0601 12:19:39.121200 140438660523904 learning.py:507] global step 8846: loss = 0.1453 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 8847: loss = 0.0911 (0.168 sec/step)\n",
            "I0601 12:19:39.290566 140438660523904 learning.py:507] global step 8847: loss = 0.0911 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8848: loss = 0.0605 (0.153 sec/step)\n",
            "I0601 12:19:39.444880 140438660523904 learning.py:507] global step 8848: loss = 0.0605 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 8849: loss = 0.1159 (0.196 sec/step)\n",
            "I0601 12:19:39.641921 140438660523904 learning.py:507] global step 8849: loss = 0.1159 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 8850: loss = 0.2459 (0.172 sec/step)\n",
            "I0601 12:19:39.815787 140438660523904 learning.py:507] global step 8850: loss = 0.2459 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8851: loss = 0.0757 (0.167 sec/step)\n",
            "I0601 12:19:39.984686 140438660523904 learning.py:507] global step 8851: loss = 0.0757 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8852: loss = 0.0508 (0.172 sec/step)\n",
            "I0601 12:19:40.158752 140438660523904 learning.py:507] global step 8852: loss = 0.0508 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8853: loss = 0.0539 (0.174 sec/step)\n",
            "I0601 12:19:40.334385 140438660523904 learning.py:507] global step 8853: loss = 0.0539 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8854: loss = 0.0566 (0.158 sec/step)\n",
            "I0601 12:19:40.493461 140438660523904 learning.py:507] global step 8854: loss = 0.0566 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8855: loss = 0.3626 (0.158 sec/step)\n",
            "I0601 12:19:40.652998 140438660523904 learning.py:507] global step 8855: loss = 0.3626 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8856: loss = 0.1685 (0.171 sec/step)\n",
            "I0601 12:19:40.824852 140438660523904 learning.py:507] global step 8856: loss = 0.1685 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8857: loss = 0.1683 (0.177 sec/step)\n",
            "I0601 12:19:41.003524 140438660523904 learning.py:507] global step 8857: loss = 0.1683 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8858: loss = 0.1060 (0.173 sec/step)\n",
            "I0601 12:19:41.178001 140438660523904 learning.py:507] global step 8858: loss = 0.1060 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8859: loss = 0.1151 (0.178 sec/step)\n",
            "I0601 12:19:41.357760 140438660523904 learning.py:507] global step 8859: loss = 0.1151 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8860: loss = 0.1770 (0.182 sec/step)\n",
            "I0601 12:19:41.540987 140438660523904 learning.py:507] global step 8860: loss = 0.1770 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8861: loss = 0.0580 (0.163 sec/step)\n",
            "I0601 12:19:41.705339 140438660523904 learning.py:507] global step 8861: loss = 0.0580 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8862: loss = 0.1048 (0.179 sec/step)\n",
            "I0601 12:19:41.885883 140438660523904 learning.py:507] global step 8862: loss = 0.1048 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8863: loss = 0.0289 (0.168 sec/step)\n",
            "I0601 12:19:42.055739 140438660523904 learning.py:507] global step 8863: loss = 0.0289 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8864: loss = 0.0546 (0.160 sec/step)\n",
            "I0601 12:19:42.217327 140438660523904 learning.py:507] global step 8864: loss = 0.0546 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8865: loss = 0.1338 (0.160 sec/step)\n",
            "I0601 12:19:42.378528 140438660523904 learning.py:507] global step 8865: loss = 0.1338 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8866: loss = 0.0917 (0.198 sec/step)\n",
            "I0601 12:19:42.578057 140438660523904 learning.py:507] global step 8866: loss = 0.0917 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 8867: loss = 0.0561 (0.171 sec/step)\n",
            "I0601 12:19:42.750731 140438660523904 learning.py:507] global step 8867: loss = 0.0561 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8868: loss = 0.1513 (0.176 sec/step)\n",
            "I0601 12:19:42.928541 140438660523904 learning.py:507] global step 8868: loss = 0.1513 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8869: loss = 0.1355 (0.195 sec/step)\n",
            "I0601 12:19:43.124703 140438660523904 learning.py:507] global step 8869: loss = 0.1355 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8870: loss = 0.0296 (0.170 sec/step)\n",
            "I0601 12:19:43.295876 140438660523904 learning.py:507] global step 8870: loss = 0.0296 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8871: loss = 0.1080 (0.155 sec/step)\n",
            "I0601 12:19:43.452072 140438660523904 learning.py:507] global step 8871: loss = 0.1080 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8872: loss = 0.0904 (0.188 sec/step)\n",
            "I0601 12:19:43.641318 140438660523904 learning.py:507] global step 8872: loss = 0.0904 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8873: loss = 0.0499 (0.171 sec/step)\n",
            "I0601 12:19:43.813254 140438660523904 learning.py:507] global step 8873: loss = 0.0499 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8874: loss = 0.1026 (0.216 sec/step)\n",
            "I0601 12:19:44.031011 140438660523904 learning.py:507] global step 8874: loss = 0.1026 (0.216 sec/step)\n",
            "INFO:tensorflow:global step 8875: loss = 0.1824 (0.193 sec/step)\n",
            "I0601 12:19:44.225146 140438660523904 learning.py:507] global step 8875: loss = 0.1824 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 8876: loss = 0.0429 (0.158 sec/step)\n",
            "I0601 12:19:44.384936 140438660523904 learning.py:507] global step 8876: loss = 0.0429 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8877: loss = 0.0506 (0.178 sec/step)\n",
            "I0601 12:19:44.564608 140438660523904 learning.py:507] global step 8877: loss = 0.0506 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8878: loss = 0.0976 (0.195 sec/step)\n",
            "I0601 12:19:44.760677 140438660523904 learning.py:507] global step 8878: loss = 0.0976 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8879: loss = 0.0959 (0.184 sec/step)\n",
            "I0601 12:19:44.946464 140438660523904 learning.py:507] global step 8879: loss = 0.0959 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8880: loss = 0.1432 (0.182 sec/step)\n",
            "I0601 12:19:45.130385 140438660523904 learning.py:507] global step 8880: loss = 0.1432 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8881: loss = 0.2262 (0.205 sec/step)\n",
            "I0601 12:19:45.336643 140438660523904 learning.py:507] global step 8881: loss = 0.2262 (0.205 sec/step)\n",
            "INFO:tensorflow:global step 8882: loss = 0.2051 (0.176 sec/step)\n",
            "I0601 12:19:45.513916 140438660523904 learning.py:507] global step 8882: loss = 0.2051 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8883: loss = 0.0471 (0.172 sec/step)\n",
            "I0601 12:19:45.687498 140438660523904 learning.py:507] global step 8883: loss = 0.0471 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8884: loss = 0.2219 (0.175 sec/step)\n",
            "I0601 12:19:45.863760 140438660523904 learning.py:507] global step 8884: loss = 0.2219 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8885: loss = 0.0402 (0.173 sec/step)\n",
            "I0601 12:19:46.038438 140438660523904 learning.py:507] global step 8885: loss = 0.0402 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8886: loss = 0.0568 (0.183 sec/step)\n",
            "I0601 12:19:46.222811 140438660523904 learning.py:507] global step 8886: loss = 0.0568 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8887: loss = 0.0687 (0.199 sec/step)\n",
            "I0601 12:19:46.422837 140438660523904 learning.py:507] global step 8887: loss = 0.0687 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 8888: loss = 0.0700 (0.202 sec/step)\n",
            "I0601 12:19:46.626285 140438660523904 learning.py:507] global step 8888: loss = 0.0700 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 8889: loss = 0.0910 (0.178 sec/step)\n",
            "I0601 12:19:46.805668 140438660523904 learning.py:507] global step 8889: loss = 0.0910 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8890: loss = 0.2576 (0.161 sec/step)\n",
            "I0601 12:19:46.968229 140438660523904 learning.py:507] global step 8890: loss = 0.2576 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8891: loss = 0.0521 (0.166 sec/step)\n",
            "I0601 12:19:47.135940 140438660523904 learning.py:507] global step 8891: loss = 0.0521 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8892: loss = 0.0858 (0.176 sec/step)\n",
            "I0601 12:19:47.313386 140438660523904 learning.py:507] global step 8892: loss = 0.0858 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8893: loss = 0.0268 (0.187 sec/step)\n",
            "I0601 12:19:47.501855 140438660523904 learning.py:507] global step 8893: loss = 0.0268 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 8894: loss = 0.0228 (0.179 sec/step)\n",
            "I0601 12:19:47.681890 140438660523904 learning.py:507] global step 8894: loss = 0.0228 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8895: loss = 0.2777 (0.163 sec/step)\n",
            "I0601 12:19:47.845795 140438660523904 learning.py:507] global step 8895: loss = 0.2777 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8896: loss = 0.2334 (0.183 sec/step)\n",
            "I0601 12:19:48.030386 140438660523904 learning.py:507] global step 8896: loss = 0.2334 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8897: loss = 0.2617 (0.218 sec/step)\n",
            "I0601 12:19:48.249572 140438660523904 learning.py:507] global step 8897: loss = 0.2617 (0.218 sec/step)\n",
            "INFO:tensorflow:global step 8898: loss = 0.2005 (0.194 sec/step)\n",
            "I0601 12:19:48.445320 140438660523904 learning.py:507] global step 8898: loss = 0.2005 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8899: loss = 0.1173 (0.189 sec/step)\n",
            "I0601 12:19:48.635405 140438660523904 learning.py:507] global step 8899: loss = 0.1173 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8900: loss = 0.0516 (0.164 sec/step)\n",
            "I0601 12:19:48.801044 140438660523904 learning.py:507] global step 8900: loss = 0.0516 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8901: loss = 0.0833 (0.197 sec/step)\n",
            "I0601 12:19:48.999293 140438660523904 learning.py:507] global step 8901: loss = 0.0833 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 8902: loss = 0.2068 (0.174 sec/step)\n",
            "I0601 12:19:49.174712 140438660523904 learning.py:507] global step 8902: loss = 0.2068 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8903: loss = 0.1209 (0.178 sec/step)\n",
            "I0601 12:19:49.354500 140438660523904 learning.py:507] global step 8903: loss = 0.1209 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 8904: loss = 0.0918 (0.177 sec/step)\n",
            "I0601 12:19:49.532660 140438660523904 learning.py:507] global step 8904: loss = 0.0918 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8905: loss = 0.1914 (0.170 sec/step)\n",
            "I0601 12:19:49.703759 140438660523904 learning.py:507] global step 8905: loss = 0.1914 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8906: loss = 0.0746 (0.173 sec/step)\n",
            "I0601 12:19:49.878648 140438660523904 learning.py:507] global step 8906: loss = 0.0746 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8907: loss = 0.1705 (0.201 sec/step)\n",
            "I0601 12:19:50.081490 140438660523904 learning.py:507] global step 8907: loss = 0.1705 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 8908: loss = 0.0530 (0.175 sec/step)\n",
            "I0601 12:19:50.257955 140438660523904 learning.py:507] global step 8908: loss = 0.0530 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8909: loss = 0.0820 (0.158 sec/step)\n",
            "I0601 12:19:50.417677 140438660523904 learning.py:507] global step 8909: loss = 0.0820 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8910: loss = 0.0567 (0.164 sec/step)\n",
            "I0601 12:19:50.583009 140438660523904 learning.py:507] global step 8910: loss = 0.0567 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8911: loss = 0.1024 (0.177 sec/step)\n",
            "I0601 12:19:50.760889 140438660523904 learning.py:507] global step 8911: loss = 0.1024 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8912: loss = 0.0255 (0.170 sec/step)\n",
            "I0601 12:19:50.932605 140438660523904 learning.py:507] global step 8912: loss = 0.0255 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8913: loss = 0.1159 (0.173 sec/step)\n",
            "I0601 12:19:51.106609 140438660523904 learning.py:507] global step 8913: loss = 0.1159 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8914: loss = 0.1348 (0.167 sec/step)\n",
            "I0601 12:19:51.275934 140438660523904 learning.py:507] global step 8914: loss = 0.1348 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8915: loss = 0.2347 (0.196 sec/step)\n",
            "I0601 12:19:51.472996 140438660523904 learning.py:507] global step 8915: loss = 0.2347 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 8916: loss = 0.1695 (0.177 sec/step)\n",
            "I0601 12:19:51.651283 140438660523904 learning.py:507] global step 8916: loss = 0.1695 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8917: loss = 0.1365 (0.180 sec/step)\n",
            "I0601 12:19:51.832627 140438660523904 learning.py:507] global step 8917: loss = 0.1365 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8918: loss = 0.1789 (0.163 sec/step)\n",
            "I0601 12:19:51.997185 140438660523904 learning.py:507] global step 8918: loss = 0.1789 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8919: loss = 0.0376 (0.170 sec/step)\n",
            "I0601 12:19:52.168868 140438660523904 learning.py:507] global step 8919: loss = 0.0376 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8920: loss = 0.1397 (0.184 sec/step)\n",
            "I0601 12:19:52.354965 140438660523904 learning.py:507] global step 8920: loss = 0.1397 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8921: loss = 0.3428 (0.182 sec/step)\n",
            "I0601 12:19:52.538602 140438660523904 learning.py:507] global step 8921: loss = 0.3428 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 8922: loss = 0.3979 (0.171 sec/step)\n",
            "I0601 12:19:52.711227 140438660523904 learning.py:507] global step 8922: loss = 0.3979 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8923: loss = 0.3256 (0.164 sec/step)\n",
            "I0601 12:19:52.876168 140438660523904 learning.py:507] global step 8923: loss = 0.3256 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8924: loss = 0.0484 (0.186 sec/step)\n",
            "I0601 12:19:53.063498 140438660523904 learning.py:507] global step 8924: loss = 0.0484 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 8925: loss = 0.0944 (0.162 sec/step)\n",
            "I0601 12:19:53.227225 140438660523904 learning.py:507] global step 8925: loss = 0.0944 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8926: loss = 0.2169 (0.183 sec/step)\n",
            "I0601 12:19:53.411386 140438660523904 learning.py:507] global step 8926: loss = 0.2169 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8927: loss = 0.2190 (0.177 sec/step)\n",
            "I0601 12:19:53.590309 140438660523904 learning.py:507] global step 8927: loss = 0.2190 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8928: loss = 0.0790 (0.168 sec/step)\n",
            "I0601 12:19:53.759703 140438660523904 learning.py:507] global step 8928: loss = 0.0790 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8929: loss = 0.0574 (0.177 sec/step)\n",
            "I0601 12:19:53.938640 140438660523904 learning.py:507] global step 8929: loss = 0.0574 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8930: loss = 0.1060 (0.181 sec/step)\n",
            "I0601 12:19:54.121399 140438660523904 learning.py:507] global step 8930: loss = 0.1060 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8931: loss = 0.0658 (0.177 sec/step)\n",
            "I0601 12:19:54.299624 140438660523904 learning.py:507] global step 8931: loss = 0.0658 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8932: loss = 0.1761 (0.212 sec/step)\n",
            "I0601 12:19:54.515079 140438660523904 learning.py:507] global step 8932: loss = 0.1761 (0.212 sec/step)\n",
            "INFO:tensorflow:global step 8933: loss = 0.0636 (0.171 sec/step)\n",
            "I0601 12:19:54.687368 140438660523904 learning.py:507] global step 8933: loss = 0.0636 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8934: loss = 0.1318 (0.173 sec/step)\n",
            "I0601 12:19:54.861557 140438660523904 learning.py:507] global step 8934: loss = 0.1318 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 8935: loss = 0.0389 (0.161 sec/step)\n",
            "I0601 12:19:55.023631 140438660523904 learning.py:507] global step 8935: loss = 0.0389 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8936: loss = 0.0822 (0.155 sec/step)\n",
            "I0601 12:19:55.180353 140438660523904 learning.py:507] global step 8936: loss = 0.0822 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8937: loss = 0.1169 (0.195 sec/step)\n",
            "I0601 12:19:55.377128 140438660523904 learning.py:507] global step 8937: loss = 0.1169 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8938: loss = 4.4204 (0.158 sec/step)\n",
            "I0601 12:19:55.536269 140438660523904 learning.py:507] global step 8938: loss = 4.4204 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8939: loss = 0.1298 (0.171 sec/step)\n",
            "I0601 12:19:55.708628 140438660523904 learning.py:507] global step 8939: loss = 0.1298 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8940: loss = 0.1811 (0.162 sec/step)\n",
            "I0601 12:19:55.871540 140438660523904 learning.py:507] global step 8940: loss = 0.1811 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8941: loss = 0.0930 (0.177 sec/step)\n",
            "I0601 12:19:56.050102 140438660523904 learning.py:507] global step 8941: loss = 0.0930 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 8942: loss = 0.1094 (0.155 sec/step)\n",
            "I0601 12:19:56.206398 140438660523904 learning.py:507] global step 8942: loss = 0.1094 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8943: loss = 0.0992 (0.207 sec/step)\n",
            "I0601 12:19:56.414890 140438660523904 learning.py:507] global step 8943: loss = 0.0992 (0.207 sec/step)\n",
            "INFO:tensorflow:global step 8944: loss = 0.1242 (0.175 sec/step)\n",
            "I0601 12:19:56.591286 140438660523904 learning.py:507] global step 8944: loss = 0.1242 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8945: loss = 0.0978 (0.167 sec/step)\n",
            "I0601 12:19:56.759802 140438660523904 learning.py:507] global step 8945: loss = 0.0978 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8946: loss = 0.0531 (0.172 sec/step)\n",
            "I0601 12:19:56.932686 140438660523904 learning.py:507] global step 8946: loss = 0.0531 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8947: loss = 0.1074 (0.156 sec/step)\n",
            "I0601 12:19:57.089797 140438660523904 learning.py:507] global step 8947: loss = 0.1074 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8948: loss = 0.1978 (0.155 sec/step)\n",
            "I0601 12:19:57.245630 140438660523904 learning.py:507] global step 8948: loss = 0.1978 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8949: loss = 0.0926 (0.185 sec/step)\n",
            "I0601 12:19:57.431816 140438660523904 learning.py:507] global step 8949: loss = 0.0926 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 8950: loss = 0.3192 (0.172 sec/step)\n",
            "I0601 12:19:57.604859 140438660523904 learning.py:507] global step 8950: loss = 0.3192 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8951: loss = 0.0807 (0.179 sec/step)\n",
            "I0601 12:19:57.785345 140438660523904 learning.py:507] global step 8951: loss = 0.0807 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 8952: loss = 0.2702 (0.156 sec/step)\n",
            "I0601 12:19:57.942320 140438660523904 learning.py:507] global step 8952: loss = 0.2702 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 8953: loss = 0.0851 (0.224 sec/step)\n",
            "I0601 12:19:58.168160 140438660523904 learning.py:507] global step 8953: loss = 0.0851 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8954: loss = 0.1130 (0.172 sec/step)\n",
            "I0601 12:19:58.341629 140438660523904 learning.py:507] global step 8954: loss = 0.1130 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8955: loss = 0.1890 (0.170 sec/step)\n",
            "I0601 12:19:58.513309 140438660523904 learning.py:507] global step 8955: loss = 0.1890 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8956: loss = 0.0495 (0.155 sec/step)\n",
            "I0601 12:19:58.669717 140438660523904 learning.py:507] global step 8956: loss = 0.0495 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 8957: loss = 0.0378 (0.166 sec/step)\n",
            "I0601 12:19:58.837531 140438660523904 learning.py:507] global step 8957: loss = 0.0378 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8958: loss = 0.0288 (0.160 sec/step)\n",
            "I0601 12:19:58.999251 140438660523904 learning.py:507] global step 8958: loss = 0.0288 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 8959: loss = 0.5856 (0.184 sec/step)\n",
            "I0601 12:19:59.184653 140438660523904 learning.py:507] global step 8959: loss = 0.5856 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 8960: loss = 0.0279 (0.168 sec/step)\n",
            "I0601 12:19:59.354069 140438660523904 learning.py:507] global step 8960: loss = 0.0279 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8961: loss = 0.3183 (0.181 sec/step)\n",
            "I0601 12:19:59.536857 140438660523904 learning.py:507] global step 8961: loss = 0.3183 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8962: loss = 0.1019 (0.167 sec/step)\n",
            "I0601 12:19:59.705201 140438660523904 learning.py:507] global step 8962: loss = 0.1019 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8963: loss = 0.0228 (0.181 sec/step)\n",
            "I0601 12:19:59.887697 140438660523904 learning.py:507] global step 8963: loss = 0.0228 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 8964: loss = 0.2187 (0.162 sec/step)\n",
            "I0601 12:20:00.050874 140438660523904 learning.py:507] global step 8964: loss = 0.2187 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 8965: loss = 4.4761 (0.175 sec/step)\n",
            "I0601 12:20:00.227612 140438660523904 learning.py:507] global step 8965: loss = 4.4761 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8966: loss = 0.2350 (0.164 sec/step)\n",
            "I0601 12:20:00.393580 140438660523904 learning.py:507] global step 8966: loss = 0.2350 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8967: loss = 0.1252 (0.172 sec/step)\n",
            "I0601 12:20:00.566795 140438660523904 learning.py:507] global step 8967: loss = 0.1252 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8968: loss = 0.0740 (0.165 sec/step)\n",
            "I0601 12:20:00.732724 140438660523904 learning.py:507] global step 8968: loss = 0.0740 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 8969: loss = 0.1600 (0.166 sec/step)\n",
            "I0601 12:20:00.899843 140438660523904 learning.py:507] global step 8969: loss = 0.1600 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8970: loss = 0.0760 (0.161 sec/step)\n",
            "I0601 12:20:01.062661 140438660523904 learning.py:507] global step 8970: loss = 0.0760 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 8971: loss = 0.1589 (0.189 sec/step)\n",
            "I0601 12:20:01.253576 140438660523904 learning.py:507] global step 8971: loss = 0.1589 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 8972: loss = 0.0807 (0.195 sec/step)\n",
            "I0601 12:20:01.449938 140438660523904 learning.py:507] global step 8972: loss = 0.0807 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 8973: loss = 0.1032 (0.171 sec/step)\n",
            "I0601 12:20:01.622573 140438660523904 learning.py:507] global step 8973: loss = 0.1032 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 8974: loss = 0.0729 (0.159 sec/step)\n",
            "I0601 12:20:01.782965 140438660523904 learning.py:507] global step 8974: loss = 0.0729 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8975: loss = 0.2619 (0.183 sec/step)\n",
            "I0601 12:20:01.967022 140438660523904 learning.py:507] global step 8975: loss = 0.2619 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 8976: loss = 0.1158 (0.174 sec/step)\n",
            "I0601 12:20:02.142529 140438660523904 learning.py:507] global step 8976: loss = 0.1158 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8977: loss = 0.1445 (0.175 sec/step)\n",
            "I0601 12:20:02.319075 140438660523904 learning.py:507] global step 8977: loss = 0.1445 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 8978: loss = 0.0498 (0.163 sec/step)\n",
            "I0601 12:20:02.483200 140438660523904 learning.py:507] global step 8978: loss = 0.0498 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8979: loss = 0.0892 (0.192 sec/step)\n",
            "I0601 12:20:02.676658 140438660523904 learning.py:507] global step 8979: loss = 0.0892 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8980: loss = 0.1428 (0.168 sec/step)\n",
            "I0601 12:20:02.846143 140438660523904 learning.py:507] global step 8980: loss = 0.1428 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8981: loss = 0.0327 (0.180 sec/step)\n",
            "I0601 12:20:03.027035 140438660523904 learning.py:507] global step 8981: loss = 0.0327 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 8982: loss = 0.2340 (0.167 sec/step)\n",
            "I0601 12:20:03.195808 140438660523904 learning.py:507] global step 8982: loss = 0.2340 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 8983: loss = 0.1317 (0.150 sec/step)\n",
            "I0601 12:20:03.347518 140438660523904 learning.py:507] global step 8983: loss = 0.1317 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 8984: loss = 0.1160 (0.188 sec/step)\n",
            "I0601 12:20:03.537093 140438660523904 learning.py:507] global step 8984: loss = 0.1160 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8985: loss = 0.0327 (0.163 sec/step)\n",
            "I0601 12:20:03.701891 140438660523904 learning.py:507] global step 8985: loss = 0.0327 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 8986: loss = 0.2338 (0.170 sec/step)\n",
            "I0601 12:20:03.873538 140438660523904 learning.py:507] global step 8986: loss = 0.2338 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 8987: loss = 0.0493 (0.174 sec/step)\n",
            "I0601 12:20:04.049293 140438660523904 learning.py:507] global step 8987: loss = 0.0493 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 8988: loss = 0.0959 (0.176 sec/step)\n",
            "I0601 12:20:04.226761 140438660523904 learning.py:507] global step 8988: loss = 0.0959 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 8989: loss = 0.0677 (0.164 sec/step)\n",
            "I0601 12:20:04.392846 140438660523904 learning.py:507] global step 8989: loss = 0.0677 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 8990: loss = 0.1085 (0.188 sec/step)\n",
            "I0601 12:20:04.582028 140438660523904 learning.py:507] global step 8990: loss = 0.1085 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 8991: loss = 0.1670 (0.172 sec/step)\n",
            "I0601 12:20:04.755040 140438660523904 learning.py:507] global step 8991: loss = 0.1670 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8992: loss = 0.4180 (0.192 sec/step)\n",
            "I0601 12:20:04.949102 140438660523904 learning.py:507] global step 8992: loss = 0.4180 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 8993: loss = 0.0643 (0.168 sec/step)\n",
            "I0601 12:20:05.118301 140438660523904 learning.py:507] global step 8993: loss = 0.0643 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 8994: loss = 0.1286 (0.159 sec/step)\n",
            "I0601 12:20:05.278454 140438660523904 learning.py:507] global step 8994: loss = 0.1286 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 8995: loss = 0.0865 (0.194 sec/step)\n",
            "I0601 12:20:05.473884 140438660523904 learning.py:507] global step 8995: loss = 0.0865 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 8996: loss = 0.0286 (0.172 sec/step)\n",
            "I0601 12:20:05.647296 140438660523904 learning.py:507] global step 8996: loss = 0.0286 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 8997: loss = 0.2068 (0.166 sec/step)\n",
            "I0601 12:20:05.814563 140438660523904 learning.py:507] global step 8997: loss = 0.2068 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 8998: loss = 0.0766 (0.158 sec/step)\n",
            "I0601 12:20:05.973956 140438660523904 learning.py:507] global step 8998: loss = 0.0766 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 8999: loss = 0.1107 (0.170 sec/step)\n",
            "I0601 12:20:06.145072 140438660523904 learning.py:507] global step 8999: loss = 0.1107 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9000: loss = 0.1691 (0.160 sec/step)\n",
            "I0601 12:20:06.306452 140438660523904 learning.py:507] global step 9000: loss = 0.1691 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9001: loss = 0.2333 (0.176 sec/step)\n",
            "I0601 12:20:06.483836 140438660523904 learning.py:507] global step 9001: loss = 0.2333 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9002: loss = 0.1037 (0.155 sec/step)\n",
            "I0601 12:20:06.639966 140438660523904 learning.py:507] global step 9002: loss = 0.1037 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9003: loss = 0.2140 (0.161 sec/step)\n",
            "I0601 12:20:06.803223 140438660523904 learning.py:507] global step 9003: loss = 0.2140 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9004: loss = 0.0656 (0.156 sec/step)\n",
            "I0601 12:20:06.960695 140438660523904 learning.py:507] global step 9004: loss = 0.0656 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9005: loss = 0.1749 (0.167 sec/step)\n",
            "I0601 12:20:07.129089 140438660523904 learning.py:507] global step 9005: loss = 0.1749 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9006: loss = 0.1100 (0.158 sec/step)\n",
            "I0601 12:20:07.288180 140438660523904 learning.py:507] global step 9006: loss = 0.1100 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9007: loss = 0.0219 (0.188 sec/step)\n",
            "I0601 12:20:07.478293 140438660523904 learning.py:507] global step 9007: loss = 0.0219 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9008: loss = 0.1002 (0.177 sec/step)\n",
            "I0601 12:20:07.657109 140438660523904 learning.py:507] global step 9008: loss = 0.1002 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9009: loss = 0.0750 (0.166 sec/step)\n",
            "I0601 12:20:07.824231 140438660523904 learning.py:507] global step 9009: loss = 0.0750 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9010: loss = 0.1238 (0.178 sec/step)\n",
            "I0601 12:20:08.003474 140438660523904 learning.py:507] global step 9010: loss = 0.1238 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9011: loss = 0.0768 (0.163 sec/step)\n",
            "I0601 12:20:08.167634 140438660523904 learning.py:507] global step 9011: loss = 0.0768 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9012: loss = 0.1709 (0.187 sec/step)\n",
            "I0601 12:20:08.356249 140438660523904 learning.py:507] global step 9012: loss = 0.1709 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9013: loss = 0.0291 (0.189 sec/step)\n",
            "I0601 12:20:08.546426 140438660523904 learning.py:507] global step 9013: loss = 0.0291 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9014: loss = 0.0212 (0.179 sec/step)\n",
            "I0601 12:20:08.726463 140438660523904 learning.py:507] global step 9014: loss = 0.0212 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9015: loss = 0.0575 (0.162 sec/step)\n",
            "I0601 12:20:08.889432 140438660523904 learning.py:507] global step 9015: loss = 0.0575 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9016: loss = 0.4074 (0.185 sec/step)\n",
            "I0601 12:20:09.075414 140438660523904 learning.py:507] global step 9016: loss = 0.4074 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9017: loss = 0.0996 (0.163 sec/step)\n",
            "I0601 12:20:09.240332 140438660523904 learning.py:507] global step 9017: loss = 0.0996 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9018: loss = 0.1387 (0.152 sec/step)\n",
            "I0601 12:20:09.393602 140438660523904 learning.py:507] global step 9018: loss = 0.1387 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9019: loss = 0.0725 (0.183 sec/step)\n",
            "I0601 12:20:09.578494 140438660523904 learning.py:507] global step 9019: loss = 0.0725 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9020: loss = 0.1719 (0.166 sec/step)\n",
            "I0601 12:20:09.745889 140438660523904 learning.py:507] global step 9020: loss = 0.1719 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9021: loss = 0.0855 (0.168 sec/step)\n",
            "I0601 12:20:09.914978 140438660523904 learning.py:507] global step 9021: loss = 0.0855 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9022: loss = 0.1205 (0.169 sec/step)\n",
            "I0601 12:20:10.085511 140438660523904 learning.py:507] global step 9022: loss = 0.1205 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9023: loss = 0.2216 (0.163 sec/step)\n",
            "I0601 12:20:10.249524 140438660523904 learning.py:507] global step 9023: loss = 0.2216 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9024: loss = 0.6403 (0.168 sec/step)\n",
            "I0601 12:20:10.418730 140438660523904 learning.py:507] global step 9024: loss = 0.6403 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9025: loss = 0.1431 (0.192 sec/step)\n",
            "I0601 12:20:10.612250 140438660523904 learning.py:507] global step 9025: loss = 0.1431 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9026: loss = 0.1125 (0.182 sec/step)\n",
            "I0601 12:20:10.795661 140438660523904 learning.py:507] global step 9026: loss = 0.1125 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9027: loss = 0.0551 (0.182 sec/step)\n",
            "I0601 12:20:10.979443 140438660523904 learning.py:507] global step 9027: loss = 0.0551 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9028: loss = 0.2373 (0.181 sec/step)\n",
            "I0601 12:20:11.162425 140438660523904 learning.py:507] global step 9028: loss = 0.2373 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9029: loss = 0.0823 (0.163 sec/step)\n",
            "I0601 12:20:11.326731 140438660523904 learning.py:507] global step 9029: loss = 0.0823 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9030: loss = 0.1710 (0.163 sec/step)\n",
            "I0601 12:20:11.491360 140438660523904 learning.py:507] global step 9030: loss = 0.1710 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9031: loss = 0.1350 (0.177 sec/step)\n",
            "I0601 12:20:11.669502 140438660523904 learning.py:507] global step 9031: loss = 0.1350 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9032: loss = 0.0930 (0.212 sec/step)\n",
            "I0601 12:20:11.882962 140438660523904 learning.py:507] global step 9032: loss = 0.0930 (0.212 sec/step)\n",
            "INFO:tensorflow:global step 9033: loss = 0.0669 (0.159 sec/step)\n",
            "I0601 12:20:12.042953 140438660523904 learning.py:507] global step 9033: loss = 0.0669 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9034: loss = 0.0674 (0.168 sec/step)\n",
            "I0601 12:20:12.212245 140438660523904 learning.py:507] global step 9034: loss = 0.0674 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9035: loss = 0.0685 (0.184 sec/step)\n",
            "I0601 12:20:12.397491 140438660523904 learning.py:507] global step 9035: loss = 0.0685 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9036: loss = 0.1712 (0.179 sec/step)\n",
            "I0601 12:20:12.578516 140438660523904 learning.py:507] global step 9036: loss = 0.1712 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9037: loss = 0.1652 (0.156 sec/step)\n",
            "I0601 12:20:12.736340 140438660523904 learning.py:507] global step 9037: loss = 0.1652 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9038: loss = 0.1115 (0.186 sec/step)\n",
            "I0601 12:20:12.924438 140438660523904 learning.py:507] global step 9038: loss = 0.1115 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9039: loss = 0.2332 (0.187 sec/step)\n",
            "I0601 12:20:13.113061 140438660523904 learning.py:507] global step 9039: loss = 0.2332 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9040: loss = 0.0854 (0.184 sec/step)\n",
            "I0601 12:20:13.298837 140438660523904 learning.py:507] global step 9040: loss = 0.0854 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9041: loss = 0.0483 (0.179 sec/step)\n",
            "I0601 12:20:13.479401 140438660523904 learning.py:507] global step 9041: loss = 0.0483 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9042: loss = 0.0588 (0.153 sec/step)\n",
            "I0601 12:20:13.633707 140438660523904 learning.py:507] global step 9042: loss = 0.0588 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9043: loss = 0.0252 (0.161 sec/step)\n",
            "I0601 12:20:13.796288 140438660523904 learning.py:507] global step 9043: loss = 0.0252 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9044: loss = 0.0329 (0.184 sec/step)\n",
            "I0601 12:20:13.981653 140438660523904 learning.py:507] global step 9044: loss = 0.0329 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9045: loss = 0.0346 (0.175 sec/step)\n",
            "I0601 12:20:14.158094 140438660523904 learning.py:507] global step 9045: loss = 0.0346 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9046: loss = 0.3319 (0.160 sec/step)\n",
            "I0601 12:20:14.319998 140438660523904 learning.py:507] global step 9046: loss = 0.3319 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9047: loss = 0.1672 (0.181 sec/step)\n",
            "I0601 12:20:14.502555 140438660523904 learning.py:507] global step 9047: loss = 0.1672 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9048: loss = 0.0299 (0.178 sec/step)\n",
            "I0601 12:20:14.682001 140438660523904 learning.py:507] global step 9048: loss = 0.0299 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9049: loss = 0.0575 (0.180 sec/step)\n",
            "I0601 12:20:14.863017 140438660523904 learning.py:507] global step 9049: loss = 0.0575 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9050: loss = 0.0677 (0.168 sec/step)\n",
            "I0601 12:20:15.032069 140438660523904 learning.py:507] global step 9050: loss = 0.0677 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9051: loss = 0.1700 (0.179 sec/step)\n",
            "I0601 12:20:15.212742 140438660523904 learning.py:507] global step 9051: loss = 0.1700 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9052: loss = 0.0280 (0.171 sec/step)\n",
            "I0601 12:20:15.384955 140438660523904 learning.py:507] global step 9052: loss = 0.0280 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9053: loss = 0.1006 (0.162 sec/step)\n",
            "I0601 12:20:15.548230 140438660523904 learning.py:507] global step 9053: loss = 0.1006 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9054: loss = 0.0415 (0.193 sec/step)\n",
            "I0601 12:20:15.742628 140438660523904 learning.py:507] global step 9054: loss = 0.0415 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9055: loss = 0.0848 (0.183 sec/step)\n",
            "I0601 12:20:15.927439 140438660523904 learning.py:507] global step 9055: loss = 0.0848 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9056: loss = 0.3783 (0.167 sec/step)\n",
            "I0601 12:20:16.095466 140438660523904 learning.py:507] global step 9056: loss = 0.3783 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9057: loss = 0.0782 (0.170 sec/step)\n",
            "I0601 12:20:16.267560 140438660523904 learning.py:507] global step 9057: loss = 0.0782 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9058: loss = 0.1278 (0.172 sec/step)\n",
            "I0601 12:20:16.440832 140438660523904 learning.py:507] global step 9058: loss = 0.1278 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9059: loss = 0.1060 (0.176 sec/step)\n",
            "I0601 12:20:16.618521 140438660523904 learning.py:507] global step 9059: loss = 0.1060 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9060: loss = 0.1781 (0.163 sec/step)\n",
            "I0601 12:20:16.782695 140438660523904 learning.py:507] global step 9060: loss = 0.1781 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9061: loss = 0.0672 (0.196 sec/step)\n",
            "I0601 12:20:16.980377 140438660523904 learning.py:507] global step 9061: loss = 0.0672 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 9062: loss = 0.0768 (0.157 sec/step)\n",
            "I0601 12:20:17.139065 140438660523904 learning.py:507] global step 9062: loss = 0.0768 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9063: loss = 0.1959 (0.172 sec/step)\n",
            "I0601 12:20:17.312718 140438660523904 learning.py:507] global step 9063: loss = 0.1959 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9064: loss = 0.1124 (0.185 sec/step)\n",
            "I0601 12:20:17.499587 140438660523904 learning.py:507] global step 9064: loss = 0.1124 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9065: loss = 0.2061 (0.180 sec/step)\n",
            "I0601 12:20:17.681453 140438660523904 learning.py:507] global step 9065: loss = 0.2061 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9066: loss = 0.0531 (0.162 sec/step)\n",
            "I0601 12:20:17.844979 140438660523904 learning.py:507] global step 9066: loss = 0.0531 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9067: loss = 0.1822 (0.162 sec/step)\n",
            "I0601 12:20:18.008445 140438660523904 learning.py:507] global step 9067: loss = 0.1822 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9068: loss = 0.1870 (0.178 sec/step)\n",
            "I0601 12:20:18.187852 140438660523904 learning.py:507] global step 9068: loss = 0.1870 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9069: loss = 0.0756 (0.168 sec/step)\n",
            "I0601 12:20:18.357074 140438660523904 learning.py:507] global step 9069: loss = 0.0756 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9070: loss = 0.0957 (0.183 sec/step)\n",
            "I0601 12:20:18.541378 140438660523904 learning.py:507] global step 9070: loss = 0.0957 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9071: loss = 0.1210 (0.174 sec/step)\n",
            "I0601 12:20:18.717272 140438660523904 learning.py:507] global step 9071: loss = 0.1210 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9072: loss = 0.1176 (0.165 sec/step)\n",
            "I0601 12:20:18.884174 140438660523904 learning.py:507] global step 9072: loss = 0.1176 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9073: loss = 0.2563 (0.187 sec/step)\n",
            "I0601 12:20:19.072732 140438660523904 learning.py:507] global step 9073: loss = 0.2563 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9074: loss = 0.4644 (0.183 sec/step)\n",
            "I0601 12:20:19.256965 140438660523904 learning.py:507] global step 9074: loss = 0.4644 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9075: loss = 0.2783 (0.168 sec/step)\n",
            "I0601 12:20:19.426041 140438660523904 learning.py:507] global step 9075: loss = 0.2783 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9076: loss = 0.1230 (0.174 sec/step)\n",
            "I0601 12:20:19.601726 140438660523904 learning.py:507] global step 9076: loss = 0.1230 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9077: loss = 0.1634 (0.173 sec/step)\n",
            "I0601 12:20:19.776251 140438660523904 learning.py:507] global step 9077: loss = 0.1634 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9078: loss = 0.1286 (0.169 sec/step)\n",
            "I0601 12:20:19.946636 140438660523904 learning.py:507] global step 9078: loss = 0.1286 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9079: loss = 4.4165 (0.172 sec/step)\n",
            "I0601 12:20:20.120108 140438660523904 learning.py:507] global step 9079: loss = 4.4165 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9080: loss = 0.0851 (0.185 sec/step)\n",
            "I0601 12:20:20.306434 140438660523904 learning.py:507] global step 9080: loss = 0.0851 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9081: loss = 0.0907 (0.169 sec/step)\n",
            "I0601 12:20:20.477152 140438660523904 learning.py:507] global step 9081: loss = 0.0907 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9082: loss = 0.1164 (0.172 sec/step)\n",
            "I0601 12:20:20.651389 140438660523904 learning.py:507] global step 9082: loss = 0.1164 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9083: loss = 0.1383 (0.166 sec/step)\n",
            "I0601 12:20:20.818998 140438660523904 learning.py:507] global step 9083: loss = 0.1383 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9084: loss = 0.0477 (0.175 sec/step)\n",
            "I0601 12:20:20.995105 140438660523904 learning.py:507] global step 9084: loss = 0.0477 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9085: loss = 0.2848 (0.175 sec/step)\n",
            "I0601 12:20:21.171605 140438660523904 learning.py:507] global step 9085: loss = 0.2848 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9086: loss = 0.3354 (0.185 sec/step)\n",
            "I0601 12:20:21.358241 140438660523904 learning.py:507] global step 9086: loss = 0.3354 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9087: loss = 0.0475 (0.159 sec/step)\n",
            "I0601 12:20:21.518936 140438660523904 learning.py:507] global step 9087: loss = 0.0475 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9088: loss = 0.2958 (0.170 sec/step)\n",
            "I0601 12:20:21.690616 140438660523904 learning.py:507] global step 9088: loss = 0.2958 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9089: loss = 0.0992 (0.170 sec/step)\n",
            "I0601 12:20:21.861521 140438660523904 learning.py:507] global step 9089: loss = 0.0992 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9090: loss = 0.0613 (0.166 sec/step)\n",
            "I0601 12:20:22.028892 140438660523904 learning.py:507] global step 9090: loss = 0.0613 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9091: loss = 0.2170 (0.191 sec/step)\n",
            "I0601 12:20:22.220886 140438660523904 learning.py:507] global step 9091: loss = 0.2170 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 9092: loss = 0.1382 (0.182 sec/step)\n",
            "I0601 12:20:22.404011 140438660523904 learning.py:507] global step 9092: loss = 0.1382 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9093: loss = 0.1238 (0.177 sec/step)\n",
            "I0601 12:20:22.582302 140438660523904 learning.py:507] global step 9093: loss = 0.1238 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9094: loss = 0.0369 (0.159 sec/step)\n",
            "I0601 12:20:22.743183 140438660523904 learning.py:507] global step 9094: loss = 0.0369 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9095: loss = 0.0971 (0.159 sec/step)\n",
            "I0601 12:20:22.903667 140438660523904 learning.py:507] global step 9095: loss = 0.0971 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9096: loss = 0.0700 (0.176 sec/step)\n",
            "I0601 12:20:23.081424 140438660523904 learning.py:507] global step 9096: loss = 0.0700 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9097: loss = 0.0647 (0.141 sec/step)\n",
            "I0601 12:20:23.223973 140438660523904 learning.py:507] global step 9097: loss = 0.0647 (0.141 sec/step)\n",
            "INFO:tensorflow:global step 9098: loss = 0.1287 (0.176 sec/step)\n",
            "I0601 12:20:23.401413 140438660523904 learning.py:507] global step 9098: loss = 0.1287 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9099: loss = 0.0409 (0.174 sec/step)\n",
            "I0601 12:20:23.577354 140438660523904 learning.py:507] global step 9099: loss = 0.0409 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9100: loss = 0.1182 (0.177 sec/step)\n",
            "I0601 12:20:23.755530 140438660523904 learning.py:507] global step 9100: loss = 0.1182 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9101: loss = 0.1274 (0.197 sec/step)\n",
            "I0601 12:20:23.954060 140438660523904 learning.py:507] global step 9101: loss = 0.1274 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 9102: loss = 0.0939 (0.172 sec/step)\n",
            "I0601 12:20:24.127797 140438660523904 learning.py:507] global step 9102: loss = 0.0939 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9103: loss = 0.0486 (0.171 sec/step)\n",
            "I0601 12:20:24.300414 140438660523904 learning.py:507] global step 9103: loss = 0.0486 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9104: loss = 0.3208 (0.183 sec/step)\n",
            "I0601 12:20:24.485146 140438660523904 learning.py:507] global step 9104: loss = 0.3208 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9105: loss = 0.0357 (0.181 sec/step)\n",
            "I0601 12:20:24.667943 140438660523904 learning.py:507] global step 9105: loss = 0.0357 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9106: loss = 0.0497 (0.166 sec/step)\n",
            "I0601 12:20:24.835614 140438660523904 learning.py:507] global step 9106: loss = 0.0497 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9107: loss = 0.1228 (0.200 sec/step)\n",
            "I0601 12:20:25.037455 140438660523904 learning.py:507] global step 9107: loss = 0.1228 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9108: loss = 0.0882 (0.162 sec/step)\n",
            "I0601 12:20:25.200998 140438660523904 learning.py:507] global step 9108: loss = 0.0882 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9109: loss = 0.1017 (0.171 sec/step)\n",
            "I0601 12:20:25.373462 140438660523904 learning.py:507] global step 9109: loss = 0.1017 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9110: loss = 0.0620 (0.162 sec/step)\n",
            "I0601 12:20:25.537363 140438660523904 learning.py:507] global step 9110: loss = 0.0620 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9111: loss = 0.0600 (0.194 sec/step)\n",
            "I0601 12:20:25.733327 140438660523904 learning.py:507] global step 9111: loss = 0.0600 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9112: loss = 0.1891 (0.162 sec/step)\n",
            "I0601 12:20:25.897166 140438660523904 learning.py:507] global step 9112: loss = 0.1891 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9113: loss = 0.0749 (0.166 sec/step)\n",
            "I0601 12:20:26.064827 140438660523904 learning.py:507] global step 9113: loss = 0.0749 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9114: loss = 0.2411 (0.172 sec/step)\n",
            "I0601 12:20:26.238492 140438660523904 learning.py:507] global step 9114: loss = 0.2411 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9115: loss = 0.0662 (0.174 sec/step)\n",
            "I0601 12:20:26.414296 140438660523904 learning.py:507] global step 9115: loss = 0.0662 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9116: loss = 0.0453 (0.173 sec/step)\n",
            "I0601 12:20:26.588951 140438660523904 learning.py:507] global step 9116: loss = 0.0453 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9117: loss = 0.0787 (0.212 sec/step)\n",
            "I0601 12:20:26.803526 140438660523904 learning.py:507] global step 9117: loss = 0.0787 (0.212 sec/step)\n",
            "INFO:tensorflow:global step 9118: loss = 0.0514 (0.179 sec/step)\n",
            "I0601 12:20:26.984262 140438660523904 learning.py:507] global step 9118: loss = 0.0514 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9119: loss = 0.0998 (0.179 sec/step)\n",
            "I0601 12:20:27.164597 140438660523904 learning.py:507] global step 9119: loss = 0.0998 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9120: loss = 0.0289 (0.143 sec/step)\n",
            "I0601 12:20:27.308926 140438660523904 learning.py:507] global step 9120: loss = 0.0289 (0.143 sec/step)\n",
            "INFO:tensorflow:global step 9121: loss = 0.0511 (0.178 sec/step)\n",
            "I0601 12:20:27.488566 140438660523904 learning.py:507] global step 9121: loss = 0.0511 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9122: loss = 0.0864 (0.172 sec/step)\n",
            "I0601 12:20:27.662607 140438660523904 learning.py:507] global step 9122: loss = 0.0864 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9123: loss = 0.0609 (0.169 sec/step)\n",
            "I0601 12:20:27.833261 140438660523904 learning.py:507] global step 9123: loss = 0.0609 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9124: loss = 0.0843 (0.169 sec/step)\n",
            "I0601 12:20:28.003639 140438660523904 learning.py:507] global step 9124: loss = 0.0843 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9125: loss = 0.1388 (0.184 sec/step)\n",
            "I0601 12:20:28.189729 140438660523904 learning.py:507] global step 9125: loss = 0.1388 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9126: loss = 0.3068 (0.163 sec/step)\n",
            "I0601 12:20:28.354056 140438660523904 learning.py:507] global step 9126: loss = 0.3068 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9127: loss = 0.1457 (0.180 sec/step)\n",
            "I0601 12:20:28.535192 140438660523904 learning.py:507] global step 9127: loss = 0.1457 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9128: loss = 0.1758 (0.167 sec/step)\n",
            "I0601 12:20:28.703153 140438660523904 learning.py:507] global step 9128: loss = 0.1758 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9129: loss = 0.0899 (0.175 sec/step)\n",
            "I0601 12:20:28.879989 140438660523904 learning.py:507] global step 9129: loss = 0.0899 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9130: loss = 0.1532 (0.179 sec/step)\n",
            "I0601 12:20:29.060354 140438660523904 learning.py:507] global step 9130: loss = 0.1532 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9131: loss = 0.3930 (0.189 sec/step)\n",
            "I0601 12:20:29.250823 140438660523904 learning.py:507] global step 9131: loss = 0.3930 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9132: loss = 0.1219 (0.163 sec/step)\n",
            "I0601 12:20:29.415349 140438660523904 learning.py:507] global step 9132: loss = 0.1219 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9133: loss = 0.0938 (0.178 sec/step)\n",
            "I0601 12:20:29.594815 140438660523904 learning.py:507] global step 9133: loss = 0.0938 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9134: loss = 0.1476 (0.158 sec/step)\n",
            "I0601 12:20:29.754514 140438660523904 learning.py:507] global step 9134: loss = 0.1476 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9135: loss = 0.1633 (0.182 sec/step)\n",
            "I0601 12:20:29.938028 140438660523904 learning.py:507] global step 9135: loss = 0.1633 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9136: loss = 0.1646 (0.158 sec/step)\n",
            "I0601 12:20:30.097583 140438660523904 learning.py:507] global step 9136: loss = 0.1646 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9137: loss = 0.1959 (0.176 sec/step)\n",
            "I0601 12:20:30.274881 140438660523904 learning.py:507] global step 9137: loss = 0.1959 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9138: loss = 0.0622 (0.138 sec/step)\n",
            "I0601 12:20:30.414061 140438660523904 learning.py:507] global step 9138: loss = 0.0622 (0.138 sec/step)\n",
            "INFO:tensorflow:global step 9139: loss = 0.0375 (0.193 sec/step)\n",
            "I0601 12:20:30.608671 140438660523904 learning.py:507] global step 9139: loss = 0.0375 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9140: loss = 0.2413 (0.174 sec/step)\n",
            "I0601 12:20:30.783784 140438660523904 learning.py:507] global step 9140: loss = 0.2413 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9141: loss = 0.0897 (0.168 sec/step)\n",
            "I0601 12:20:30.952690 140438660523904 learning.py:507] global step 9141: loss = 0.0897 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9142: loss = 0.1880 (0.169 sec/step)\n",
            "I0601 12:20:31.122897 140438660523904 learning.py:507] global step 9142: loss = 0.1880 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9143: loss = 4.4225 (0.175 sec/step)\n",
            "I0601 12:20:31.298984 140438660523904 learning.py:507] global step 9143: loss = 4.4225 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9144: loss = 0.0280 (0.167 sec/step)\n",
            "I0601 12:20:31.467499 140438660523904 learning.py:507] global step 9144: loss = 0.0280 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9145: loss = 0.0720 (0.206 sec/step)\n",
            "I0601 12:20:31.675258 140438660523904 learning.py:507] global step 9145: loss = 0.0720 (0.206 sec/step)\n",
            "INFO:tensorflow:global step 9146: loss = 0.0473 (0.173 sec/step)\n",
            "I0601 12:20:31.850098 140438660523904 learning.py:507] global step 9146: loss = 0.0473 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9147: loss = 0.1478 (0.166 sec/step)\n",
            "I0601 12:20:32.017969 140438660523904 learning.py:507] global step 9147: loss = 0.1478 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9148: loss = 0.0274 (0.151 sec/step)\n",
            "I0601 12:20:32.170576 140438660523904 learning.py:507] global step 9148: loss = 0.0274 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9149: loss = 0.0685 (0.162 sec/step)\n",
            "I0601 12:20:32.334327 140438660523904 learning.py:507] global step 9149: loss = 0.0685 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9150: loss = 0.1943 (0.192 sec/step)\n",
            "I0601 12:20:32.527896 140438660523904 learning.py:507] global step 9150: loss = 0.1943 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9151: loss = 0.0712 (0.173 sec/step)\n",
            "I0601 12:20:32.702244 140438660523904 learning.py:507] global step 9151: loss = 0.0712 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9152: loss = 0.5194 (0.172 sec/step)\n",
            "I0601 12:20:32.875786 140438660523904 learning.py:507] global step 9152: loss = 0.5194 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9153: loss = 0.1977 (0.176 sec/step)\n",
            "I0601 12:20:33.053672 140438660523904 learning.py:507] global step 9153: loss = 0.1977 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9154: loss = 0.0394 (0.202 sec/step)\n",
            "I0601 12:20:33.256666 140438660523904 learning.py:507] global step 9154: loss = 0.0394 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 9155: loss = 0.0436 (0.167 sec/step)\n",
            "I0601 12:20:33.424869 140438660523904 learning.py:507] global step 9155: loss = 0.0436 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9156: loss = 0.0816 (0.169 sec/step)\n",
            "I0601 12:20:33.595426 140438660523904 learning.py:507] global step 9156: loss = 0.0816 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9157: loss = 0.0513 (0.180 sec/step)\n",
            "I0601 12:20:33.776697 140438660523904 learning.py:507] global step 9157: loss = 0.0513 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9158: loss = 0.0592 (0.174 sec/step)\n",
            "I0601 12:20:33.952172 140438660523904 learning.py:507] global step 9158: loss = 0.0592 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9159: loss = 0.1314 (0.151 sec/step)\n",
            "I0601 12:20:34.104550 140438660523904 learning.py:507] global step 9159: loss = 0.1314 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9160: loss = 0.0590 (0.170 sec/step)\n",
            "I0601 12:20:34.275854 140438660523904 learning.py:507] global step 9160: loss = 0.0590 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9161: loss = 0.0608 (0.183 sec/step)\n",
            "I0601 12:20:34.460044 140438660523904 learning.py:507] global step 9161: loss = 0.0608 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9162: loss = 0.1185 (0.162 sec/step)\n",
            "I0601 12:20:34.623070 140438660523904 learning.py:507] global step 9162: loss = 0.1185 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9163: loss = 0.4807 (0.174 sec/step)\n",
            "I0601 12:20:34.798824 140438660523904 learning.py:507] global step 9163: loss = 0.4807 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9164: loss = 0.1074 (0.169 sec/step)\n",
            "I0601 12:20:34.968888 140438660523904 learning.py:507] global step 9164: loss = 0.1074 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9165: loss = 0.0457 (0.184 sec/step)\n",
            "I0601 12:20:35.154614 140438660523904 learning.py:507] global step 9165: loss = 0.0457 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9166: loss = 0.1374 (0.166 sec/step)\n",
            "I0601 12:20:35.322386 140438660523904 learning.py:507] global step 9166: loss = 0.1374 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9167: loss = 0.2700 (0.172 sec/step)\n",
            "I0601 12:20:35.496279 140438660523904 learning.py:507] global step 9167: loss = 0.2700 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9168: loss = 0.1581 (0.175 sec/step)\n",
            "I0601 12:20:35.672821 140438660523904 learning.py:507] global step 9168: loss = 0.1581 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9169: loss = 0.0695 (0.165 sec/step)\n",
            "I0601 12:20:35.838831 140438660523904 learning.py:507] global step 9169: loss = 0.0695 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9170: loss = 0.1058 (0.169 sec/step)\n",
            "I0601 12:20:36.009482 140438660523904 learning.py:507] global step 9170: loss = 0.1058 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9171: loss = 0.1030 (0.184 sec/step)\n",
            "I0601 12:20:36.195006 140438660523904 learning.py:507] global step 9171: loss = 0.1030 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9172: loss = 0.0715 (0.180 sec/step)\n",
            "I0601 12:20:36.376215 140438660523904 learning.py:507] global step 9172: loss = 0.0715 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9173: loss = 0.1015 (0.156 sec/step)\n",
            "I0601 12:20:36.533148 140438660523904 learning.py:507] global step 9173: loss = 0.1015 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9174: loss = 0.3126 (0.173 sec/step)\n",
            "I0601 12:20:36.707221 140438660523904 learning.py:507] global step 9174: loss = 0.3126 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9175: loss = 0.1376 (0.157 sec/step)\n",
            "I0601 12:20:36.865583 140438660523904 learning.py:507] global step 9175: loss = 0.1376 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9176: loss = 0.0983 (0.183 sec/step)\n",
            "I0601 12:20:37.050294 140438660523904 learning.py:507] global step 9176: loss = 0.0983 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9177: loss = 0.1512 (0.177 sec/step)\n",
            "I0601 12:20:37.228347 140438660523904 learning.py:507] global step 9177: loss = 0.1512 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9178: loss = 0.0259 (0.181 sec/step)\n",
            "I0601 12:20:37.411020 140438660523904 learning.py:507] global step 9178: loss = 0.0259 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9179: loss = 0.1566 (0.153 sec/step)\n",
            "I0601 12:20:37.565312 140438660523904 learning.py:507] global step 9179: loss = 0.1566 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9180: loss = 0.0575 (0.176 sec/step)\n",
            "I0601 12:20:37.743048 140438660523904 learning.py:507] global step 9180: loss = 0.0575 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9181: loss = 0.0575 (0.178 sec/step)\n",
            "I0601 12:20:37.922462 140438660523904 learning.py:507] global step 9181: loss = 0.0575 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9182: loss = 0.0629 (0.186 sec/step)\n",
            "I0601 12:20:38.110035 140438660523904 learning.py:507] global step 9182: loss = 0.0629 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9183: loss = 0.0691 (0.181 sec/step)\n",
            "I0601 12:20:38.291976 140438660523904 learning.py:507] global step 9183: loss = 0.0691 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9184: loss = 0.2457 (0.178 sec/step)\n",
            "I0601 12:20:38.471185 140438660523904 learning.py:507] global step 9184: loss = 0.2457 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9185: loss = 0.1277 (0.179 sec/step)\n",
            "I0601 12:20:38.651421 140438660523904 learning.py:507] global step 9185: loss = 0.1277 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9186: loss = 0.0819 (0.175 sec/step)\n",
            "I0601 12:20:38.828405 140438660523904 learning.py:507] global step 9186: loss = 0.0819 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9187: loss = 0.0304 (0.160 sec/step)\n",
            "I0601 12:20:38.990075 140438660523904 learning.py:507] global step 9187: loss = 0.0304 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9188: loss = 0.1078 (0.183 sec/step)\n",
            "I0601 12:20:39.174808 140438660523904 learning.py:507] global step 9188: loss = 0.1078 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9189: loss = 0.2114 (0.161 sec/step)\n",
            "I0601 12:20:39.337562 140438660523904 learning.py:507] global step 9189: loss = 0.2114 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9190: loss = 0.1718 (0.171 sec/step)\n",
            "I0601 12:20:39.510360 140438660523904 learning.py:507] global step 9190: loss = 0.1718 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9191: loss = 0.0799 (0.165 sec/step)\n",
            "I0601 12:20:39.676979 140438660523904 learning.py:507] global step 9191: loss = 0.0799 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9192: loss = 0.2174 (0.178 sec/step)\n",
            "I0601 12:20:39.856363 140438660523904 learning.py:507] global step 9192: loss = 0.2174 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9193: loss = 0.1311 (0.181 sec/step)\n",
            "I0601 12:20:40.039160 140438660523904 learning.py:507] global step 9193: loss = 0.1311 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9194: loss = 0.0403 (0.176 sec/step)\n",
            "I0601 12:20:40.216782 140438660523904 learning.py:507] global step 9194: loss = 0.0403 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9195: loss = 0.0290 (0.172 sec/step)\n",
            "I0601 12:20:40.390522 140438660523904 learning.py:507] global step 9195: loss = 0.0290 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9196: loss = 0.1909 (0.161 sec/step)\n",
            "I0601 12:20:40.552392 140438660523904 learning.py:507] global step 9196: loss = 0.1909 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9197: loss = 0.0452 (0.180 sec/step)\n",
            "I0601 12:20:40.733745 140438660523904 learning.py:507] global step 9197: loss = 0.0452 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9198: loss = 0.0244 (0.175 sec/step)\n",
            "I0601 12:20:40.910239 140438660523904 learning.py:507] global step 9198: loss = 0.0244 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9199: loss = 0.3382 (0.176 sec/step)\n",
            "I0601 12:20:41.087846 140438660523904 learning.py:507] global step 9199: loss = 0.3382 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9200: loss = 0.1997 (0.175 sec/step)\n",
            "I0601 12:20:41.264801 140438660523904 learning.py:507] global step 9200: loss = 0.1997 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9201: loss = 0.0694 (0.175 sec/step)\n",
            "I0601 12:20:41.440858 140438660523904 learning.py:507] global step 9201: loss = 0.0694 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9202: loss = 0.0621 (0.176 sec/step)\n",
            "I0601 12:20:41.617736 140438660523904 learning.py:507] global step 9202: loss = 0.0621 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9203: loss = 0.0937 (0.167 sec/step)\n",
            "I0601 12:20:41.786744 140438660523904 learning.py:507] global step 9203: loss = 0.0937 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9204: loss = 0.2109 (0.165 sec/step)\n",
            "I0601 12:20:41.953198 140438660523904 learning.py:507] global step 9204: loss = 0.2109 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9205: loss = 0.2532 (0.178 sec/step)\n",
            "I0601 12:20:42.132750 140438660523904 learning.py:507] global step 9205: loss = 0.2532 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9206: loss = 0.0212 (0.170 sec/step)\n",
            "I0601 12:20:42.304442 140438660523904 learning.py:507] global step 9206: loss = 0.0212 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9207: loss = 0.0293 (0.197 sec/step)\n",
            "I0601 12:20:42.502745 140438660523904 learning.py:507] global step 9207: loss = 0.0293 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 9208: loss = 0.3315 (0.170 sec/step)\n",
            "I0601 12:20:42.674449 140438660523904 learning.py:507] global step 9208: loss = 0.3315 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9209: loss = 0.0294 (0.162 sec/step)\n",
            "I0601 12:20:42.838118 140438660523904 learning.py:507] global step 9209: loss = 0.0294 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9210: loss = 0.0533 (0.146 sec/step)\n",
            "I0601 12:20:42.985071 140438660523904 learning.py:507] global step 9210: loss = 0.0533 (0.146 sec/step)\n",
            "INFO:tensorflow:global step 9211: loss = 0.1757 (0.177 sec/step)\n",
            "I0601 12:20:43.164040 140438660523904 learning.py:507] global step 9211: loss = 0.1757 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9212: loss = 0.2806 (0.185 sec/step)\n",
            "I0601 12:20:43.350621 140438660523904 learning.py:507] global step 9212: loss = 0.2806 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9213: loss = 0.0958 (0.166 sec/step)\n",
            "I0601 12:20:43.518478 140438660523904 learning.py:507] global step 9213: loss = 0.0958 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9214: loss = 0.1116 (0.159 sec/step)\n",
            "I0601 12:20:43.679488 140438660523904 learning.py:507] global step 9214: loss = 0.1116 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9215: loss = 0.1250 (0.185 sec/step)\n",
            "I0601 12:20:43.866257 140438660523904 learning.py:507] global step 9215: loss = 0.1250 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9216: loss = 0.1599 (0.197 sec/step)\n",
            "I0601 12:20:44.064512 140438660523904 learning.py:507] global step 9216: loss = 0.1599 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 9217: loss = 0.0655 (0.175 sec/step)\n",
            "I0601 12:20:44.240657 140438660523904 learning.py:507] global step 9217: loss = 0.0655 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9218: loss = 0.0397 (0.167 sec/step)\n",
            "I0601 12:20:44.409042 140438660523904 learning.py:507] global step 9218: loss = 0.0397 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9219: loss = 0.0197 (0.167 sec/step)\n",
            "I0601 12:20:44.577216 140438660523904 learning.py:507] global step 9219: loss = 0.0197 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9220: loss = 0.0598 (0.172 sec/step)\n",
            "I0601 12:20:44.750415 140438660523904 learning.py:507] global step 9220: loss = 0.0598 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9221: loss = 0.0805 (0.164 sec/step)\n",
            "I0601 12:20:44.916170 140438660523904 learning.py:507] global step 9221: loss = 0.0805 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9222: loss = 0.1466 (0.182 sec/step)\n",
            "I0601 12:20:45.099457 140438660523904 learning.py:507] global step 9222: loss = 0.1466 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9223: loss = 0.1669 (0.175 sec/step)\n",
            "I0601 12:20:45.275947 140438660523904 learning.py:507] global step 9223: loss = 0.1669 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9224: loss = 0.0516 (0.162 sec/step)\n",
            "I0601 12:20:45.439793 140438660523904 learning.py:507] global step 9224: loss = 0.0516 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9225: loss = 0.0967 (0.171 sec/step)\n",
            "I0601 12:20:45.611736 140438660523904 learning.py:507] global step 9225: loss = 0.0967 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9226: loss = 0.2151 (0.172 sec/step)\n",
            "I0601 12:20:45.784725 140438660523904 learning.py:507] global step 9226: loss = 0.2151 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9227: loss = 0.1460 (0.169 sec/step)\n",
            "I0601 12:20:45.954705 140438660523904 learning.py:507] global step 9227: loss = 0.1460 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9228: loss = 0.1909 (0.170 sec/step)\n",
            "I0601 12:20:46.126106 140438660523904 learning.py:507] global step 9228: loss = 0.1909 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9229: loss = 0.0256 (0.145 sec/step)\n",
            "I0601 12:20:46.272280 140438660523904 learning.py:507] global step 9229: loss = 0.0256 (0.145 sec/step)\n",
            "INFO:tensorflow:global step 9230: loss = 0.1154 (0.181 sec/step)\n",
            "I0601 12:20:46.454357 140438660523904 learning.py:507] global step 9230: loss = 0.1154 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9231: loss = 0.0331 (0.154 sec/step)\n",
            "I0601 12:20:46.610148 140438660523904 learning.py:507] global step 9231: loss = 0.0331 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9232: loss = 0.2776 (0.168 sec/step)\n",
            "I0601 12:20:46.779765 140438660523904 learning.py:507] global step 9232: loss = 0.2776 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9233: loss = 0.4318 (0.185 sec/step)\n",
            "I0601 12:20:46.965761 140438660523904 learning.py:507] global step 9233: loss = 0.4318 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9234: loss = 0.3112 (0.171 sec/step)\n",
            "I0601 12:20:47.137841 140438660523904 learning.py:507] global step 9234: loss = 0.3112 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9235: loss = 0.3264 (0.193 sec/step)\n",
            "I0601 12:20:47.332723 140438660523904 learning.py:507] global step 9235: loss = 0.3264 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9236: loss = 0.1584 (0.157 sec/step)\n",
            "I0601 12:20:47.490802 140438660523904 learning.py:507] global step 9236: loss = 0.1584 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9237: loss = 0.0634 (0.173 sec/step)\n",
            "I0601 12:20:47.665145 140438660523904 learning.py:507] global step 9237: loss = 0.0634 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9238: loss = 0.0847 (0.170 sec/step)\n",
            "I0601 12:20:47.836518 140438660523904 learning.py:507] global step 9238: loss = 0.0847 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9239: loss = 0.0300 (0.173 sec/step)\n",
            "I0601 12:20:48.010896 140438660523904 learning.py:507] global step 9239: loss = 0.0300 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9240: loss = 0.3900 (0.170 sec/step)\n",
            "I0601 12:20:48.181887 140438660523904 learning.py:507] global step 9240: loss = 0.3900 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9241: loss = 0.1275 (0.170 sec/step)\n",
            "I0601 12:20:48.353743 140438660523904 learning.py:507] global step 9241: loss = 0.1275 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9242: loss = 0.2126 (0.200 sec/step)\n",
            "I0601 12:20:48.555613 140438660523904 learning.py:507] global step 9242: loss = 0.2126 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9243: loss = 0.0594 (0.177 sec/step)\n",
            "I0601 12:20:48.733796 140438660523904 learning.py:507] global step 9243: loss = 0.0594 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9244: loss = 4.1072 (0.176 sec/step)\n",
            "I0601 12:20:48.910634 140438660523904 learning.py:507] global step 9244: loss = 4.1072 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9245: loss = 0.0488 (0.176 sec/step)\n",
            "I0601 12:20:49.087684 140438660523904 learning.py:507] global step 9245: loss = 0.0488 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9246: loss = 0.1181 (0.174 sec/step)\n",
            "I0601 12:20:49.263640 140438660523904 learning.py:507] global step 9246: loss = 0.1181 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9247: loss = 0.0805 (0.175 sec/step)\n",
            "I0601 12:20:49.440131 140438660523904 learning.py:507] global step 9247: loss = 0.0805 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9248: loss = 0.0173 (0.153 sec/step)\n",
            "I0601 12:20:49.594498 140438660523904 learning.py:507] global step 9248: loss = 0.0173 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9249: loss = 0.1322 (0.178 sec/step)\n",
            "I0601 12:20:49.774195 140438660523904 learning.py:507] global step 9249: loss = 0.1322 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9250: loss = 0.1452 (0.172 sec/step)\n",
            "I0601 12:20:49.947253 140438660523904 learning.py:507] global step 9250: loss = 0.1452 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9251: loss = 0.1255 (0.182 sec/step)\n",
            "I0601 12:20:50.130680 140438660523904 learning.py:507] global step 9251: loss = 0.1255 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9252: loss = 0.0810 (0.152 sec/step)\n",
            "I0601 12:20:50.284224 140438660523904 learning.py:507] global step 9252: loss = 0.0810 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9253: loss = 0.1161 (0.151 sec/step)\n",
            "I0601 12:20:50.437006 140438660523904 learning.py:507] global step 9253: loss = 0.1161 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9254: loss = 0.2056 (0.166 sec/step)\n",
            "I0601 12:20:50.604605 140438660523904 learning.py:507] global step 9254: loss = 0.2056 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9255: loss = 0.3604 (0.187 sec/step)\n",
            "I0601 12:20:50.792782 140438660523904 learning.py:507] global step 9255: loss = 0.3604 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9256: loss = 0.1308 (0.177 sec/step)\n",
            "I0601 12:20:50.970935 140438660523904 learning.py:507] global step 9256: loss = 0.1308 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9257: loss = 0.0545 (0.175 sec/step)\n",
            "I0601 12:20:51.147174 140438660523904 learning.py:507] global step 9257: loss = 0.0545 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9258: loss = 0.1378 (0.186 sec/step)\n",
            "I0601 12:20:51.334281 140438660523904 learning.py:507] global step 9258: loss = 0.1378 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9259: loss = 0.0792 (0.197 sec/step)\n",
            "I0601 12:20:51.533073 140438660523904 learning.py:507] global step 9259: loss = 0.0792 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 9260: loss = 0.2010 (0.167 sec/step)\n",
            "I0601 12:20:51.701514 140438660523904 learning.py:507] global step 9260: loss = 0.2010 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9261: loss = 0.2576 (0.184 sec/step)\n",
            "I0601 12:20:51.886795 140438660523904 learning.py:507] global step 9261: loss = 0.2576 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9262: loss = 0.0638 (0.165 sec/step)\n",
            "I0601 12:20:52.053524 140438660523904 learning.py:507] global step 9262: loss = 0.0638 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9263: loss = 0.1196 (0.179 sec/step)\n",
            "I0601 12:20:52.234609 140438660523904 learning.py:507] global step 9263: loss = 0.1196 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9264: loss = 0.1458 (0.163 sec/step)\n",
            "I0601 12:20:52.399016 140438660523904 learning.py:507] global step 9264: loss = 0.1458 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9265: loss = 0.1027 (0.183 sec/step)\n",
            "I0601 12:20:52.583833 140438660523904 learning.py:507] global step 9265: loss = 0.1027 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9266: loss = 0.1981 (0.167 sec/step)\n",
            "I0601 12:20:52.753007 140438660523904 learning.py:507] global step 9266: loss = 0.1981 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9267: loss = 0.1276 (0.167 sec/step)\n",
            "I0601 12:20:52.921514 140438660523904 learning.py:507] global step 9267: loss = 0.1276 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9268: loss = 0.0876 (0.190 sec/step)\n",
            "I0601 12:20:53.113122 140438660523904 learning.py:507] global step 9268: loss = 0.0876 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9269: loss = 4.3962 (0.178 sec/step)\n",
            "I0601 12:20:53.293433 140438660523904 learning.py:507] global step 9269: loss = 4.3962 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9270: loss = 0.0509 (0.166 sec/step)\n",
            "I0601 12:20:53.460432 140438660523904 learning.py:507] global step 9270: loss = 0.0509 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9271: loss = 0.0828 (0.182 sec/step)\n",
            "I0601 12:20:53.643357 140438660523904 learning.py:507] global step 9271: loss = 0.0828 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9272: loss = 0.2890 (0.186 sec/step)\n",
            "I0601 12:20:53.830667 140438660523904 learning.py:507] global step 9272: loss = 0.2890 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9273: loss = 0.1230 (0.171 sec/step)\n",
            "I0601 12:20:54.002735 140438660523904 learning.py:507] global step 9273: loss = 0.1230 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9274: loss = 0.1245 (0.172 sec/step)\n",
            "I0601 12:20:54.176623 140438660523904 learning.py:507] global step 9274: loss = 0.1245 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9275: loss = 0.2777 (0.154 sec/step)\n",
            "I0601 12:20:54.332057 140438660523904 learning.py:507] global step 9275: loss = 0.2777 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9276: loss = 0.1202 (0.167 sec/step)\n",
            "I0601 12:20:54.500231 140438660523904 learning.py:507] global step 9276: loss = 0.1202 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9277: loss = 0.1240 (0.172 sec/step)\n",
            "I0601 12:20:54.674438 140438660523904 learning.py:507] global step 9277: loss = 0.1240 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9278: loss = 0.0509 (0.177 sec/step)\n",
            "I0601 12:20:54.852598 140438660523904 learning.py:507] global step 9278: loss = 0.0509 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9279: loss = 0.0267 (0.156 sec/step)\n",
            "I0601 12:20:55.010178 140438660523904 learning.py:507] global step 9279: loss = 0.0267 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9280: loss = 0.1417 (0.163 sec/step)\n",
            "I0601 12:20:55.174581 140438660523904 learning.py:507] global step 9280: loss = 0.1417 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9281: loss = 0.3026 (0.170 sec/step)\n",
            "I0601 12:20:55.345661 140438660523904 learning.py:507] global step 9281: loss = 0.3026 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9282: loss = 0.1034 (0.170 sec/step)\n",
            "I0601 12:20:55.516680 140438660523904 learning.py:507] global step 9282: loss = 0.1034 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9283: loss = 0.0893 (0.162 sec/step)\n",
            "I0601 12:20:55.679543 140438660523904 learning.py:507] global step 9283: loss = 0.0893 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9284: loss = 0.1596 (0.178 sec/step)\n",
            "I0601 12:20:55.858489 140438660523904 learning.py:507] global step 9284: loss = 0.1596 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9285: loss = 0.0208 (0.172 sec/step)\n",
            "I0601 12:20:56.031880 140438660523904 learning.py:507] global step 9285: loss = 0.0208 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9286: loss = 0.1067 (0.161 sec/step)\n",
            "I0601 12:20:56.194042 140438660523904 learning.py:507] global step 9286: loss = 0.1067 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9287: loss = 0.1121 (0.185 sec/step)\n",
            "I0601 12:20:56.379962 140438660523904 learning.py:507] global step 9287: loss = 0.1121 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9288: loss = 0.0332 (0.169 sec/step)\n",
            "I0601 12:20:56.550280 140438660523904 learning.py:507] global step 9288: loss = 0.0332 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9289: loss = 0.5265 (0.183 sec/step)\n",
            "I0601 12:20:56.735036 140438660523904 learning.py:507] global step 9289: loss = 0.5265 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9290: loss = 0.0150 (0.171 sec/step)\n",
            "I0601 12:20:56.907574 140438660523904 learning.py:507] global step 9290: loss = 0.0150 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9291: loss = 0.3896 (0.181 sec/step)\n",
            "I0601 12:20:57.090421 140438660523904 learning.py:507] global step 9291: loss = 0.3896 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9292: loss = 0.1811 (0.162 sec/step)\n",
            "I0601 12:20:57.254129 140438660523904 learning.py:507] global step 9292: loss = 0.1811 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9293: loss = 0.0770 (0.176 sec/step)\n",
            "I0601 12:20:57.431328 140438660523904 learning.py:507] global step 9293: loss = 0.0770 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9294: loss = 0.0675 (0.171 sec/step)\n",
            "I0601 12:20:57.603900 140438660523904 learning.py:507] global step 9294: loss = 0.0675 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9295: loss = 0.3040 (0.145 sec/step)\n",
            "I0601 12:20:57.750633 140438660523904 learning.py:507] global step 9295: loss = 0.3040 (0.145 sec/step)\n",
            "INFO:tensorflow:global step 9296: loss = 0.2145 (0.194 sec/step)\n",
            "I0601 12:20:57.945780 140438660523904 learning.py:507] global step 9296: loss = 0.2145 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9297: loss = 0.0888 (0.164 sec/step)\n",
            "I0601 12:20:58.110687 140438660523904 learning.py:507] global step 9297: loss = 0.0888 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9298: loss = 0.0455 (0.175 sec/step)\n",
            "I0601 12:20:58.287390 140438660523904 learning.py:507] global step 9298: loss = 0.0455 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9299: loss = 0.1887 (0.167 sec/step)\n",
            "I0601 12:20:58.456012 140438660523904 learning.py:507] global step 9299: loss = 0.1887 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9300: loss = 0.1855 (0.154 sec/step)\n",
            "I0601 12:20:58.611401 140438660523904 learning.py:507] global step 9300: loss = 0.1855 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9301: loss = 0.2510 (0.167 sec/step)\n",
            "I0601 12:20:58.779846 140438660523904 learning.py:507] global step 9301: loss = 0.2510 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9302: loss = 0.1477 (0.200 sec/step)\n",
            "I0601 12:20:58.981565 140438660523904 learning.py:507] global step 9302: loss = 0.1477 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9303: loss = 0.0589 (0.163 sec/step)\n",
            "I0601 12:20:59.145711 140438660523904 learning.py:507] global step 9303: loss = 0.0589 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9304: loss = 0.1369 (0.164 sec/step)\n",
            "I0601 12:20:59.311458 140438660523904 learning.py:507] global step 9304: loss = 0.1369 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9305: loss = 0.2860 (0.156 sec/step)\n",
            "I0601 12:20:59.469033 140438660523904 learning.py:507] global step 9305: loss = 0.2860 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9306: loss = 0.0252 (0.147 sec/step)\n",
            "I0601 12:20:59.617711 140438660523904 learning.py:507] global step 9306: loss = 0.0252 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 9307: loss = 0.0974 (0.161 sec/step)\n",
            "I0601 12:20:59.780368 140438660523904 learning.py:507] global step 9307: loss = 0.0974 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9308: loss = 0.1283 (0.176 sec/step)\n",
            "I0601 12:20:59.957427 140438660523904 learning.py:507] global step 9308: loss = 0.1283 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9309: loss = 0.0816 (0.219 sec/step)\n",
            "I0601 12:21:00.178333 140438660523904 learning.py:507] global step 9309: loss = 0.0816 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 9310: loss = 0.1093 (0.155 sec/step)\n",
            "I0601 12:21:00.334554 140438660523904 learning.py:507] global step 9310: loss = 0.1093 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9311: loss = 0.1396 (0.171 sec/step)\n",
            "I0601 12:21:00.507116 140438660523904 learning.py:507] global step 9311: loss = 0.1396 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9312: loss = 0.1265 (0.170 sec/step)\n",
            "I0601 12:21:00.678049 140438660523904 learning.py:507] global step 9312: loss = 0.1265 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9313: loss = 0.0987 (0.183 sec/step)\n",
            "I0601 12:21:00.862104 140438660523904 learning.py:507] global step 9313: loss = 0.0987 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9314: loss = 0.0446 (0.139 sec/step)\n",
            "I0601 12:21:01.002603 140438660523904 learning.py:507] global step 9314: loss = 0.0446 (0.139 sec/step)\n",
            "INFO:tensorflow:global step 9315: loss = 0.0292 (0.188 sec/step)\n",
            "I0601 12:21:01.192572 140438660523904 learning.py:507] global step 9315: loss = 0.0292 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9316: loss = 0.0636 (0.192 sec/step)\n",
            "I0601 12:21:01.385632 140438660523904 learning.py:507] global step 9316: loss = 0.0636 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9317: loss = 0.0788 (0.170 sec/step)\n",
            "I0601 12:21:01.557180 140438660523904 learning.py:507] global step 9317: loss = 0.0788 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9318: loss = 0.0487 (0.172 sec/step)\n",
            "I0601 12:21:01.730250 140438660523904 learning.py:507] global step 9318: loss = 0.0487 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9319: loss = 0.0809 (0.164 sec/step)\n",
            "I0601 12:21:01.895999 140438660523904 learning.py:507] global step 9319: loss = 0.0809 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9320: loss = 0.0737 (0.164 sec/step)\n",
            "I0601 12:21:02.061051 140438660523904 learning.py:507] global step 9320: loss = 0.0737 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9321: loss = 0.2358 (0.218 sec/step)\n",
            "I0601 12:21:02.281526 140438660523904 learning.py:507] global step 9321: loss = 0.2358 (0.218 sec/step)\n",
            "INFO:tensorflow:global step 9322: loss = 0.1056 (0.164 sec/step)\n",
            "I0601 12:21:02.447984 140438660523904 learning.py:507] global step 9322: loss = 0.1056 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9323: loss = 0.4324 (0.170 sec/step)\n",
            "I0601 12:21:02.619715 140438660523904 learning.py:507] global step 9323: loss = 0.4324 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9324: loss = 0.0954 (0.175 sec/step)\n",
            "I0601 12:21:02.795921 140438660523904 learning.py:507] global step 9324: loss = 0.0954 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9325: loss = 0.3371 (0.164 sec/step)\n",
            "I0601 12:21:02.961587 140438660523904 learning.py:507] global step 9325: loss = 0.3371 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9326: loss = 0.2143 (0.208 sec/step)\n",
            "I0601 12:21:03.171485 140438660523904 learning.py:507] global step 9326: loss = 0.2143 (0.208 sec/step)\n",
            "INFO:tensorflow:global step 9327: loss = 0.0820 (0.166 sec/step)\n",
            "I0601 12:21:03.338998 140438660523904 learning.py:507] global step 9327: loss = 0.0820 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9328: loss = 0.1561 (0.161 sec/step)\n",
            "I0601 12:21:03.501506 140438660523904 learning.py:507] global step 9328: loss = 0.1561 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9329: loss = 0.1268 (0.178 sec/step)\n",
            "I0601 12:21:03.681239 140438660523904 learning.py:507] global step 9329: loss = 0.1268 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9330: loss = 0.1135 (0.180 sec/step)\n",
            "I0601 12:21:03.862136 140438660523904 learning.py:507] global step 9330: loss = 0.1135 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9331: loss = 0.0299 (0.148 sec/step)\n",
            "I0601 12:21:04.010978 140438660523904 learning.py:507] global step 9331: loss = 0.0299 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9332: loss = 0.2092 (0.191 sec/step)\n",
            "I0601 12:21:04.203652 140438660523904 learning.py:507] global step 9332: loss = 0.2092 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 9333: loss = 0.1868 (0.178 sec/step)\n",
            "I0601 12:21:04.382686 140438660523904 learning.py:507] global step 9333: loss = 0.1868 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9334: loss = 0.1783 (0.173 sec/step)\n",
            "I0601 12:21:04.557509 140438660523904 learning.py:507] global step 9334: loss = 0.1783 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9335: loss = 0.1133 (0.174 sec/step)\n",
            "I0601 12:21:04.732877 140438660523904 learning.py:507] global step 9335: loss = 0.1133 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9336: loss = 0.1755 (0.165 sec/step)\n",
            "I0601 12:21:04.899786 140438660523904 learning.py:507] global step 9336: loss = 0.1755 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9337: loss = 0.1126 (0.159 sec/step)\n",
            "I0601 12:21:05.059881 140438660523904 learning.py:507] global step 9337: loss = 0.1126 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9338: loss = 0.0494 (0.168 sec/step)\n",
            "I0601 12:21:05.229489 140438660523904 learning.py:507] global step 9338: loss = 0.0494 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9339: loss = 0.0878 (0.175 sec/step)\n",
            "I0601 12:21:05.406183 140438660523904 learning.py:507] global step 9339: loss = 0.0878 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9340: loss = 0.0366 (0.174 sec/step)\n",
            "I0601 12:21:05.581917 140438660523904 learning.py:507] global step 9340: loss = 0.0366 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9341: loss = 0.0237 (0.177 sec/step)\n",
            "I0601 12:21:05.759994 140438660523904 learning.py:507] global step 9341: loss = 0.0237 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9342: loss = 0.1085 (0.183 sec/step)\n",
            "I0601 12:21:05.944714 140438660523904 learning.py:507] global step 9342: loss = 0.1085 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9343: loss = 0.0675 (0.182 sec/step)\n",
            "I0601 12:21:06.128368 140438660523904 learning.py:507] global step 9343: loss = 0.0675 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9344: loss = 0.2538 (0.171 sec/step)\n",
            "I0601 12:21:06.301104 140438660523904 learning.py:507] global step 9344: loss = 0.2538 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9345: loss = 0.1017 (0.185 sec/step)\n",
            "I0601 12:21:06.487577 140438660523904 learning.py:507] global step 9345: loss = 0.1017 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9346: loss = 0.0778 (0.154 sec/step)\n",
            "I0601 12:21:06.642755 140438660523904 learning.py:507] global step 9346: loss = 0.0778 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9347: loss = 0.1271 (0.162 sec/step)\n",
            "I0601 12:21:06.806712 140438660523904 learning.py:507] global step 9347: loss = 0.1271 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9348: loss = 0.1708 (0.180 sec/step)\n",
            "I0601 12:21:06.988278 140438660523904 learning.py:507] global step 9348: loss = 0.1708 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9349: loss = 0.0328 (0.164 sec/step)\n",
            "I0601 12:21:07.154055 140438660523904 learning.py:507] global step 9349: loss = 0.0328 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9350: loss = 0.1443 (0.158 sec/step)\n",
            "I0601 12:21:07.313849 140438660523904 learning.py:507] global step 9350: loss = 0.1443 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9351: loss = 0.1223 (0.182 sec/step)\n",
            "I0601 12:21:07.497138 140438660523904 learning.py:507] global step 9351: loss = 0.1223 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9352: loss = 0.1465 (0.151 sec/step)\n",
            "I0601 12:21:07.649698 140438660523904 learning.py:507] global step 9352: loss = 0.1465 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9353: loss = 0.0830 (0.167 sec/step)\n",
            "I0601 12:21:07.818093 140438660523904 learning.py:507] global step 9353: loss = 0.0830 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9354: loss = 0.0210 (0.158 sec/step)\n",
            "I0601 12:21:07.977513 140438660523904 learning.py:507] global step 9354: loss = 0.0210 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9355: loss = 0.0931 (0.178 sec/step)\n",
            "I0601 12:21:08.156617 140438660523904 learning.py:507] global step 9355: loss = 0.0931 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9356: loss = 0.1887 (0.161 sec/step)\n",
            "I0601 12:21:08.319589 140438660523904 learning.py:507] global step 9356: loss = 0.1887 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9357: loss = 0.2884 (0.178 sec/step)\n",
            "I0601 12:21:08.499627 140438660523904 learning.py:507] global step 9357: loss = 0.2884 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9358: loss = 0.1405 (0.168 sec/step)\n",
            "I0601 12:21:08.669319 140438660523904 learning.py:507] global step 9358: loss = 0.1405 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9359: loss = 0.1128 (0.158 sec/step)\n",
            "I0601 12:21:08.828635 140438660523904 learning.py:507] global step 9359: loss = 0.1128 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9360: loss = 0.0456 (0.154 sec/step)\n",
            "I0601 12:21:08.983881 140438660523904 learning.py:507] global step 9360: loss = 0.0456 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9361: loss = 0.1667 (0.169 sec/step)\n",
            "I0601 12:21:09.154014 140438660523904 learning.py:507] global step 9361: loss = 0.1667 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9362: loss = 0.0899 (0.189 sec/step)\n",
            "I0601 12:21:09.344106 140438660523904 learning.py:507] global step 9362: loss = 0.0899 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9363: loss = 0.0989 (0.165 sec/step)\n",
            "I0601 12:21:09.510416 140438660523904 learning.py:507] global step 9363: loss = 0.0989 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9364: loss = 0.2002 (0.200 sec/step)\n",
            "I0601 12:21:09.712026 140438660523904 learning.py:507] global step 9364: loss = 0.2002 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9365: loss = 0.1256 (0.182 sec/step)\n",
            "I0601 12:21:09.896369 140438660523904 learning.py:507] global step 9365: loss = 0.1256 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9366: loss = 0.2694 (0.198 sec/step)\n",
            "I0601 12:21:10.096202 140438660523904 learning.py:507] global step 9366: loss = 0.2694 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 9367: loss = 0.0747 (0.167 sec/step)\n",
            "I0601 12:21:10.264228 140438660523904 learning.py:507] global step 9367: loss = 0.0747 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9368: loss = 0.0576 (0.179 sec/step)\n",
            "I0601 12:21:10.444900 140438660523904 learning.py:507] global step 9368: loss = 0.0576 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9369: loss = 0.0936 (0.178 sec/step)\n",
            "I0601 12:21:10.624172 140438660523904 learning.py:507] global step 9369: loss = 0.0936 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9370: loss = 0.1234 (0.190 sec/step)\n",
            "I0601 12:21:10.815554 140438660523904 learning.py:507] global step 9370: loss = 0.1234 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9371: loss = 0.0377 (0.147 sec/step)\n",
            "I0601 12:21:10.964464 140438660523904 learning.py:507] global step 9371: loss = 0.0377 (0.147 sec/step)\n",
            "INFO:tensorflow:global step 9372: loss = 0.1473 (0.163 sec/step)\n",
            "I0601 12:21:11.128808 140438660523904 learning.py:507] global step 9372: loss = 0.1473 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9373: loss = 0.2244 (0.180 sec/step)\n",
            "I0601 12:21:11.310029 140438660523904 learning.py:507] global step 9373: loss = 0.2244 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9374: loss = 0.1598 (0.184 sec/step)\n",
            "I0601 12:21:11.495274 140438660523904 learning.py:507] global step 9374: loss = 0.1598 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9375: loss = 0.0659 (0.164 sec/step)\n",
            "I0601 12:21:11.660472 140438660523904 learning.py:507] global step 9375: loss = 0.0659 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9376: loss = 0.0818 (0.185 sec/step)\n",
            "I0601 12:21:11.847251 140438660523904 learning.py:507] global step 9376: loss = 0.0818 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9377: loss = 0.1353 (0.172 sec/step)\n",
            "I0601 12:21:12.021294 140438660523904 learning.py:507] global step 9377: loss = 0.1353 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9378: loss = 0.1758 (0.168 sec/step)\n",
            "I0601 12:21:12.191007 140438660523904 learning.py:507] global step 9378: loss = 0.1758 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9379: loss = 0.1801 (0.175 sec/step)\n",
            "I0601 12:21:12.368052 140438660523904 learning.py:507] global step 9379: loss = 0.1801 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9380: loss = 0.0583 (0.205 sec/step)\n",
            "I0601 12:21:12.574721 140438660523904 learning.py:507] global step 9380: loss = 0.0583 (0.205 sec/step)\n",
            "INFO:tensorflow:global step 9381: loss = 0.0673 (0.166 sec/step)\n",
            "I0601 12:21:12.742569 140438660523904 learning.py:507] global step 9381: loss = 0.0673 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9382: loss = 0.0880 (0.182 sec/step)\n",
            "I0601 12:21:12.925723 140438660523904 learning.py:507] global step 9382: loss = 0.0880 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9383: loss = 0.0448 (0.161 sec/step)\n",
            "I0601 12:21:13.088234 140438660523904 learning.py:507] global step 9383: loss = 0.0448 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9384: loss = 0.0415 (0.164 sec/step)\n",
            "I0601 12:21:13.254389 140438660523904 learning.py:507] global step 9384: loss = 0.0415 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9385: loss = 0.1144 (0.198 sec/step)\n",
            "I0601 12:21:13.453958 140438660523904 learning.py:507] global step 9385: loss = 0.1144 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 9386: loss = 0.2103 (0.181 sec/step)\n",
            "I0601 12:21:13.636407 140438660523904 learning.py:507] global step 9386: loss = 0.2103 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9387: loss = 0.1667 (0.174 sec/step)\n",
            "I0601 12:21:13.811809 140438660523904 learning.py:507] global step 9387: loss = 0.1667 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9388: loss = 0.1217 (0.179 sec/step)\n",
            "I0601 12:21:13.992295 140438660523904 learning.py:507] global step 9388: loss = 0.1217 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9389: loss = 0.0681 (0.157 sec/step)\n",
            "I0601 12:21:14.150996 140438660523904 learning.py:507] global step 9389: loss = 0.0681 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9390: loss = 0.0827 (0.162 sec/step)\n",
            "I0601 12:21:14.314543 140438660523904 learning.py:507] global step 9390: loss = 0.0827 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9391: loss = 0.0555 (0.185 sec/step)\n",
            "I0601 12:21:14.500960 140438660523904 learning.py:507] global step 9391: loss = 0.0555 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9392: loss = 0.0505 (0.166 sec/step)\n",
            "I0601 12:21:14.668710 140438660523904 learning.py:507] global step 9392: loss = 0.0505 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9393: loss = 0.1139 (0.176 sec/step)\n",
            "I0601 12:21:14.846568 140438660523904 learning.py:507] global step 9393: loss = 0.1139 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9394: loss = 0.3482 (0.144 sec/step)\n",
            "I0601 12:21:14.992272 140438660523904 learning.py:507] global step 9394: loss = 0.3482 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 9395: loss = 0.0611 (0.165 sec/step)\n",
            "I0601 12:21:15.158544 140438660523904 learning.py:507] global step 9395: loss = 0.0611 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9396: loss = 0.1197 (0.152 sec/step)\n",
            "I0601 12:21:15.311572 140438660523904 learning.py:507] global step 9396: loss = 0.1197 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9397: loss = 0.1171 (0.165 sec/step)\n",
            "I0601 12:21:15.477822 140438660523904 learning.py:507] global step 9397: loss = 0.1171 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9398: loss = 0.1129 (0.190 sec/step)\n",
            "I0601 12:21:15.668882 140438660523904 learning.py:507] global step 9398: loss = 0.1129 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9399: loss = 0.0574 (0.179 sec/step)\n",
            "I0601 12:21:15.849077 140438660523904 learning.py:507] global step 9399: loss = 0.0574 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9400: loss = 0.1530 (0.160 sec/step)\n",
            "I0601 12:21:16.010309 140438660523904 learning.py:507] global step 9400: loss = 0.1530 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9401: loss = 0.0415 (0.169 sec/step)\n",
            "I0601 12:21:16.180437 140438660523904 learning.py:507] global step 9401: loss = 0.0415 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9402: loss = 0.2431 (0.196 sec/step)\n",
            "I0601 12:21:16.378144 140438660523904 learning.py:507] global step 9402: loss = 0.2431 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 9403: loss = 0.0353 (0.167 sec/step)\n",
            "I0601 12:21:16.546926 140438660523904 learning.py:507] global step 9403: loss = 0.0353 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9404: loss = 0.0825 (0.180 sec/step)\n",
            "I0601 12:21:16.728370 140438660523904 learning.py:507] global step 9404: loss = 0.0825 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9405: loss = 0.0919 (0.171 sec/step)\n",
            "I0601 12:21:16.900949 140438660523904 learning.py:507] global step 9405: loss = 0.0919 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9406: loss = 0.2298 (0.173 sec/step)\n",
            "I0601 12:21:17.075660 140438660523904 learning.py:507] global step 9406: loss = 0.2298 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9407: loss = 0.1035 (0.152 sec/step)\n",
            "I0601 12:21:17.229213 140438660523904 learning.py:507] global step 9407: loss = 0.1035 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9408: loss = 0.0166 (0.152 sec/step)\n",
            "I0601 12:21:17.382282 140438660523904 learning.py:507] global step 9408: loss = 0.0166 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9409: loss = 0.2995 (0.157 sec/step)\n",
            "I0601 12:21:17.540396 140438660523904 learning.py:507] global step 9409: loss = 0.2995 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9410: loss = 0.0529 (0.181 sec/step)\n",
            "I0601 12:21:17.723154 140438660523904 learning.py:507] global step 9410: loss = 0.0529 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9411: loss = 0.1075 (0.161 sec/step)\n",
            "I0601 12:21:17.885086 140438660523904 learning.py:507] global step 9411: loss = 0.1075 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9412: loss = 4.1634 (0.179 sec/step)\n",
            "I0601 12:21:18.065655 140438660523904 learning.py:507] global step 9412: loss = 4.1634 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9413: loss = 0.1381 (0.172 sec/step)\n",
            "I0601 12:21:18.239502 140438660523904 learning.py:507] global step 9413: loss = 0.1381 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9414: loss = 0.1619 (0.173 sec/step)\n",
            "I0601 12:21:18.413608 140438660523904 learning.py:507] global step 9414: loss = 0.1619 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9415: loss = 0.0311 (0.163 sec/step)\n",
            "I0601 12:21:18.578708 140438660523904 learning.py:507] global step 9415: loss = 0.0311 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9416: loss = 0.0972 (0.169 sec/step)\n",
            "I0601 12:21:18.748556 140438660523904 learning.py:507] global step 9416: loss = 0.0972 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9417: loss = 0.0985 (0.199 sec/step)\n",
            "I0601 12:21:18.948775 140438660523904 learning.py:507] global step 9417: loss = 0.0985 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 9418: loss = 0.0997 (0.143 sec/step)\n",
            "I0601 12:21:19.092974 140438660523904 learning.py:507] global step 9418: loss = 0.0997 (0.143 sec/step)\n",
            "INFO:tensorflow:global step 9419: loss = 0.0385 (0.151 sec/step)\n",
            "I0601 12:21:19.245249 140438660523904 learning.py:507] global step 9419: loss = 0.0385 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9420: loss = 0.1562 (0.168 sec/step)\n",
            "I0601 12:21:19.414421 140438660523904 learning.py:507] global step 9420: loss = 0.1562 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9421: loss = 0.1877 (0.153 sec/step)\n",
            "I0601 12:21:19.568620 140438660523904 learning.py:507] global step 9421: loss = 0.1877 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9422: loss = 0.1250 (0.179 sec/step)\n",
            "I0601 12:21:19.749544 140438660523904 learning.py:507] global step 9422: loss = 0.1250 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9423: loss = 0.0960 (0.161 sec/step)\n",
            "I0601 12:21:19.911734 140438660523904 learning.py:507] global step 9423: loss = 0.0960 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9424: loss = 0.0496 (0.168 sec/step)\n",
            "I0601 12:21:20.081284 140438660523904 learning.py:507] global step 9424: loss = 0.0496 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9425: loss = 0.1056 (0.163 sec/step)\n",
            "I0601 12:21:20.245710 140438660523904 learning.py:507] global step 9425: loss = 0.1056 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9426: loss = 0.0677 (0.162 sec/step)\n",
            "I0601 12:21:20.409529 140438660523904 learning.py:507] global step 9426: loss = 0.0677 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9427: loss = 0.1225 (0.179 sec/step)\n",
            "I0601 12:21:20.589796 140438660523904 learning.py:507] global step 9427: loss = 0.1225 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9428: loss = 0.1703 (0.184 sec/step)\n",
            "I0601 12:21:20.775197 140438660523904 learning.py:507] global step 9428: loss = 0.1703 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9429: loss = 0.2637 (0.155 sec/step)\n",
            "I0601 12:21:20.931874 140438660523904 learning.py:507] global step 9429: loss = 0.2637 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9430: loss = 0.0752 (0.177 sec/step)\n",
            "I0601 12:21:21.110316 140438660523904 learning.py:507] global step 9430: loss = 0.0752 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9431: loss = 0.0208 (0.164 sec/step)\n",
            "I0601 12:21:21.275417 140438660523904 learning.py:507] global step 9431: loss = 0.0208 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9432: loss = 0.0751 (0.181 sec/step)\n",
            "I0601 12:21:21.457658 140438660523904 learning.py:507] global step 9432: loss = 0.0751 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9433: loss = 0.3527 (0.189 sec/step)\n",
            "I0601 12:21:21.648452 140438660523904 learning.py:507] global step 9433: loss = 0.3527 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9434: loss = 0.0935 (0.159 sec/step)\n",
            "I0601 12:21:21.809125 140438660523904 learning.py:507] global step 9434: loss = 0.0935 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9435: loss = 0.2729 (0.180 sec/step)\n",
            "I0601 12:21:21.990679 140438660523904 learning.py:507] global step 9435: loss = 0.2729 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9436: loss = 0.1778 (0.170 sec/step)\n",
            "I0601 12:21:22.161696 140438660523904 learning.py:507] global step 9436: loss = 0.1778 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9437: loss = 0.4184 (0.182 sec/step)\n",
            "I0601 12:21:22.344876 140438660523904 learning.py:507] global step 9437: loss = 0.4184 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9438: loss = 0.0496 (0.186 sec/step)\n",
            "I0601 12:21:22.532726 140438660523904 learning.py:507] global step 9438: loss = 0.0496 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9439: loss = 0.1208 (0.178 sec/step)\n",
            "I0601 12:21:22.711899 140438660523904 learning.py:507] global step 9439: loss = 0.1208 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9440: loss = 0.1983 (0.165 sec/step)\n",
            "I0601 12:21:22.878248 140438660523904 learning.py:507] global step 9440: loss = 0.1983 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9441: loss = 0.1024 (0.163 sec/step)\n",
            "I0601 12:21:23.043189 140438660523904 learning.py:507] global step 9441: loss = 0.1024 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9442: loss = 0.0189 (0.178 sec/step)\n",
            "I0601 12:21:23.222052 140438660523904 learning.py:507] global step 9442: loss = 0.0189 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9443: loss = 0.0616 (0.187 sec/step)\n",
            "I0601 12:21:23.410282 140438660523904 learning.py:507] global step 9443: loss = 0.0616 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9444: loss = 0.2405 (0.159 sec/step)\n",
            "I0601 12:21:23.570965 140438660523904 learning.py:507] global step 9444: loss = 0.2405 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9445: loss = 0.0226 (0.189 sec/step)\n",
            "I0601 12:21:23.761325 140438660523904 learning.py:507] global step 9445: loss = 0.0226 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9446: loss = 0.1087 (0.163 sec/step)\n",
            "I0601 12:21:23.925287 140438660523904 learning.py:507] global step 9446: loss = 0.1087 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9447: loss = 0.0329 (0.160 sec/step)\n",
            "I0601 12:21:24.087014 140438660523904 learning.py:507] global step 9447: loss = 0.0329 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9448: loss = 0.1339 (0.209 sec/step)\n",
            "I0601 12:21:24.297304 140438660523904 learning.py:507] global step 9448: loss = 0.1339 (0.209 sec/step)\n",
            "INFO:tensorflow:global step 9449: loss = 0.2927 (0.182 sec/step)\n",
            "I0601 12:21:24.480625 140438660523904 learning.py:507] global step 9449: loss = 0.2927 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9450: loss = 0.0353 (0.163 sec/step)\n",
            "I0601 12:21:24.645332 140438660523904 learning.py:507] global step 9450: loss = 0.0353 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9451: loss = 0.2540 (0.194 sec/step)\n",
            "I0601 12:21:24.840424 140438660523904 learning.py:507] global step 9451: loss = 0.2540 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9452: loss = 0.1492 (0.167 sec/step)\n",
            "I0601 12:21:25.009316 140438660523904 learning.py:507] global step 9452: loss = 0.1492 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9453: loss = 0.1127 (0.165 sec/step)\n",
            "I0601 12:21:25.176617 140438660523904 learning.py:507] global step 9453: loss = 0.1127 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9454: loss = 0.1563 (0.174 sec/step)\n",
            "I0601 12:21:25.352388 140438660523904 learning.py:507] global step 9454: loss = 0.1563 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9455: loss = 0.0746 (0.171 sec/step)\n",
            "I0601 12:21:25.524923 140438660523904 learning.py:507] global step 9455: loss = 0.0746 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9456: loss = 0.2236 (0.175 sec/step)\n",
            "I0601 12:21:25.701560 140438660523904 learning.py:507] global step 9456: loss = 0.2236 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9457: loss = 0.2305 (0.170 sec/step)\n",
            "I0601 12:21:25.872964 140438660523904 learning.py:507] global step 9457: loss = 0.2305 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9458: loss = 0.1551 (0.184 sec/step)\n",
            "I0601 12:21:26.058217 140438660523904 learning.py:507] global step 9458: loss = 0.1551 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9459: loss = 0.0994 (0.167 sec/step)\n",
            "I0601 12:21:26.227010 140438660523904 learning.py:507] global step 9459: loss = 0.0994 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9460: loss = 0.2499 (0.166 sec/step)\n",
            "I0601 12:21:26.394820 140438660523904 learning.py:507] global step 9460: loss = 0.2499 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9461: loss = 0.0470 (0.159 sec/step)\n",
            "I0601 12:21:26.555238 140438660523904 learning.py:507] global step 9461: loss = 0.0470 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9462: loss = 0.0748 (0.194 sec/step)\n",
            "I0601 12:21:26.750948 140438660523904 learning.py:507] global step 9462: loss = 0.0748 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9463: loss = 0.0568 (0.162 sec/step)\n",
            "I0601 12:21:26.913936 140438660523904 learning.py:507] global step 9463: loss = 0.0568 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9464: loss = 0.0769 (0.173 sec/step)\n",
            "I0601 12:21:27.088137 140438660523904 learning.py:507] global step 9464: loss = 0.0769 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9465: loss = 0.0493 (0.158 sec/step)\n",
            "I0601 12:21:27.247407 140438660523904 learning.py:507] global step 9465: loss = 0.0493 (0.158 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n",
            "I0601 12:21:27.354926 140435020310272 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n",
            "INFO:tensorflow:global step 9466: loss = 0.0318 (0.608 sec/step)\n",
            "I0601 12:21:27.958422 140438660523904 learning.py:507] global step 9466: loss = 0.0318 (0.608 sec/step)\n",
            "INFO:tensorflow:global step 9467: loss = 0.0992 (0.481 sec/step)\n",
            "I0601 12:21:28.443360 140438660523904 learning.py:507] global step 9467: loss = 0.0992 (0.481 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 9468.\n",
            "I0601 12:21:28.910661 140435003524864 supervisor.py:1050] Recording summary at step 9468.\n",
            "INFO:tensorflow:global step 9468: loss = 0.0478 (0.466 sec/step)\n",
            "I0601 12:21:28.925250 140438660523904 learning.py:507] global step 9468: loss = 0.0478 (0.466 sec/step)\n",
            "INFO:tensorflow:global step 9469: loss = 0.0512 (0.311 sec/step)\n",
            "I0601 12:21:29.314287 140438660523904 learning.py:507] global step 9469: loss = 0.0512 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 9470: loss = 0.0353 (0.198 sec/step)\n",
            "I0601 12:21:29.575163 140438660523904 learning.py:507] global step 9470: loss = 0.0353 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 9471: loss = 0.1396 (0.183 sec/step)\n",
            "I0601 12:21:29.759843 140438660523904 learning.py:507] global step 9471: loss = 0.1396 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9472: loss = 0.0701 (0.193 sec/step)\n",
            "I0601 12:21:29.954181 140438660523904 learning.py:507] global step 9472: loss = 0.0701 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9473: loss = 0.0878 (0.168 sec/step)\n",
            "I0601 12:21:30.124036 140438660523904 learning.py:507] global step 9473: loss = 0.0878 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9474: loss = 0.3927 (0.181 sec/step)\n",
            "I0601 12:21:30.306782 140438660523904 learning.py:507] global step 9474: loss = 0.3927 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9475: loss = 0.0566 (0.174 sec/step)\n",
            "I0601 12:21:30.482871 140438660523904 learning.py:507] global step 9475: loss = 0.0566 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9476: loss = 0.1724 (0.166 sec/step)\n",
            "I0601 12:21:30.650804 140438660523904 learning.py:507] global step 9476: loss = 0.1724 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9477: loss = 0.0765 (0.188 sec/step)\n",
            "I0601 12:21:30.840443 140438660523904 learning.py:507] global step 9477: loss = 0.0765 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9478: loss = 0.0967 (0.179 sec/step)\n",
            "I0601 12:21:31.020979 140438660523904 learning.py:507] global step 9478: loss = 0.0967 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9479: loss = 0.1206 (0.170 sec/step)\n",
            "I0601 12:21:31.192014 140438660523904 learning.py:507] global step 9479: loss = 0.1206 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9480: loss = 0.1387 (0.179 sec/step)\n",
            "I0601 12:21:31.373066 140438660523904 learning.py:507] global step 9480: loss = 0.1387 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9481: loss = 0.0865 (0.164 sec/step)\n",
            "I0601 12:21:31.538443 140438660523904 learning.py:507] global step 9481: loss = 0.0865 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9482: loss = 0.0999 (0.193 sec/step)\n",
            "I0601 12:21:31.733014 140438660523904 learning.py:507] global step 9482: loss = 0.0999 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9483: loss = 0.0438 (0.155 sec/step)\n",
            "I0601 12:21:31.889841 140438660523904 learning.py:507] global step 9483: loss = 0.0438 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9484: loss = 0.0731 (0.164 sec/step)\n",
            "I0601 12:21:32.056063 140438660523904 learning.py:507] global step 9484: loss = 0.0731 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9485: loss = 0.1029 (0.170 sec/step)\n",
            "I0601 12:21:32.227314 140438660523904 learning.py:507] global step 9485: loss = 0.1029 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9486: loss = 0.0403 (0.199 sec/step)\n",
            "I0601 12:21:32.427286 140438660523904 learning.py:507] global step 9486: loss = 0.0403 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 9487: loss = 0.0681 (0.158 sec/step)\n",
            "I0601 12:21:32.586885 140438660523904 learning.py:507] global step 9487: loss = 0.0681 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9488: loss = 0.1071 (0.160 sec/step)\n",
            "I0601 12:21:32.748605 140438660523904 learning.py:507] global step 9488: loss = 0.1071 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9489: loss = 0.1267 (0.175 sec/step)\n",
            "I0601 12:21:32.924865 140438660523904 learning.py:507] global step 9489: loss = 0.1267 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9490: loss = 0.2406 (0.175 sec/step)\n",
            "I0601 12:21:33.101475 140438660523904 learning.py:507] global step 9490: loss = 0.2406 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9491: loss = 0.0505 (0.166 sec/step)\n",
            "I0601 12:21:33.268687 140438660523904 learning.py:507] global step 9491: loss = 0.0505 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9492: loss = 0.1497 (0.174 sec/step)\n",
            "I0601 12:21:33.444039 140438660523904 learning.py:507] global step 9492: loss = 0.1497 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9493: loss = 0.0438 (0.148 sec/step)\n",
            "I0601 12:21:33.593142 140438660523904 learning.py:507] global step 9493: loss = 0.0438 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9494: loss = 0.1026 (0.154 sec/step)\n",
            "I0601 12:21:33.748754 140438660523904 learning.py:507] global step 9494: loss = 0.1026 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9495: loss = 0.0238 (0.167 sec/step)\n",
            "I0601 12:21:33.917552 140438660523904 learning.py:507] global step 9495: loss = 0.0238 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9496: loss = 0.1375 (0.160 sec/step)\n",
            "I0601 12:21:34.078949 140438660523904 learning.py:507] global step 9496: loss = 0.1375 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9497: loss = 0.1747 (0.178 sec/step)\n",
            "I0601 12:21:34.258067 140438660523904 learning.py:507] global step 9497: loss = 0.1747 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9498: loss = 0.0640 (0.177 sec/step)\n",
            "I0601 12:21:34.436090 140438660523904 learning.py:507] global step 9498: loss = 0.0640 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9499: loss = 0.2708 (0.183 sec/step)\n",
            "I0601 12:21:34.620469 140438660523904 learning.py:507] global step 9499: loss = 0.2708 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9500: loss = 0.0651 (0.250 sec/step)\n",
            "I0601 12:21:34.872538 140438660523904 learning.py:507] global step 9500: loss = 0.0651 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9501: loss = 0.1281 (0.203 sec/step)\n",
            "I0601 12:21:35.077603 140438660523904 learning.py:507] global step 9501: loss = 0.1281 (0.203 sec/step)\n",
            "INFO:tensorflow:global step 9502: loss = 0.0716 (0.233 sec/step)\n",
            "I0601 12:21:35.312494 140438660523904 learning.py:507] global step 9502: loss = 0.0716 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9503: loss = 0.0866 (0.235 sec/step)\n",
            "I0601 12:21:35.549859 140438660523904 learning.py:507] global step 9503: loss = 0.0866 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9504: loss = 0.0704 (0.188 sec/step)\n",
            "I0601 12:21:35.739786 140438660523904 learning.py:507] global step 9504: loss = 0.0704 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9505: loss = 0.1175 (0.182 sec/step)\n",
            "I0601 12:21:35.923290 140438660523904 learning.py:507] global step 9505: loss = 0.1175 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9506: loss = 0.0906 (0.172 sec/step)\n",
            "I0601 12:21:36.096492 140438660523904 learning.py:507] global step 9506: loss = 0.0906 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9507: loss = 0.0615 (0.173 sec/step)\n",
            "I0601 12:21:36.270667 140438660523904 learning.py:507] global step 9507: loss = 0.0615 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9508: loss = 0.0659 (0.174 sec/step)\n",
            "I0601 12:21:36.446263 140438660523904 learning.py:507] global step 9508: loss = 0.0659 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9509: loss = 0.0877 (0.181 sec/step)\n",
            "I0601 12:21:36.628763 140438660523904 learning.py:507] global step 9509: loss = 0.0877 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9510: loss = 0.2579 (0.159 sec/step)\n",
            "I0601 12:21:36.789330 140438660523904 learning.py:507] global step 9510: loss = 0.2579 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9511: loss = 0.0812 (0.170 sec/step)\n",
            "I0601 12:21:36.960522 140438660523904 learning.py:507] global step 9511: loss = 0.0812 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9512: loss = 0.1701 (0.173 sec/step)\n",
            "I0601 12:21:37.134825 140438660523904 learning.py:507] global step 9512: loss = 0.1701 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9513: loss = 0.3262 (0.181 sec/step)\n",
            "I0601 12:21:37.316872 140438660523904 learning.py:507] global step 9513: loss = 0.3262 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9514: loss = 0.0893 (0.173 sec/step)\n",
            "I0601 12:21:37.491412 140438660523904 learning.py:507] global step 9514: loss = 0.0893 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9515: loss = 0.0520 (0.181 sec/step)\n",
            "I0601 12:21:37.674172 140438660523904 learning.py:507] global step 9515: loss = 0.0520 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9516: loss = 0.0877 (0.181 sec/step)\n",
            "I0601 12:21:37.856463 140438660523904 learning.py:507] global step 9516: loss = 0.0877 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9517: loss = 0.0568 (0.167 sec/step)\n",
            "I0601 12:21:38.024365 140438660523904 learning.py:507] global step 9517: loss = 0.0568 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9518: loss = 0.0880 (0.169 sec/step)\n",
            "I0601 12:21:38.195144 140438660523904 learning.py:507] global step 9518: loss = 0.0880 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9519: loss = 0.0500 (0.172 sec/step)\n",
            "I0601 12:21:38.368479 140438660523904 learning.py:507] global step 9519: loss = 0.0500 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9520: loss = 0.1719 (0.161 sec/step)\n",
            "I0601 12:21:38.531418 140438660523904 learning.py:507] global step 9520: loss = 0.1719 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9521: loss = 0.0567 (0.168 sec/step)\n",
            "I0601 12:21:38.700772 140438660523904 learning.py:507] global step 9521: loss = 0.0567 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9522: loss = 0.0896 (0.200 sec/step)\n",
            "I0601 12:21:38.903311 140438660523904 learning.py:507] global step 9522: loss = 0.0896 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9523: loss = 0.0727 (0.164 sec/step)\n",
            "I0601 12:21:39.069223 140438660523904 learning.py:507] global step 9523: loss = 0.0727 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9524: loss = 0.1146 (0.193 sec/step)\n",
            "I0601 12:21:39.263155 140438660523904 learning.py:507] global step 9524: loss = 0.1146 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9525: loss = 0.2141 (0.192 sec/step)\n",
            "I0601 12:21:39.456496 140438660523904 learning.py:507] global step 9525: loss = 0.2141 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9526: loss = 0.2085 (0.173 sec/step)\n",
            "I0601 12:21:39.630687 140438660523904 learning.py:507] global step 9526: loss = 0.2085 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9527: loss = 0.1900 (0.165 sec/step)\n",
            "I0601 12:21:39.798070 140438660523904 learning.py:507] global step 9527: loss = 0.1900 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9528: loss = 0.1760 (0.180 sec/step)\n",
            "I0601 12:21:39.979723 140438660523904 learning.py:507] global step 9528: loss = 0.1760 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9529: loss = 0.2528 (0.197 sec/step)\n",
            "I0601 12:21:40.178925 140438660523904 learning.py:507] global step 9529: loss = 0.2528 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 9530: loss = 0.0777 (0.143 sec/step)\n",
            "I0601 12:21:40.323129 140438660523904 learning.py:507] global step 9530: loss = 0.0777 (0.143 sec/step)\n",
            "INFO:tensorflow:global step 9531: loss = 0.0968 (0.170 sec/step)\n",
            "I0601 12:21:40.494742 140438660523904 learning.py:507] global step 9531: loss = 0.0968 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9532: loss = 0.0788 (0.173 sec/step)\n",
            "I0601 12:21:40.668735 140438660523904 learning.py:507] global step 9532: loss = 0.0788 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9533: loss = 0.2314 (0.173 sec/step)\n",
            "I0601 12:21:40.843541 140438660523904 learning.py:507] global step 9533: loss = 0.2314 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9534: loss = 0.0812 (0.180 sec/step)\n",
            "I0601 12:21:41.025664 140438660523904 learning.py:507] global step 9534: loss = 0.0812 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9535: loss = 0.1467 (0.158 sec/step)\n",
            "I0601 12:21:41.185123 140438660523904 learning.py:507] global step 9535: loss = 0.1467 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9536: loss = 0.0804 (0.175 sec/step)\n",
            "I0601 12:21:41.361016 140438660523904 learning.py:507] global step 9536: loss = 0.0804 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9537: loss = 0.0825 (0.173 sec/step)\n",
            "I0601 12:21:41.535177 140438660523904 learning.py:507] global step 9537: loss = 0.0825 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9538: loss = 0.1020 (0.192 sec/step)\n",
            "I0601 12:21:41.728387 140438660523904 learning.py:507] global step 9538: loss = 0.1020 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9539: loss = 0.2859 (0.176 sec/step)\n",
            "I0601 12:21:41.906998 140438660523904 learning.py:507] global step 9539: loss = 0.2859 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9540: loss = 0.1052 (0.153 sec/step)\n",
            "I0601 12:21:42.061057 140438660523904 learning.py:507] global step 9540: loss = 0.1052 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9541: loss = 0.1623 (0.173 sec/step)\n",
            "I0601 12:21:42.235456 140438660523904 learning.py:507] global step 9541: loss = 0.1623 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9542: loss = 0.2177 (0.162 sec/step)\n",
            "I0601 12:21:42.398745 140438660523904 learning.py:507] global step 9542: loss = 0.2177 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9543: loss = 0.0812 (0.178 sec/step)\n",
            "I0601 12:21:42.578285 140438660523904 learning.py:507] global step 9543: loss = 0.0812 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9544: loss = 0.0901 (0.175 sec/step)\n",
            "I0601 12:21:42.754542 140438660523904 learning.py:507] global step 9544: loss = 0.0901 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9545: loss = 0.0386 (0.168 sec/step)\n",
            "I0601 12:21:42.924413 140438660523904 learning.py:507] global step 9545: loss = 0.0386 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9546: loss = 0.0689 (0.180 sec/step)\n",
            "I0601 12:21:43.106188 140438660523904 learning.py:507] global step 9546: loss = 0.0689 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9547: loss = 0.0692 (0.167 sec/step)\n",
            "I0601 12:21:43.274605 140438660523904 learning.py:507] global step 9547: loss = 0.0692 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9548: loss = 0.1299 (0.175 sec/step)\n",
            "I0601 12:21:43.451212 140438660523904 learning.py:507] global step 9548: loss = 0.1299 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9549: loss = 0.0785 (0.177 sec/step)\n",
            "I0601 12:21:43.630249 140438660523904 learning.py:507] global step 9549: loss = 0.0785 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9550: loss = 0.1366 (0.194 sec/step)\n",
            "I0601 12:21:43.825433 140438660523904 learning.py:507] global step 9550: loss = 0.1366 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9551: loss = 0.0461 (0.181 sec/step)\n",
            "I0601 12:21:44.007520 140438660523904 learning.py:507] global step 9551: loss = 0.0461 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9552: loss = 0.2317 (0.189 sec/step)\n",
            "I0601 12:21:44.197888 140438660523904 learning.py:507] global step 9552: loss = 0.2317 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9553: loss = 0.0801 (0.170 sec/step)\n",
            "I0601 12:21:44.368832 140438660523904 learning.py:507] global step 9553: loss = 0.0801 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9554: loss = 0.0754 (0.177 sec/step)\n",
            "I0601 12:21:44.547325 140438660523904 learning.py:507] global step 9554: loss = 0.0754 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9555: loss = 0.1186 (0.204 sec/step)\n",
            "I0601 12:21:44.753372 140438660523904 learning.py:507] global step 9555: loss = 0.1186 (0.204 sec/step)\n",
            "INFO:tensorflow:global step 9556: loss = 0.2058 (0.179 sec/step)\n",
            "I0601 12:21:44.934484 140438660523904 learning.py:507] global step 9556: loss = 0.2058 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9557: loss = 0.1568 (0.154 sec/step)\n",
            "I0601 12:21:45.089881 140438660523904 learning.py:507] global step 9557: loss = 0.1568 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9558: loss = 0.2088 (0.164 sec/step)\n",
            "I0601 12:21:45.255398 140438660523904 learning.py:507] global step 9558: loss = 0.2088 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9559: loss = 0.1303 (0.165 sec/step)\n",
            "I0601 12:21:45.421917 140438660523904 learning.py:507] global step 9559: loss = 0.1303 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9560: loss = 0.1171 (0.166 sec/step)\n",
            "I0601 12:21:45.589535 140438660523904 learning.py:507] global step 9560: loss = 0.1171 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9561: loss = 0.2477 (0.178 sec/step)\n",
            "I0601 12:21:45.769372 140438660523904 learning.py:507] global step 9561: loss = 0.2477 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9562: loss = 0.1928 (0.179 sec/step)\n",
            "I0601 12:21:45.949398 140438660523904 learning.py:507] global step 9562: loss = 0.1928 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9563: loss = 0.0781 (0.187 sec/step)\n",
            "I0601 12:21:46.138188 140438660523904 learning.py:507] global step 9563: loss = 0.0781 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9564: loss = 0.0392 (0.163 sec/step)\n",
            "I0601 12:21:46.302024 140438660523904 learning.py:507] global step 9564: loss = 0.0392 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9565: loss = 0.0303 (0.168 sec/step)\n",
            "I0601 12:21:46.471510 140438660523904 learning.py:507] global step 9565: loss = 0.0303 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9566: loss = 0.0820 (0.164 sec/step)\n",
            "I0601 12:21:46.636661 140438660523904 learning.py:507] global step 9566: loss = 0.0820 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9567: loss = 0.1907 (0.189 sec/step)\n",
            "I0601 12:21:46.826784 140438660523904 learning.py:507] global step 9567: loss = 0.1907 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9568: loss = 0.2147 (0.186 sec/step)\n",
            "I0601 12:21:47.014044 140438660523904 learning.py:507] global step 9568: loss = 0.2147 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9569: loss = 0.4731 (0.158 sec/step)\n",
            "I0601 12:21:47.172981 140438660523904 learning.py:507] global step 9569: loss = 0.4731 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9570: loss = 0.0835 (0.172 sec/step)\n",
            "I0601 12:21:47.345966 140438660523904 learning.py:507] global step 9570: loss = 0.0835 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9571: loss = 0.1112 (0.163 sec/step)\n",
            "I0601 12:21:47.510653 140438660523904 learning.py:507] global step 9571: loss = 0.1112 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9572: loss = 0.0708 (0.173 sec/step)\n",
            "I0601 12:21:47.685548 140438660523904 learning.py:507] global step 9572: loss = 0.0708 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9573: loss = 0.0712 (0.181 sec/step)\n",
            "I0601 12:21:47.868386 140438660523904 learning.py:507] global step 9573: loss = 0.0712 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9574: loss = 0.2878 (0.215 sec/step)\n",
            "I0601 12:21:48.084547 140438660523904 learning.py:507] global step 9574: loss = 0.2878 (0.215 sec/step)\n",
            "INFO:tensorflow:global step 9575: loss = 0.2234 (0.151 sec/step)\n",
            "I0601 12:21:48.237265 140438660523904 learning.py:507] global step 9575: loss = 0.2234 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9576: loss = 0.1755 (0.187 sec/step)\n",
            "I0601 12:21:48.425732 140438660523904 learning.py:507] global step 9576: loss = 0.1755 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9577: loss = 0.2496 (0.165 sec/step)\n",
            "I0601 12:21:48.592445 140438660523904 learning.py:507] global step 9577: loss = 0.2496 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9578: loss = 0.3685 (0.161 sec/step)\n",
            "I0601 12:21:48.755008 140438660523904 learning.py:507] global step 9578: loss = 0.3685 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9579: loss = 0.1074 (0.160 sec/step)\n",
            "I0601 12:21:48.915929 140438660523904 learning.py:507] global step 9579: loss = 0.1074 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9580: loss = 0.2177 (0.187 sec/step)\n",
            "I0601 12:21:49.105453 140438660523904 learning.py:507] global step 9580: loss = 0.2177 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9581: loss = 0.0933 (0.166 sec/step)\n",
            "I0601 12:21:49.272676 140438660523904 learning.py:507] global step 9581: loss = 0.0933 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9582: loss = 0.0226 (0.184 sec/step)\n",
            "I0601 12:21:49.458668 140438660523904 learning.py:507] global step 9582: loss = 0.0226 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9583: loss = 0.1477 (0.166 sec/step)\n",
            "I0601 12:21:49.625896 140438660523904 learning.py:507] global step 9583: loss = 0.1477 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9584: loss = 0.1455 (0.212 sec/step)\n",
            "I0601 12:21:49.839019 140438660523904 learning.py:507] global step 9584: loss = 0.1455 (0.212 sec/step)\n",
            "INFO:tensorflow:global step 9585: loss = 0.2557 (0.182 sec/step)\n",
            "I0601 12:21:50.022055 140438660523904 learning.py:507] global step 9585: loss = 0.2557 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9586: loss = 0.1362 (0.193 sec/step)\n",
            "I0601 12:21:50.216434 140438660523904 learning.py:507] global step 9586: loss = 0.1362 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9587: loss = 0.1568 (0.159 sec/step)\n",
            "I0601 12:21:50.377185 140438660523904 learning.py:507] global step 9587: loss = 0.1568 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9588: loss = 0.1559 (0.169 sec/step)\n",
            "I0601 12:21:50.547238 140438660523904 learning.py:507] global step 9588: loss = 0.1559 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9589: loss = 0.1113 (0.165 sec/step)\n",
            "I0601 12:21:50.714065 140438660523904 learning.py:507] global step 9589: loss = 0.1113 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9590: loss = 0.0519 (0.203 sec/step)\n",
            "I0601 12:21:50.918720 140438660523904 learning.py:507] global step 9590: loss = 0.0519 (0.203 sec/step)\n",
            "INFO:tensorflow:global step 9591: loss = 0.0372 (0.175 sec/step)\n",
            "I0601 12:21:51.094809 140438660523904 learning.py:507] global step 9591: loss = 0.0372 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9592: loss = 0.1359 (0.173 sec/step)\n",
            "I0601 12:21:51.269165 140438660523904 learning.py:507] global step 9592: loss = 0.1359 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9593: loss = 0.2111 (0.185 sec/step)\n",
            "I0601 12:21:51.455208 140438660523904 learning.py:507] global step 9593: loss = 0.2111 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9594: loss = 0.0742 (0.167 sec/step)\n",
            "I0601 12:21:51.623758 140438660523904 learning.py:507] global step 9594: loss = 0.0742 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9595: loss = 0.1951 (0.165 sec/step)\n",
            "I0601 12:21:51.790691 140438660523904 learning.py:507] global step 9595: loss = 0.1951 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9596: loss = 0.0638 (0.166 sec/step)\n",
            "I0601 12:21:51.958570 140438660523904 learning.py:507] global step 9596: loss = 0.0638 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9597: loss = 0.0700 (0.186 sec/step)\n",
            "I0601 12:21:52.145482 140438660523904 learning.py:507] global step 9597: loss = 0.0700 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9598: loss = 0.1007 (0.161 sec/step)\n",
            "I0601 12:21:52.307542 140438660523904 learning.py:507] global step 9598: loss = 0.1007 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9599: loss = 0.2221 (0.164 sec/step)\n",
            "I0601 12:21:52.473262 140438660523904 learning.py:507] global step 9599: loss = 0.2221 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9600: loss = 0.0708 (0.188 sec/step)\n",
            "I0601 12:21:52.662383 140438660523904 learning.py:507] global step 9600: loss = 0.0708 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9601: loss = 0.1826 (0.160 sec/step)\n",
            "I0601 12:21:52.823887 140438660523904 learning.py:507] global step 9601: loss = 0.1826 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9602: loss = 0.0336 (0.193 sec/step)\n",
            "I0601 12:21:53.018506 140438660523904 learning.py:507] global step 9602: loss = 0.0336 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9603: loss = 0.0853 (0.174 sec/step)\n",
            "I0601 12:21:53.194131 140438660523904 learning.py:507] global step 9603: loss = 0.0853 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9604: loss = 0.1203 (0.169 sec/step)\n",
            "I0601 12:21:53.365160 140438660523904 learning.py:507] global step 9604: loss = 0.1203 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9605: loss = 0.2061 (0.166 sec/step)\n",
            "I0601 12:21:53.532603 140438660523904 learning.py:507] global step 9605: loss = 0.2061 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9606: loss = 0.1963 (0.193 sec/step)\n",
            "I0601 12:21:53.726927 140438660523904 learning.py:507] global step 9606: loss = 0.1963 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9607: loss = 0.3123 (0.168 sec/step)\n",
            "I0601 12:21:53.896388 140438660523904 learning.py:507] global step 9607: loss = 0.3123 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9608: loss = 0.0847 (0.190 sec/step)\n",
            "I0601 12:21:54.087425 140438660523904 learning.py:507] global step 9608: loss = 0.0847 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9609: loss = 0.2656 (0.173 sec/step)\n",
            "I0601 12:21:54.261415 140438660523904 learning.py:507] global step 9609: loss = 0.2656 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9610: loss = 0.0155 (0.173 sec/step)\n",
            "I0601 12:21:54.435532 140438660523904 learning.py:507] global step 9610: loss = 0.0155 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9611: loss = 0.1789 (0.202 sec/step)\n",
            "I0601 12:21:54.639087 140438660523904 learning.py:507] global step 9611: loss = 0.1789 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 9612: loss = 0.0380 (0.166 sec/step)\n",
            "I0601 12:21:54.806674 140438660523904 learning.py:507] global step 9612: loss = 0.0380 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9613: loss = 0.2755 (0.180 sec/step)\n",
            "I0601 12:21:54.987992 140438660523904 learning.py:507] global step 9613: loss = 0.2755 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9614: loss = 0.0553 (0.159 sec/step)\n",
            "I0601 12:21:55.148699 140438660523904 learning.py:507] global step 9614: loss = 0.0553 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9615: loss = 0.0763 (0.171 sec/step)\n",
            "I0601 12:21:55.321347 140438660523904 learning.py:507] global step 9615: loss = 0.0763 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9616: loss = 0.2926 (0.160 sec/step)\n",
            "I0601 12:21:55.482371 140438660523904 learning.py:507] global step 9616: loss = 0.2926 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9617: loss = 0.0329 (0.168 sec/step)\n",
            "I0601 12:21:55.652401 140438660523904 learning.py:507] global step 9617: loss = 0.0329 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9618: loss = 0.2613 (0.160 sec/step)\n",
            "I0601 12:21:55.813942 140438660523904 learning.py:507] global step 9618: loss = 0.2613 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9619: loss = 0.1495 (0.194 sec/step)\n",
            "I0601 12:21:56.009397 140438660523904 learning.py:507] global step 9619: loss = 0.1495 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9620: loss = 0.0672 (0.155 sec/step)\n",
            "I0601 12:21:56.165953 140438660523904 learning.py:507] global step 9620: loss = 0.0672 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9621: loss = 0.1227 (0.188 sec/step)\n",
            "I0601 12:21:56.355463 140438660523904 learning.py:507] global step 9621: loss = 0.1227 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9622: loss = 0.2955 (0.175 sec/step)\n",
            "I0601 12:21:56.531337 140438660523904 learning.py:507] global step 9622: loss = 0.2955 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9623: loss = 0.1949 (0.182 sec/step)\n",
            "I0601 12:21:56.715084 140438660523904 learning.py:507] global step 9623: loss = 0.1949 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9624: loss = 0.1723 (0.181 sec/step)\n",
            "I0601 12:21:56.897719 140438660523904 learning.py:507] global step 9624: loss = 0.1723 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9625: loss = 0.1115 (0.202 sec/step)\n",
            "I0601 12:21:57.101595 140438660523904 learning.py:507] global step 9625: loss = 0.1115 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 9626: loss = 0.0619 (0.200 sec/step)\n",
            "I0601 12:21:57.303564 140438660523904 learning.py:507] global step 9626: loss = 0.0619 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9627: loss = 0.2587 (0.164 sec/step)\n",
            "I0601 12:21:57.468951 140438660523904 learning.py:507] global step 9627: loss = 0.2587 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9628: loss = 0.0984 (0.181 sec/step)\n",
            "I0601 12:21:57.651932 140438660523904 learning.py:507] global step 9628: loss = 0.0984 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9629: loss = 0.1734 (0.181 sec/step)\n",
            "I0601 12:21:57.834313 140438660523904 learning.py:507] global step 9629: loss = 0.1734 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9630: loss = 0.1992 (0.182 sec/step)\n",
            "I0601 12:21:58.017625 140438660523904 learning.py:507] global step 9630: loss = 0.1992 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9631: loss = 0.1921 (0.211 sec/step)\n",
            "I0601 12:21:58.230577 140438660523904 learning.py:507] global step 9631: loss = 0.1921 (0.211 sec/step)\n",
            "INFO:tensorflow:global step 9632: loss = 0.1314 (0.173 sec/step)\n",
            "I0601 12:21:58.404974 140438660523904 learning.py:507] global step 9632: loss = 0.1314 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9633: loss = 0.0524 (0.162 sec/step)\n",
            "I0601 12:21:58.568324 140438660523904 learning.py:507] global step 9633: loss = 0.0524 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9634: loss = 0.0553 (0.200 sec/step)\n",
            "I0601 12:21:58.769119 140438660523904 learning.py:507] global step 9634: loss = 0.0553 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9635: loss = 0.0446 (0.179 sec/step)\n",
            "I0601 12:21:58.949885 140438660523904 learning.py:507] global step 9635: loss = 0.0446 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9636: loss = 0.1621 (0.167 sec/step)\n",
            "I0601 12:21:59.118508 140438660523904 learning.py:507] global step 9636: loss = 0.1621 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9637: loss = 0.1767 (0.175 sec/step)\n",
            "I0601 12:21:59.294562 140438660523904 learning.py:507] global step 9637: loss = 0.1767 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9638: loss = 0.1459 (0.177 sec/step)\n",
            "I0601 12:21:59.473191 140438660523904 learning.py:507] global step 9638: loss = 0.1459 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9639: loss = 0.0801 (0.170 sec/step)\n",
            "I0601 12:21:59.644861 140438660523904 learning.py:507] global step 9639: loss = 0.0801 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9640: loss = 0.0758 (0.164 sec/step)\n",
            "I0601 12:21:59.810589 140438660523904 learning.py:507] global step 9640: loss = 0.0758 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9641: loss = 0.1666 (0.188 sec/step)\n",
            "I0601 12:21:59.999742 140438660523904 learning.py:507] global step 9641: loss = 0.1666 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9642: loss = 0.1791 (0.148 sec/step)\n",
            "I0601 12:22:00.149284 140438660523904 learning.py:507] global step 9642: loss = 0.1791 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9643: loss = 0.0746 (0.183 sec/step)\n",
            "I0601 12:22:00.334125 140438660523904 learning.py:507] global step 9643: loss = 0.0746 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9644: loss = 0.2460 (0.172 sec/step)\n",
            "I0601 12:22:00.507710 140438660523904 learning.py:507] global step 9644: loss = 0.2460 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9645: loss = 0.0301 (0.177 sec/step)\n",
            "I0601 12:22:00.686309 140438660523904 learning.py:507] global step 9645: loss = 0.0301 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9646: loss = 0.1643 (0.166 sec/step)\n",
            "I0601 12:22:00.853828 140438660523904 learning.py:507] global step 9646: loss = 0.1643 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9647: loss = 0.1768 (0.165 sec/step)\n",
            "I0601 12:22:01.020407 140438660523904 learning.py:507] global step 9647: loss = 0.1768 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9648: loss = 0.1750 (0.169 sec/step)\n",
            "I0601 12:22:01.190461 140438660523904 learning.py:507] global step 9648: loss = 0.1750 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9649: loss = 0.2342 (0.192 sec/step)\n",
            "I0601 12:22:01.383776 140438660523904 learning.py:507] global step 9649: loss = 0.2342 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9650: loss = 0.0277 (0.247 sec/step)\n",
            "I0601 12:22:01.632820 140438660523904 learning.py:507] global step 9650: loss = 0.0277 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9651: loss = 0.0570 (0.170 sec/step)\n",
            "I0601 12:22:01.804548 140438660523904 learning.py:507] global step 9651: loss = 0.0570 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9652: loss = 0.1839 (0.176 sec/step)\n",
            "I0601 12:22:01.982326 140438660523904 learning.py:507] global step 9652: loss = 0.1839 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9653: loss = 0.1100 (0.162 sec/step)\n",
            "I0601 12:22:02.146164 140438660523904 learning.py:507] global step 9653: loss = 0.1100 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9654: loss = 0.0511 (0.177 sec/step)\n",
            "I0601 12:22:02.324939 140438660523904 learning.py:507] global step 9654: loss = 0.0511 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9655: loss = 0.1815 (0.144 sec/step)\n",
            "I0601 12:22:02.469980 140438660523904 learning.py:507] global step 9655: loss = 0.1815 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 9656: loss = 0.1801 (0.184 sec/step)\n",
            "I0601 12:22:02.655935 140438660523904 learning.py:507] global step 9656: loss = 0.1801 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9657: loss = 0.1739 (0.166 sec/step)\n",
            "I0601 12:22:02.823711 140438660523904 learning.py:507] global step 9657: loss = 0.1739 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9658: loss = 0.0828 (0.181 sec/step)\n",
            "I0601 12:22:03.006597 140438660523904 learning.py:507] global step 9658: loss = 0.0828 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9659: loss = 0.2930 (0.177 sec/step)\n",
            "I0601 12:22:03.185398 140438660523904 learning.py:507] global step 9659: loss = 0.2930 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9660: loss = 0.1064 (0.187 sec/step)\n",
            "I0601 12:22:03.373912 140438660523904 learning.py:507] global step 9660: loss = 0.1064 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9661: loss = 0.0860 (0.178 sec/step)\n",
            "I0601 12:22:03.553623 140438660523904 learning.py:507] global step 9661: loss = 0.0860 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9662: loss = 0.3059 (0.175 sec/step)\n",
            "I0601 12:22:03.729690 140438660523904 learning.py:507] global step 9662: loss = 0.3059 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9663: loss = 0.1040 (0.176 sec/step)\n",
            "I0601 12:22:03.907464 140438660523904 learning.py:507] global step 9663: loss = 0.1040 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9664: loss = 0.1699 (0.174 sec/step)\n",
            "I0601 12:22:04.082860 140438660523904 learning.py:507] global step 9664: loss = 0.1699 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9665: loss = 0.0937 (0.171 sec/step)\n",
            "I0601 12:22:04.255136 140438660523904 learning.py:507] global step 9665: loss = 0.0937 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9666: loss = 0.0340 (0.157 sec/step)\n",
            "I0601 12:22:04.413940 140438660523904 learning.py:507] global step 9666: loss = 0.0340 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9667: loss = 0.0483 (0.195 sec/step)\n",
            "I0601 12:22:04.610093 140438660523904 learning.py:507] global step 9667: loss = 0.0483 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 9668: loss = 0.0260 (0.171 sec/step)\n",
            "I0601 12:22:04.782794 140438660523904 learning.py:507] global step 9668: loss = 0.0260 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9669: loss = 0.0374 (0.186 sec/step)\n",
            "I0601 12:22:04.969879 140438660523904 learning.py:507] global step 9669: loss = 0.0374 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9670: loss = 0.0981 (0.174 sec/step)\n",
            "I0601 12:22:05.145358 140438660523904 learning.py:507] global step 9670: loss = 0.0981 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9671: loss = 0.2029 (0.183 sec/step)\n",
            "I0601 12:22:05.329716 140438660523904 learning.py:507] global step 9671: loss = 0.2029 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9672: loss = 0.5018 (0.160 sec/step)\n",
            "I0601 12:22:05.491019 140438660523904 learning.py:507] global step 9672: loss = 0.5018 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9673: loss = 0.1329 (0.180 sec/step)\n",
            "I0601 12:22:05.672673 140438660523904 learning.py:507] global step 9673: loss = 0.1329 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9674: loss = 0.1856 (0.211 sec/step)\n",
            "I0601 12:22:05.884953 140438660523904 learning.py:507] global step 9674: loss = 0.1856 (0.211 sec/step)\n",
            "INFO:tensorflow:global step 9675: loss = 0.0961 (0.187 sec/step)\n",
            "I0601 12:22:06.073387 140438660523904 learning.py:507] global step 9675: loss = 0.0961 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9676: loss = 0.1760 (0.181 sec/step)\n",
            "I0601 12:22:06.257120 140438660523904 learning.py:507] global step 9676: loss = 0.1760 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9677: loss = 0.1576 (0.170 sec/step)\n",
            "I0601 12:22:06.428689 140438660523904 learning.py:507] global step 9677: loss = 0.1576 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9678: loss = 0.1175 (0.190 sec/step)\n",
            "I0601 12:22:06.619967 140438660523904 learning.py:507] global step 9678: loss = 0.1175 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9679: loss = 0.1318 (0.194 sec/step)\n",
            "I0601 12:22:06.814817 140438660523904 learning.py:507] global step 9679: loss = 0.1318 (0.194 sec/step)\n",
            "INFO:tensorflow:global step 9680: loss = 0.2957 (0.161 sec/step)\n",
            "I0601 12:22:06.977566 140438660523904 learning.py:507] global step 9680: loss = 0.2957 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9681: loss = 0.1064 (0.195 sec/step)\n",
            "I0601 12:22:07.174814 140438660523904 learning.py:507] global step 9681: loss = 0.1064 (0.195 sec/step)\n",
            "INFO:tensorflow:global step 9682: loss = 0.1135 (0.188 sec/step)\n",
            "I0601 12:22:07.364496 140438660523904 learning.py:507] global step 9682: loss = 0.1135 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9683: loss = 0.1385 (0.159 sec/step)\n",
            "I0601 12:22:07.524583 140438660523904 learning.py:507] global step 9683: loss = 0.1385 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9684: loss = 0.0631 (0.170 sec/step)\n",
            "I0601 12:22:07.696036 140438660523904 learning.py:507] global step 9684: loss = 0.0631 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9685: loss = 0.0955 (0.162 sec/step)\n",
            "I0601 12:22:07.859193 140438660523904 learning.py:507] global step 9685: loss = 0.0955 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9686: loss = 0.0949 (0.174 sec/step)\n",
            "I0601 12:22:08.035432 140438660523904 learning.py:507] global step 9686: loss = 0.0949 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9687: loss = 0.0683 (0.162 sec/step)\n",
            "I0601 12:22:08.198632 140438660523904 learning.py:507] global step 9687: loss = 0.0683 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9688: loss = 0.2483 (0.179 sec/step)\n",
            "I0601 12:22:08.379400 140438660523904 learning.py:507] global step 9688: loss = 0.2483 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9689: loss = 0.3554 (0.182 sec/step)\n",
            "I0601 12:22:08.562765 140438660523904 learning.py:507] global step 9689: loss = 0.3554 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9690: loss = 0.2482 (0.163 sec/step)\n",
            "I0601 12:22:08.727641 140438660523904 learning.py:507] global step 9690: loss = 0.2482 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9691: loss = 0.0873 (0.174 sec/step)\n",
            "I0601 12:22:08.903095 140438660523904 learning.py:507] global step 9691: loss = 0.0873 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9692: loss = 0.2151 (0.201 sec/step)\n",
            "I0601 12:22:09.105037 140438660523904 learning.py:507] global step 9692: loss = 0.2151 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 9693: loss = 0.1022 (0.167 sec/step)\n",
            "I0601 12:22:09.273792 140438660523904 learning.py:507] global step 9693: loss = 0.1022 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9694: loss = 0.0429 (0.185 sec/step)\n",
            "I0601 12:22:09.459798 140438660523904 learning.py:507] global step 9694: loss = 0.0429 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9695: loss = 0.1193 (0.153 sec/step)\n",
            "I0601 12:22:09.614152 140438660523904 learning.py:507] global step 9695: loss = 0.1193 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9696: loss = 0.0524 (0.165 sec/step)\n",
            "I0601 12:22:09.780815 140438660523904 learning.py:507] global step 9696: loss = 0.0524 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9697: loss = 0.1711 (0.222 sec/step)\n",
            "I0601 12:22:10.003866 140438660523904 learning.py:507] global step 9697: loss = 0.1711 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9698: loss = 0.1044 (0.183 sec/step)\n",
            "I0601 12:22:10.187928 140438660523904 learning.py:507] global step 9698: loss = 0.1044 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9699: loss = 0.0774 (0.165 sec/step)\n",
            "I0601 12:22:10.354166 140438660523904 learning.py:507] global step 9699: loss = 0.0774 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9700: loss = 0.1067 (0.179 sec/step)\n",
            "I0601 12:22:10.534338 140438660523904 learning.py:507] global step 9700: loss = 0.1067 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9701: loss = 0.0662 (0.162 sec/step)\n",
            "I0601 12:22:10.697796 140438660523904 learning.py:507] global step 9701: loss = 0.0662 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9702: loss = 0.1291 (0.152 sec/step)\n",
            "I0601 12:22:10.851464 140438660523904 learning.py:507] global step 9702: loss = 0.1291 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9703: loss = 0.0474 (0.169 sec/step)\n",
            "I0601 12:22:11.021725 140438660523904 learning.py:507] global step 9703: loss = 0.0474 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9704: loss = 0.0953 (0.191 sec/step)\n",
            "I0601 12:22:11.213928 140438660523904 learning.py:507] global step 9704: loss = 0.0953 (0.191 sec/step)\n",
            "INFO:tensorflow:global step 9705: loss = 0.1438 (0.174 sec/step)\n",
            "I0601 12:22:11.389699 140438660523904 learning.py:507] global step 9705: loss = 0.1438 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9706: loss = 0.1323 (0.151 sec/step)\n",
            "I0601 12:22:11.541805 140438660523904 learning.py:507] global step 9706: loss = 0.1323 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9707: loss = 0.0222 (0.174 sec/step)\n",
            "I0601 12:22:11.718490 140438660523904 learning.py:507] global step 9707: loss = 0.0222 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9708: loss = 0.1593 (0.154 sec/step)\n",
            "I0601 12:22:11.874652 140438660523904 learning.py:507] global step 9708: loss = 0.1593 (0.154 sec/step)\n",
            "INFO:tensorflow:global step 9709: loss = 0.0790 (0.153 sec/step)\n",
            "I0601 12:22:12.029418 140438660523904 learning.py:507] global step 9709: loss = 0.0790 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9710: loss = 0.3652 (0.174 sec/step)\n",
            "I0601 12:22:12.204465 140438660523904 learning.py:507] global step 9710: loss = 0.3652 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9711: loss = 0.1658 (0.183 sec/step)\n",
            "I0601 12:22:12.388670 140438660523904 learning.py:507] global step 9711: loss = 0.1658 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9712: loss = 0.1058 (0.177 sec/step)\n",
            "I0601 12:22:12.566602 140438660523904 learning.py:507] global step 9712: loss = 0.1058 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9713: loss = 0.1806 (0.158 sec/step)\n",
            "I0601 12:22:12.725726 140438660523904 learning.py:507] global step 9713: loss = 0.1806 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9714: loss = 0.0393 (0.158 sec/step)\n",
            "I0601 12:22:12.885529 140438660523904 learning.py:507] global step 9714: loss = 0.0393 (0.158 sec/step)\n",
            "INFO:tensorflow:global step 9715: loss = 0.1819 (0.164 sec/step)\n",
            "I0601 12:22:13.051300 140438660523904 learning.py:507] global step 9715: loss = 0.1819 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9716: loss = 0.0708 (0.174 sec/step)\n",
            "I0601 12:22:13.226729 140438660523904 learning.py:507] global step 9716: loss = 0.0708 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9717: loss = 0.1476 (0.181 sec/step)\n",
            "I0601 12:22:13.408621 140438660523904 learning.py:507] global step 9717: loss = 0.1476 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9718: loss = 0.2316 (0.179 sec/step)\n",
            "I0601 12:22:13.588621 140438660523904 learning.py:507] global step 9718: loss = 0.2316 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9719: loss = 0.0690 (0.168 sec/step)\n",
            "I0601 12:22:13.758475 140438660523904 learning.py:507] global step 9719: loss = 0.0690 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9720: loss = 0.0384 (0.162 sec/step)\n",
            "I0601 12:22:13.921985 140438660523904 learning.py:507] global step 9720: loss = 0.0384 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9721: loss = 0.1584 (0.168 sec/step)\n",
            "I0601 12:22:14.091263 140438660523904 learning.py:507] global step 9721: loss = 0.1584 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9722: loss = 0.0417 (0.174 sec/step)\n",
            "I0601 12:22:14.267050 140438660523904 learning.py:507] global step 9722: loss = 0.0417 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9723: loss = 0.0887 (0.176 sec/step)\n",
            "I0601 12:22:14.444411 140438660523904 learning.py:507] global step 9723: loss = 0.0887 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9724: loss = 0.2396 (0.182 sec/step)\n",
            "I0601 12:22:14.627469 140438660523904 learning.py:507] global step 9724: loss = 0.2396 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9725: loss = 0.1850 (0.175 sec/step)\n",
            "I0601 12:22:14.803941 140438660523904 learning.py:507] global step 9725: loss = 0.1850 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9726: loss = 0.3049 (0.168 sec/step)\n",
            "I0601 12:22:14.973362 140438660523904 learning.py:507] global step 9726: loss = 0.3049 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9727: loss = 0.1088 (0.153 sec/step)\n",
            "I0601 12:22:15.128581 140438660523904 learning.py:507] global step 9727: loss = 0.1088 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9728: loss = 0.0969 (0.173 sec/step)\n",
            "I0601 12:22:15.302857 140438660523904 learning.py:507] global step 9728: loss = 0.0969 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9729: loss = 0.0538 (0.169 sec/step)\n",
            "I0601 12:22:15.472814 140438660523904 learning.py:507] global step 9729: loss = 0.0538 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9730: loss = 0.1378 (0.202 sec/step)\n",
            "I0601 12:22:15.676026 140438660523904 learning.py:507] global step 9730: loss = 0.1378 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 9731: loss = 0.2072 (0.176 sec/step)\n",
            "I0601 12:22:15.853343 140438660523904 learning.py:507] global step 9731: loss = 0.2072 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9732: loss = 0.0208 (0.170 sec/step)\n",
            "I0601 12:22:16.024392 140438660523904 learning.py:507] global step 9732: loss = 0.0208 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9733: loss = 0.0675 (0.162 sec/step)\n",
            "I0601 12:22:16.187644 140438660523904 learning.py:507] global step 9733: loss = 0.0675 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9734: loss = 0.2169 (0.178 sec/step)\n",
            "I0601 12:22:16.366738 140438660523904 learning.py:507] global step 9734: loss = 0.2169 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9735: loss = 0.0707 (0.170 sec/step)\n",
            "I0601 12:22:16.537642 140438660523904 learning.py:507] global step 9735: loss = 0.0707 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9736: loss = 0.3088 (0.159 sec/step)\n",
            "I0601 12:22:16.697979 140438660523904 learning.py:507] global step 9736: loss = 0.3088 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9737: loss = 0.1208 (0.168 sec/step)\n",
            "I0601 12:22:16.867722 140438660523904 learning.py:507] global step 9737: loss = 0.1208 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9738: loss = 0.2737 (0.186 sec/step)\n",
            "I0601 12:22:17.054974 140438660523904 learning.py:507] global step 9738: loss = 0.2737 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9739: loss = 0.1116 (0.164 sec/step)\n",
            "I0601 12:22:17.220133 140438660523904 learning.py:507] global step 9739: loss = 0.1116 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9740: loss = 0.1708 (0.181 sec/step)\n",
            "I0601 12:22:17.402059 140438660523904 learning.py:507] global step 9740: loss = 0.1708 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9741: loss = 0.0460 (0.155 sec/step)\n",
            "I0601 12:22:17.558195 140438660523904 learning.py:507] global step 9741: loss = 0.0460 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9742: loss = 0.1366 (0.180 sec/step)\n",
            "I0601 12:22:17.739176 140438660523904 learning.py:507] global step 9742: loss = 0.1366 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9743: loss = 0.0285 (0.179 sec/step)\n",
            "I0601 12:22:17.919104 140438660523904 learning.py:507] global step 9743: loss = 0.0285 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9744: loss = 0.1148 (0.176 sec/step)\n",
            "I0601 12:22:18.096812 140438660523904 learning.py:507] global step 9744: loss = 0.1148 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9745: loss = 0.0568 (0.162 sec/step)\n",
            "I0601 12:22:18.260055 140438660523904 learning.py:507] global step 9745: loss = 0.0568 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9746: loss = 0.0505 (0.169 sec/step)\n",
            "I0601 12:22:18.429974 140438660523904 learning.py:507] global step 9746: loss = 0.0505 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9747: loss = 0.2233 (0.208 sec/step)\n",
            "I0601 12:22:18.639408 140438660523904 learning.py:507] global step 9747: loss = 0.2233 (0.208 sec/step)\n",
            "INFO:tensorflow:global step 9748: loss = 0.2360 (0.198 sec/step)\n",
            "I0601 12:22:18.838536 140438660523904 learning.py:507] global step 9748: loss = 0.2360 (0.198 sec/step)\n",
            "INFO:tensorflow:global step 9749: loss = 0.0181 (0.174 sec/step)\n",
            "I0601 12:22:19.013808 140438660523904 learning.py:507] global step 9749: loss = 0.0181 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9750: loss = 0.4842 (0.170 sec/step)\n",
            "I0601 12:22:19.185641 140438660523904 learning.py:507] global step 9750: loss = 0.4842 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9751: loss = 0.0287 (0.156 sec/step)\n",
            "I0601 12:22:19.343001 140438660523904 learning.py:507] global step 9751: loss = 0.0287 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9752: loss = 0.2894 (0.177 sec/step)\n",
            "I0601 12:22:19.521793 140438660523904 learning.py:507] global step 9752: loss = 0.2894 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9753: loss = 0.1884 (0.171 sec/step)\n",
            "I0601 12:22:19.694017 140438660523904 learning.py:507] global step 9753: loss = 0.1884 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9754: loss = 0.1305 (0.209 sec/step)\n",
            "I0601 12:22:19.904972 140438660523904 learning.py:507] global step 9754: loss = 0.1305 (0.209 sec/step)\n",
            "INFO:tensorflow:global step 9755: loss = 0.0352 (0.177 sec/step)\n",
            "I0601 12:22:20.084053 140438660523904 learning.py:507] global step 9755: loss = 0.0352 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9756: loss = 0.0569 (0.166 sec/step)\n",
            "I0601 12:22:20.251839 140438660523904 learning.py:507] global step 9756: loss = 0.0569 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9757: loss = 0.0976 (0.153 sec/step)\n",
            "I0601 12:22:20.406603 140438660523904 learning.py:507] global step 9757: loss = 0.0976 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9758: loss = 0.0223 (0.175 sec/step)\n",
            "I0601 12:22:20.583014 140438660523904 learning.py:507] global step 9758: loss = 0.0223 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9759: loss = 0.0309 (0.161 sec/step)\n",
            "I0601 12:22:20.745177 140438660523904 learning.py:507] global step 9759: loss = 0.0309 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9760: loss = 0.1915 (0.181 sec/step)\n",
            "I0601 12:22:20.927184 140438660523904 learning.py:507] global step 9760: loss = 0.1915 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9761: loss = 0.0587 (0.166 sec/step)\n",
            "I0601 12:22:21.094750 140438660523904 learning.py:507] global step 9761: loss = 0.0587 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9762: loss = 0.0292 (0.170 sec/step)\n",
            "I0601 12:22:21.265923 140438660523904 learning.py:507] global step 9762: loss = 0.0292 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9763: loss = 0.2206 (0.178 sec/step)\n",
            "I0601 12:22:21.445676 140438660523904 learning.py:507] global step 9763: loss = 0.2206 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9764: loss = 0.2399 (0.175 sec/step)\n",
            "I0601 12:22:21.622759 140438660523904 learning.py:507] global step 9764: loss = 0.2399 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9765: loss = 0.1535 (0.171 sec/step)\n",
            "I0601 12:22:21.795428 140438660523904 learning.py:507] global step 9765: loss = 0.1535 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9766: loss = 0.0255 (0.153 sec/step)\n",
            "I0601 12:22:21.949844 140438660523904 learning.py:507] global step 9766: loss = 0.0255 (0.153 sec/step)\n",
            "INFO:tensorflow:global step 9767: loss = 0.3035 (0.180 sec/step)\n",
            "I0601 12:22:22.131388 140438660523904 learning.py:507] global step 9767: loss = 0.3035 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9768: loss = 0.1348 (0.168 sec/step)\n",
            "I0601 12:22:22.300932 140438660523904 learning.py:507] global step 9768: loss = 0.1348 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9769: loss = 0.1175 (0.175 sec/step)\n",
            "I0601 12:22:22.477438 140438660523904 learning.py:507] global step 9769: loss = 0.1175 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9770: loss = 0.0140 (0.167 sec/step)\n",
            "I0601 12:22:22.646045 140438660523904 learning.py:507] global step 9770: loss = 0.0140 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9771: loss = 0.1612 (0.174 sec/step)\n",
            "I0601 12:22:22.821530 140438660523904 learning.py:507] global step 9771: loss = 0.1612 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9772: loss = 0.1470 (0.168 sec/step)\n",
            "I0601 12:22:22.990483 140438660523904 learning.py:507] global step 9772: loss = 0.1470 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9773: loss = 0.1855 (0.177 sec/step)\n",
            "I0601 12:22:23.168731 140438660523904 learning.py:507] global step 9773: loss = 0.1855 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9774: loss = 0.2106 (0.182 sec/step)\n",
            "I0601 12:22:23.352296 140438660523904 learning.py:507] global step 9774: loss = 0.2106 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9775: loss = 0.2206 (0.193 sec/step)\n",
            "I0601 12:22:23.546425 140438660523904 learning.py:507] global step 9775: loss = 0.2206 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9776: loss = 0.0571 (0.181 sec/step)\n",
            "I0601 12:22:23.729193 140438660523904 learning.py:507] global step 9776: loss = 0.0571 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9777: loss = 0.1231 (0.168 sec/step)\n",
            "I0601 12:22:23.898424 140438660523904 learning.py:507] global step 9777: loss = 0.1231 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9778: loss = 0.1437 (0.177 sec/step)\n",
            "I0601 12:22:24.077363 140438660523904 learning.py:507] global step 9778: loss = 0.1437 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9779: loss = 0.0849 (0.155 sec/step)\n",
            "I0601 12:22:24.233966 140438660523904 learning.py:507] global step 9779: loss = 0.0849 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9780: loss = 0.1371 (0.165 sec/step)\n",
            "I0601 12:22:24.400068 140438660523904 learning.py:507] global step 9780: loss = 0.1371 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9781: loss = 4.1770 (0.177 sec/step)\n",
            "I0601 12:22:24.578171 140438660523904 learning.py:507] global step 9781: loss = 4.1770 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9782: loss = 0.0910 (0.177 sec/step)\n",
            "I0601 12:22:24.756204 140438660523904 learning.py:507] global step 9782: loss = 0.0910 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9783: loss = 0.1172 (0.176 sec/step)\n",
            "I0601 12:22:24.933738 140438660523904 learning.py:507] global step 9783: loss = 0.1172 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9784: loss = 0.0186 (0.169 sec/step)\n",
            "I0601 12:22:25.103942 140438660523904 learning.py:507] global step 9784: loss = 0.0186 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9785: loss = 0.1758 (0.173 sec/step)\n",
            "I0601 12:22:25.278320 140438660523904 learning.py:507] global step 9785: loss = 0.1758 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9786: loss = 0.1392 (0.156 sec/step)\n",
            "I0601 12:22:25.435931 140438660523904 learning.py:507] global step 9786: loss = 0.1392 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9787: loss = 0.0397 (0.167 sec/step)\n",
            "I0601 12:22:25.604788 140438660523904 learning.py:507] global step 9787: loss = 0.0397 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9788: loss = 0.1348 (0.163 sec/step)\n",
            "I0601 12:22:25.769073 140438660523904 learning.py:507] global step 9788: loss = 0.1348 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9789: loss = 0.1334 (0.177 sec/step)\n",
            "I0601 12:22:25.947018 140438660523904 learning.py:507] global step 9789: loss = 0.1334 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9790: loss = 0.2900 (0.178 sec/step)\n",
            "I0601 12:22:26.126371 140438660523904 learning.py:507] global step 9790: loss = 0.2900 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9791: loss = 0.0588 (0.172 sec/step)\n",
            "I0601 12:22:26.301717 140438660523904 learning.py:507] global step 9791: loss = 0.0588 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9792: loss = 0.0811 (0.180 sec/step)\n",
            "I0601 12:22:26.483338 140438660523904 learning.py:507] global step 9792: loss = 0.0811 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9793: loss = 0.0721 (0.188 sec/step)\n",
            "I0601 12:22:26.672535 140438660523904 learning.py:507] global step 9793: loss = 0.0721 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9794: loss = 0.1249 (0.196 sec/step)\n",
            "I0601 12:22:26.869808 140438660523904 learning.py:507] global step 9794: loss = 0.1249 (0.196 sec/step)\n",
            "INFO:tensorflow:global step 9795: loss = 0.2718 (0.179 sec/step)\n",
            "I0601 12:22:27.050353 140438660523904 learning.py:507] global step 9795: loss = 0.2718 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9796: loss = 0.1222 (0.152 sec/step)\n",
            "I0601 12:22:27.203570 140438660523904 learning.py:507] global step 9796: loss = 0.1222 (0.152 sec/step)\n",
            "INFO:tensorflow:global step 9797: loss = 0.1312 (0.162 sec/step)\n",
            "I0601 12:22:27.366614 140438660523904 learning.py:507] global step 9797: loss = 0.1312 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9798: loss = 0.1457 (0.190 sec/step)\n",
            "I0601 12:22:27.558397 140438660523904 learning.py:507] global step 9798: loss = 0.1457 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9799: loss = 0.1237 (0.202 sec/step)\n",
            "I0601 12:22:27.761844 140438660523904 learning.py:507] global step 9799: loss = 0.1237 (0.202 sec/step)\n",
            "INFO:tensorflow:global step 9800: loss = 0.1284 (0.164 sec/step)\n",
            "I0601 12:22:27.927347 140438660523904 learning.py:507] global step 9800: loss = 0.1284 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9801: loss = 0.1715 (0.184 sec/step)\n",
            "I0601 12:22:28.112433 140438660523904 learning.py:507] global step 9801: loss = 0.1715 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9802: loss = 0.1538 (0.168 sec/step)\n",
            "I0601 12:22:28.281565 140438660523904 learning.py:507] global step 9802: loss = 0.1538 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9803: loss = 0.0497 (0.155 sec/step)\n",
            "I0601 12:22:28.438278 140438660523904 learning.py:507] global step 9803: loss = 0.0497 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9804: loss = 0.0444 (0.171 sec/step)\n",
            "I0601 12:22:28.610712 140438660523904 learning.py:507] global step 9804: loss = 0.0444 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9805: loss = 0.0186 (0.159 sec/step)\n",
            "I0601 12:22:28.771341 140438660523904 learning.py:507] global step 9805: loss = 0.0186 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9806: loss = 0.2959 (0.175 sec/step)\n",
            "I0601 12:22:28.947221 140438660523904 learning.py:507] global step 9806: loss = 0.2959 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9807: loss = 0.1989 (0.182 sec/step)\n",
            "I0601 12:22:29.130743 140438660523904 learning.py:507] global step 9807: loss = 0.1989 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9808: loss = 0.3224 (0.221 sec/step)\n",
            "I0601 12:22:29.353024 140438660523904 learning.py:507] global step 9808: loss = 0.3224 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9809: loss = 0.0670 (0.189 sec/step)\n",
            "I0601 12:22:29.543408 140438660523904 learning.py:507] global step 9809: loss = 0.0670 (0.189 sec/step)\n",
            "INFO:tensorflow:global step 9810: loss = 0.0554 (0.175 sec/step)\n",
            "I0601 12:22:29.719745 140438660523904 learning.py:507] global step 9810: loss = 0.0554 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9811: loss = 0.0761 (0.164 sec/step)\n",
            "I0601 12:22:29.884807 140438660523904 learning.py:507] global step 9811: loss = 0.0761 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9812: loss = 0.0749 (0.161 sec/step)\n",
            "I0601 12:22:30.047727 140438660523904 learning.py:507] global step 9812: loss = 0.0749 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9813: loss = 0.0604 (0.161 sec/step)\n",
            "I0601 12:22:30.209769 140438660523904 learning.py:507] global step 9813: loss = 0.0604 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9814: loss = 0.0491 (0.188 sec/step)\n",
            "I0601 12:22:30.400675 140438660523904 learning.py:507] global step 9814: loss = 0.0491 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9815: loss = 0.1696 (0.186 sec/step)\n",
            "I0601 12:22:30.588398 140438660523904 learning.py:507] global step 9815: loss = 0.1696 (0.186 sec/step)\n",
            "INFO:tensorflow:global step 9816: loss = 0.0585 (0.182 sec/step)\n",
            "I0601 12:22:30.771608 140438660523904 learning.py:507] global step 9816: loss = 0.0585 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9817: loss = 0.0733 (0.163 sec/step)\n",
            "I0601 12:22:30.936380 140438660523904 learning.py:507] global step 9817: loss = 0.0733 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9818: loss = 0.0998 (0.179 sec/step)\n",
            "I0601 12:22:31.116950 140438660523904 learning.py:507] global step 9818: loss = 0.0998 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9819: loss = 0.1485 (0.184 sec/step)\n",
            "I0601 12:22:31.302682 140438660523904 learning.py:507] global step 9819: loss = 0.1485 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9820: loss = 0.0549 (0.173 sec/step)\n",
            "I0601 12:22:31.477441 140438660523904 learning.py:507] global step 9820: loss = 0.0549 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9821: loss = 0.0740 (0.174 sec/step)\n",
            "I0601 12:22:31.652967 140438660523904 learning.py:507] global step 9821: loss = 0.0740 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9822: loss = 0.0820 (0.159 sec/step)\n",
            "I0601 12:22:31.813126 140438660523904 learning.py:507] global step 9822: loss = 0.0820 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9823: loss = 0.0791 (0.171 sec/step)\n",
            "I0601 12:22:31.985818 140438660523904 learning.py:507] global step 9823: loss = 0.0791 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9824: loss = 0.2891 (0.164 sec/step)\n",
            "I0601 12:22:32.151487 140438660523904 learning.py:507] global step 9824: loss = 0.2891 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9825: loss = 0.0179 (0.177 sec/step)\n",
            "I0601 12:22:32.329674 140438660523904 learning.py:507] global step 9825: loss = 0.0179 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9826: loss = 0.0511 (0.165 sec/step)\n",
            "I0601 12:22:32.496123 140438660523904 learning.py:507] global step 9826: loss = 0.0511 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9827: loss = 0.0497 (0.190 sec/step)\n",
            "I0601 12:22:32.687634 140438660523904 learning.py:507] global step 9827: loss = 0.0497 (0.190 sec/step)\n",
            "INFO:tensorflow:global step 9828: loss = 0.0343 (0.176 sec/step)\n",
            "I0601 12:22:32.865350 140438660523904 learning.py:507] global step 9828: loss = 0.0343 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9829: loss = 0.1069 (0.174 sec/step)\n",
            "I0601 12:22:33.041460 140438660523904 learning.py:507] global step 9829: loss = 0.1069 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9830: loss = 0.1183 (0.169 sec/step)\n",
            "I0601 12:22:33.212018 140438660523904 learning.py:507] global step 9830: loss = 0.1183 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9831: loss = 0.1847 (0.173 sec/step)\n",
            "I0601 12:22:33.386894 140438660523904 learning.py:507] global step 9831: loss = 0.1847 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9832: loss = 0.0170 (0.203 sec/step)\n",
            "I0601 12:22:33.591087 140438660523904 learning.py:507] global step 9832: loss = 0.0170 (0.203 sec/step)\n",
            "INFO:tensorflow:global step 9833: loss = 0.1082 (0.160 sec/step)\n",
            "I0601 12:22:33.752849 140438660523904 learning.py:507] global step 9833: loss = 0.1082 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9834: loss = 0.0664 (0.168 sec/step)\n",
            "I0601 12:22:33.922273 140438660523904 learning.py:507] global step 9834: loss = 0.0664 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9835: loss = 0.0665 (0.148 sec/step)\n",
            "I0601 12:22:34.071732 140438660523904 learning.py:507] global step 9835: loss = 0.0665 (0.148 sec/step)\n",
            "INFO:tensorflow:global step 9836: loss = 0.1243 (0.166 sec/step)\n",
            "I0601 12:22:34.239357 140438660523904 learning.py:507] global step 9836: loss = 0.1243 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9837: loss = 0.0816 (0.161 sec/step)\n",
            "I0601 12:22:34.402179 140438660523904 learning.py:507] global step 9837: loss = 0.0816 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9838: loss = 0.0522 (0.249 sec/step)\n",
            "I0601 12:22:34.652708 140438660523904 learning.py:507] global step 9838: loss = 0.0522 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9839: loss = 0.1167 (0.180 sec/step)\n",
            "I0601 12:22:34.834604 140438660523904 learning.py:507] global step 9839: loss = 0.1167 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9840: loss = 0.1309 (0.183 sec/step)\n",
            "I0601 12:22:35.018619 140438660523904 learning.py:507] global step 9840: loss = 0.1309 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9841: loss = 0.1014 (0.170 sec/step)\n",
            "I0601 12:22:35.189811 140438660523904 learning.py:507] global step 9841: loss = 0.1014 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9842: loss = 0.1192 (0.177 sec/step)\n",
            "I0601 12:22:35.368364 140438660523904 learning.py:507] global step 9842: loss = 0.1192 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9843: loss = 0.0406 (0.185 sec/step)\n",
            "I0601 12:22:35.554975 140438660523904 learning.py:507] global step 9843: loss = 0.0406 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9844: loss = 0.0811 (0.171 sec/step)\n",
            "I0601 12:22:35.727687 140438660523904 learning.py:507] global step 9844: loss = 0.0811 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9845: loss = 0.1959 (0.157 sec/step)\n",
            "I0601 12:22:35.886599 140438660523904 learning.py:507] global step 9845: loss = 0.1959 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9846: loss = 0.2200 (0.169 sec/step)\n",
            "I0601 12:22:36.057414 140438660523904 learning.py:507] global step 9846: loss = 0.2200 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9847: loss = 0.1581 (0.172 sec/step)\n",
            "I0601 12:22:36.231319 140438660523904 learning.py:507] global step 9847: loss = 0.1581 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9848: loss = 0.1370 (0.175 sec/step)\n",
            "I0601 12:22:36.407738 140438660523904 learning.py:507] global step 9848: loss = 0.1370 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9849: loss = 0.1104 (0.167 sec/step)\n",
            "I0601 12:22:36.575644 140438660523904 learning.py:507] global step 9849: loss = 0.1104 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9850: loss = 0.0580 (0.200 sec/step)\n",
            "I0601 12:22:36.776633 140438660523904 learning.py:507] global step 9850: loss = 0.0580 (0.200 sec/step)\n",
            "INFO:tensorflow:global step 9851: loss = 0.1622 (0.157 sec/step)\n",
            "I0601 12:22:36.935513 140438660523904 learning.py:507] global step 9851: loss = 0.1622 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9852: loss = 0.0440 (0.178 sec/step)\n",
            "I0601 12:22:37.115976 140438660523904 learning.py:507] global step 9852: loss = 0.0440 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9853: loss = 0.1512 (0.163 sec/step)\n",
            "I0601 12:22:37.280365 140438660523904 learning.py:507] global step 9853: loss = 0.1512 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9854: loss = 0.1131 (0.182 sec/step)\n",
            "I0601 12:22:37.464125 140438660523904 learning.py:507] global step 9854: loss = 0.1131 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9855: loss = 0.0275 (0.184 sec/step)\n",
            "I0601 12:22:37.649541 140438660523904 learning.py:507] global step 9855: loss = 0.0275 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9856: loss = 0.2967 (0.183 sec/step)\n",
            "I0601 12:22:37.834170 140438660523904 learning.py:507] global step 9856: loss = 0.2967 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9857: loss = 0.0730 (0.173 sec/step)\n",
            "I0601 12:22:38.008360 140438660523904 learning.py:507] global step 9857: loss = 0.0730 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9858: loss = 0.0596 (0.164 sec/step)\n",
            "I0601 12:22:38.174165 140438660523904 learning.py:507] global step 9858: loss = 0.0596 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9859: loss = 0.2602 (0.168 sec/step)\n",
            "I0601 12:22:38.343928 140438660523904 learning.py:507] global step 9859: loss = 0.2602 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9860: loss = 0.1505 (0.179 sec/step)\n",
            "I0601 12:22:38.524287 140438660523904 learning.py:507] global step 9860: loss = 0.1505 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9861: loss = 0.0589 (0.192 sec/step)\n",
            "I0601 12:22:38.718024 140438660523904 learning.py:507] global step 9861: loss = 0.0589 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9862: loss = 0.0517 (0.169 sec/step)\n",
            "I0601 12:22:38.888850 140438660523904 learning.py:507] global step 9862: loss = 0.0517 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9863: loss = 0.0897 (0.180 sec/step)\n",
            "I0601 12:22:39.070732 140438660523904 learning.py:507] global step 9863: loss = 0.0897 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9864: loss = 0.1614 (0.167 sec/step)\n",
            "I0601 12:22:39.239635 140438660523904 learning.py:507] global step 9864: loss = 0.1614 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9865: loss = 0.0534 (0.151 sec/step)\n",
            "I0601 12:22:39.392169 140438660523904 learning.py:507] global step 9865: loss = 0.0534 (0.151 sec/step)\n",
            "INFO:tensorflow:global step 9866: loss = 0.0842 (0.159 sec/step)\n",
            "I0601 12:22:39.552585 140438660523904 learning.py:507] global step 9866: loss = 0.0842 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9867: loss = 0.0762 (0.172 sec/step)\n",
            "I0601 12:22:39.725810 140438660523904 learning.py:507] global step 9867: loss = 0.0762 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9868: loss = 0.0523 (0.179 sec/step)\n",
            "I0601 12:22:39.908806 140438660523904 learning.py:507] global step 9868: loss = 0.0523 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9869: loss = 0.1039 (0.168 sec/step)\n",
            "I0601 12:22:40.078546 140438660523904 learning.py:507] global step 9869: loss = 0.1039 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9870: loss = 0.0788 (0.164 sec/step)\n",
            "I0601 12:22:40.244320 140438660523904 learning.py:507] global step 9870: loss = 0.0788 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9871: loss = 0.0194 (0.199 sec/step)\n",
            "I0601 12:22:40.444834 140438660523904 learning.py:507] global step 9871: loss = 0.0194 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 9872: loss = 0.0186 (0.182 sec/step)\n",
            "I0601 12:22:40.628011 140438660523904 learning.py:507] global step 9872: loss = 0.0186 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9873: loss = 0.1600 (0.159 sec/step)\n",
            "I0601 12:22:40.789456 140438660523904 learning.py:507] global step 9873: loss = 0.1600 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9874: loss = 0.1976 (0.225 sec/step)\n",
            "I0601 12:22:41.016048 140438660523904 learning.py:507] global step 9874: loss = 0.1976 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9875: loss = 0.1976 (0.201 sec/step)\n",
            "I0601 12:22:41.218216 140438660523904 learning.py:507] global step 9875: loss = 0.1976 (0.201 sec/step)\n",
            "INFO:tensorflow:global step 9876: loss = 0.0843 (0.167 sec/step)\n",
            "I0601 12:22:41.387007 140438660523904 learning.py:507] global step 9876: loss = 0.0843 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9877: loss = 0.0826 (0.170 sec/step)\n",
            "I0601 12:22:41.558515 140438660523904 learning.py:507] global step 9877: loss = 0.0826 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9878: loss = 0.2246 (0.155 sec/step)\n",
            "I0601 12:22:41.714835 140438660523904 learning.py:507] global step 9878: loss = 0.2246 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9879: loss = 0.0932 (0.171 sec/step)\n",
            "I0601 12:22:41.886938 140438660523904 learning.py:507] global step 9879: loss = 0.0932 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9880: loss = 0.1131 (0.197 sec/step)\n",
            "I0601 12:22:42.084992 140438660523904 learning.py:507] global step 9880: loss = 0.1131 (0.197 sec/step)\n",
            "INFO:tensorflow:global step 9881: loss = 0.1786 (0.177 sec/step)\n",
            "I0601 12:22:42.263347 140438660523904 learning.py:507] global step 9881: loss = 0.1786 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9882: loss = 0.1534 (0.183 sec/step)\n",
            "I0601 12:22:42.447462 140438660523904 learning.py:507] global step 9882: loss = 0.1534 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9883: loss = 0.0313 (0.164 sec/step)\n",
            "I0601 12:22:42.613171 140438660523904 learning.py:507] global step 9883: loss = 0.0313 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9884: loss = 0.0534 (0.173 sec/step)\n",
            "I0601 12:22:42.787706 140438660523904 learning.py:507] global step 9884: loss = 0.0534 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9885: loss = 0.1282 (0.164 sec/step)\n",
            "I0601 12:22:42.952728 140438660523904 learning.py:507] global step 9885: loss = 0.1282 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9886: loss = 0.2092 (0.172 sec/step)\n",
            "I0601 12:22:43.125998 140438660523904 learning.py:507] global step 9886: loss = 0.2092 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9887: loss = 0.0764 (0.179 sec/step)\n",
            "I0601 12:22:43.306469 140438660523904 learning.py:507] global step 9887: loss = 0.0764 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9888: loss = 4.1281 (0.183 sec/step)\n",
            "I0601 12:22:43.491171 140438660523904 learning.py:507] global step 9888: loss = 4.1281 (0.183 sec/step)\n",
            "INFO:tensorflow:global step 9889: loss = 0.0538 (0.145 sec/step)\n",
            "I0601 12:22:43.637850 140438660523904 learning.py:507] global step 9889: loss = 0.0538 (0.145 sec/step)\n",
            "INFO:tensorflow:global step 9890: loss = 0.0220 (0.171 sec/step)\n",
            "I0601 12:22:43.809812 140438660523904 learning.py:507] global step 9890: loss = 0.0220 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9891: loss = 0.1565 (0.185 sec/step)\n",
            "I0601 12:22:43.995716 140438660523904 learning.py:507] global step 9891: loss = 0.1565 (0.185 sec/step)\n",
            "INFO:tensorflow:global step 9892: loss = 0.1864 (0.177 sec/step)\n",
            "I0601 12:22:44.174233 140438660523904 learning.py:507] global step 9892: loss = 0.1864 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9893: loss = 0.1322 (0.157 sec/step)\n",
            "I0601 12:22:44.332634 140438660523904 learning.py:507] global step 9893: loss = 0.1322 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9894: loss = 0.0747 (0.163 sec/step)\n",
            "I0601 12:22:44.496603 140438660523904 learning.py:507] global step 9894: loss = 0.0747 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9895: loss = 0.0817 (0.173 sec/step)\n",
            "I0601 12:22:44.671210 140438660523904 learning.py:507] global step 9895: loss = 0.0817 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9896: loss = 0.0432 (0.166 sec/step)\n",
            "I0601 12:22:44.838339 140438660523904 learning.py:507] global step 9896: loss = 0.0432 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9897: loss = 0.0479 (0.169 sec/step)\n",
            "I0601 12:22:45.009786 140438660523904 learning.py:507] global step 9897: loss = 0.0479 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9898: loss = 0.1149 (0.166 sec/step)\n",
            "I0601 12:22:45.177068 140438660523904 learning.py:507] global step 9898: loss = 0.1149 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9899: loss = 0.1039 (0.155 sec/step)\n",
            "I0601 12:22:45.333076 140438660523904 learning.py:507] global step 9899: loss = 0.1039 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9900: loss = 0.1792 (0.170 sec/step)\n",
            "I0601 12:22:45.504568 140438660523904 learning.py:507] global step 9900: loss = 0.1792 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9901: loss = 0.1105 (0.179 sec/step)\n",
            "I0601 12:22:45.684735 140438660523904 learning.py:507] global step 9901: loss = 0.1105 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9902: loss = 0.0970 (0.175 sec/step)\n",
            "I0601 12:22:45.862335 140438660523904 learning.py:507] global step 9902: loss = 0.0970 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9903: loss = 0.1896 (0.165 sec/step)\n",
            "I0601 12:22:46.029133 140438660523904 learning.py:507] global step 9903: loss = 0.1896 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9904: loss = 0.0509 (0.179 sec/step)\n",
            "I0601 12:22:46.209409 140438660523904 learning.py:507] global step 9904: loss = 0.0509 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9905: loss = 0.1355 (0.192 sec/step)\n",
            "I0601 12:22:46.403141 140438660523904 learning.py:507] global step 9905: loss = 0.1355 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9906: loss = 0.1663 (0.173 sec/step)\n",
            "I0601 12:22:46.577861 140438660523904 learning.py:507] global step 9906: loss = 0.1663 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9907: loss = 0.0497 (0.156 sec/step)\n",
            "I0601 12:22:46.734948 140438660523904 learning.py:507] global step 9907: loss = 0.0497 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9908: loss = 0.0787 (0.188 sec/step)\n",
            "I0601 12:22:46.924055 140438660523904 learning.py:507] global step 9908: loss = 0.0787 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9909: loss = 0.0690 (0.179 sec/step)\n",
            "I0601 12:22:47.104043 140438660523904 learning.py:507] global step 9909: loss = 0.0690 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9910: loss = 0.0622 (0.179 sec/step)\n",
            "I0601 12:22:47.284824 140438660523904 learning.py:507] global step 9910: loss = 0.0622 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9911: loss = 0.0980 (0.209 sec/step)\n",
            "I0601 12:22:47.495729 140438660523904 learning.py:507] global step 9911: loss = 0.0980 (0.209 sec/step)\n",
            "INFO:tensorflow:global step 9912: loss = 0.0342 (0.145 sec/step)\n",
            "I0601 12:22:47.642813 140438660523904 learning.py:507] global step 9912: loss = 0.0342 (0.145 sec/step)\n",
            "INFO:tensorflow:global step 9913: loss = 0.0838 (0.187 sec/step)\n",
            "I0601 12:22:47.831711 140438660523904 learning.py:507] global step 9913: loss = 0.0838 (0.187 sec/step)\n",
            "INFO:tensorflow:global step 9914: loss = 0.0379 (0.176 sec/step)\n",
            "I0601 12:22:48.009397 140438660523904 learning.py:507] global step 9914: loss = 0.0379 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9915: loss = 0.0866 (0.176 sec/step)\n",
            "I0601 12:22:48.187811 140438660523904 learning.py:507] global step 9915: loss = 0.0866 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9916: loss = 0.0886 (0.164 sec/step)\n",
            "I0601 12:22:48.353179 140438660523904 learning.py:507] global step 9916: loss = 0.0886 (0.164 sec/step)\n",
            "INFO:tensorflow:global step 9917: loss = 0.1199 (0.181 sec/step)\n",
            "I0601 12:22:48.535307 140438660523904 learning.py:507] global step 9917: loss = 0.1199 (0.181 sec/step)\n",
            "INFO:tensorflow:global step 9918: loss = 0.0625 (0.178 sec/step)\n",
            "I0601 12:22:48.714724 140438660523904 learning.py:507] global step 9918: loss = 0.0625 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9919: loss = 0.2021 (0.172 sec/step)\n",
            "I0601 12:22:48.888542 140438660523904 learning.py:507] global step 9919: loss = 0.2021 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9920: loss = 0.0405 (0.170 sec/step)\n",
            "I0601 12:22:49.059732 140438660523904 learning.py:507] global step 9920: loss = 0.0405 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9921: loss = 0.0886 (0.192 sec/step)\n",
            "I0601 12:22:49.253064 140438660523904 learning.py:507] global step 9921: loss = 0.0886 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9922: loss = 0.0856 (0.150 sec/step)\n",
            "I0601 12:22:49.404624 140438660523904 learning.py:507] global step 9922: loss = 0.0856 (0.150 sec/step)\n",
            "INFO:tensorflow:global step 9923: loss = 0.0855 (0.173 sec/step)\n",
            "I0601 12:22:49.578963 140438660523904 learning.py:507] global step 9923: loss = 0.0855 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9924: loss = 0.1251 (0.162 sec/step)\n",
            "I0601 12:22:49.742874 140438660523904 learning.py:507] global step 9924: loss = 0.1251 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9925: loss = 0.2666 (0.176 sec/step)\n",
            "I0601 12:22:49.921518 140438660523904 learning.py:507] global step 9925: loss = 0.2666 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9926: loss = 0.0556 (0.177 sec/step)\n",
            "I0601 12:22:50.100027 140438660523904 learning.py:507] global step 9926: loss = 0.0556 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9927: loss = 0.1362 (0.178 sec/step)\n",
            "I0601 12:22:50.279360 140438660523904 learning.py:507] global step 9927: loss = 0.1362 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9928: loss = 0.0493 (0.172 sec/step)\n",
            "I0601 12:22:50.453342 140438660523904 learning.py:507] global step 9928: loss = 0.0493 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9929: loss = 0.1638 (0.184 sec/step)\n",
            "I0601 12:22:50.639412 140438660523904 learning.py:507] global step 9929: loss = 0.1638 (0.184 sec/step)\n",
            "INFO:tensorflow:global step 9930: loss = 0.0497 (0.144 sec/step)\n",
            "I0601 12:22:50.784475 140438660523904 learning.py:507] global step 9930: loss = 0.0497 (0.144 sec/step)\n",
            "INFO:tensorflow:global step 9931: loss = 0.0722 (0.161 sec/step)\n",
            "I0601 12:22:50.946859 140438660523904 learning.py:507] global step 9931: loss = 0.0722 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9932: loss = 0.0905 (0.173 sec/step)\n",
            "I0601 12:22:51.121169 140438660523904 learning.py:507] global step 9932: loss = 0.0905 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9933: loss = 0.0162 (0.166 sec/step)\n",
            "I0601 12:22:51.289138 140438660523904 learning.py:507] global step 9933: loss = 0.0162 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9934: loss = 0.1335 (0.156 sec/step)\n",
            "I0601 12:22:51.446958 140438660523904 learning.py:507] global step 9934: loss = 0.1335 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9935: loss = 0.0902 (0.176 sec/step)\n",
            "I0601 12:22:51.624766 140438660523904 learning.py:507] global step 9935: loss = 0.0902 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9936: loss = 0.0283 (0.162 sec/step)\n",
            "I0601 12:22:51.787816 140438660523904 learning.py:507] global step 9936: loss = 0.0283 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9937: loss = 0.0983 (0.161 sec/step)\n",
            "I0601 12:22:51.950713 140438660523904 learning.py:507] global step 9937: loss = 0.0983 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9938: loss = 0.2766 (0.159 sec/step)\n",
            "I0601 12:22:52.115058 140438660523904 learning.py:507] global step 9938: loss = 0.2766 (0.159 sec/step)\n",
            "INFO:tensorflow:global step 9939: loss = 0.0681 (0.182 sec/step)\n",
            "I0601 12:22:52.298078 140438660523904 learning.py:507] global step 9939: loss = 0.0681 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9940: loss = 0.2303 (0.175 sec/step)\n",
            "I0601 12:22:52.474262 140438660523904 learning.py:507] global step 9940: loss = 0.2303 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9941: loss = 0.0508 (0.165 sec/step)\n",
            "I0601 12:22:52.641144 140438660523904 learning.py:507] global step 9941: loss = 0.0508 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9942: loss = 0.0746 (0.162 sec/step)\n",
            "I0601 12:22:52.804775 140438660523904 learning.py:507] global step 9942: loss = 0.0746 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9943: loss = 0.0355 (0.160 sec/step)\n",
            "I0601 12:22:52.966408 140438660523904 learning.py:507] global step 9943: loss = 0.0355 (0.160 sec/step)\n",
            "INFO:tensorflow:global step 9944: loss = 0.0304 (0.149 sec/step)\n",
            "I0601 12:22:53.116909 140438660523904 learning.py:507] global step 9944: loss = 0.0304 (0.149 sec/step)\n",
            "INFO:tensorflow:global step 9945: loss = 0.2834 (0.173 sec/step)\n",
            "I0601 12:22:53.291254 140438660523904 learning.py:507] global step 9945: loss = 0.2834 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9946: loss = 0.0246 (0.155 sec/step)\n",
            "I0601 12:22:53.448344 140438660523904 learning.py:507] global step 9946: loss = 0.0246 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9947: loss = 0.0930 (0.175 sec/step)\n",
            "I0601 12:22:53.624516 140438660523904 learning.py:507] global step 9947: loss = 0.0930 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9948: loss = 0.0443 (0.140 sec/step)\n",
            "I0601 12:22:53.765747 140438660523904 learning.py:507] global step 9948: loss = 0.0443 (0.140 sec/step)\n",
            "INFO:tensorflow:global step 9949: loss = 0.0320 (0.173 sec/step)\n",
            "I0601 12:22:53.940421 140438660523904 learning.py:507] global step 9949: loss = 0.0320 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9950: loss = 0.1232 (0.170 sec/step)\n",
            "I0601 12:22:54.111274 140438660523904 learning.py:507] global step 9950: loss = 0.1232 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9951: loss = 4.1801 (0.192 sec/step)\n",
            "I0601 12:22:54.304529 140438660523904 learning.py:507] global step 9951: loss = 4.1801 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9952: loss = 0.0998 (0.156 sec/step)\n",
            "I0601 12:22:54.461557 140438660523904 learning.py:507] global step 9952: loss = 0.0998 (0.156 sec/step)\n",
            "INFO:tensorflow:global step 9953: loss = 0.2105 (0.192 sec/step)\n",
            "I0601 12:22:54.654696 140438660523904 learning.py:507] global step 9953: loss = 0.2105 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9954: loss = 0.2245 (0.179 sec/step)\n",
            "I0601 12:22:54.834860 140438660523904 learning.py:507] global step 9954: loss = 0.2245 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9955: loss = 0.1076 (0.174 sec/step)\n",
            "I0601 12:22:55.010617 140438660523904 learning.py:507] global step 9955: loss = 0.1076 (0.174 sec/step)\n",
            "INFO:tensorflow:global step 9956: loss = 0.0979 (0.177 sec/step)\n",
            "I0601 12:22:55.189361 140438660523904 learning.py:507] global step 9956: loss = 0.0979 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9957: loss = 0.1282 (0.179 sec/step)\n",
            "I0601 12:22:55.369336 140438660523904 learning.py:507] global step 9957: loss = 0.1282 (0.179 sec/step)\n",
            "INFO:tensorflow:global step 9958: loss = 0.0720 (0.171 sec/step)\n",
            "I0601 12:22:55.541466 140438660523904 learning.py:507] global step 9958: loss = 0.0720 (0.171 sec/step)\n",
            "INFO:tensorflow:global step 9959: loss = 0.0189 (0.176 sec/step)\n",
            "I0601 12:22:55.718805 140438660523904 learning.py:507] global step 9959: loss = 0.0189 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9960: loss = 0.0951 (0.162 sec/step)\n",
            "I0601 12:22:55.882573 140438660523904 learning.py:507] global step 9960: loss = 0.0951 (0.162 sec/step)\n",
            "INFO:tensorflow:global step 9961: loss = 0.1597 (0.178 sec/step)\n",
            "I0601 12:22:56.062186 140438660523904 learning.py:507] global step 9961: loss = 0.1597 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9962: loss = 0.1493 (0.163 sec/step)\n",
            "I0601 12:22:56.226461 140438660523904 learning.py:507] global step 9962: loss = 0.1493 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9963: loss = 0.0626 (0.192 sec/step)\n",
            "I0601 12:22:56.420428 140438660523904 learning.py:507] global step 9963: loss = 0.0626 (0.192 sec/step)\n",
            "INFO:tensorflow:global step 9964: loss = 0.2371 (0.170 sec/step)\n",
            "I0601 12:22:56.591853 140438660523904 learning.py:507] global step 9964: loss = 0.2371 (0.170 sec/step)\n",
            "INFO:tensorflow:global step 9965: loss = 0.1708 (0.177 sec/step)\n",
            "I0601 12:22:56.770063 140438660523904 learning.py:507] global step 9965: loss = 0.1708 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9966: loss = 0.1888 (0.163 sec/step)\n",
            "I0601 12:22:56.934795 140438660523904 learning.py:507] global step 9966: loss = 0.1888 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9967: loss = 0.1194 (0.178 sec/step)\n",
            "I0601 12:22:57.114143 140438660523904 learning.py:507] global step 9967: loss = 0.1194 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9968: loss = 0.2035 (0.172 sec/step)\n",
            "I0601 12:22:57.287195 140438660523904 learning.py:507] global step 9968: loss = 0.2035 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9969: loss = 0.2796 (0.177 sec/step)\n",
            "I0601 12:22:57.466004 140438660523904 learning.py:507] global step 9969: loss = 0.2796 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9970: loss = 0.1222 (0.155 sec/step)\n",
            "I0601 12:22:57.622303 140438660523904 learning.py:507] global step 9970: loss = 0.1222 (0.155 sec/step)\n",
            "INFO:tensorflow:global step 9971: loss = 0.0584 (0.169 sec/step)\n",
            "I0601 12:22:57.793056 140438660523904 learning.py:507] global step 9971: loss = 0.0584 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9972: loss = 0.0265 (0.143 sec/step)\n",
            "I0601 12:22:57.937669 140438660523904 learning.py:507] global step 9972: loss = 0.0265 (0.143 sec/step)\n",
            "INFO:tensorflow:global step 9973: loss = 0.2957 (0.199 sec/step)\n",
            "I0601 12:22:58.138322 140438660523904 learning.py:507] global step 9973: loss = 0.2957 (0.199 sec/step)\n",
            "INFO:tensorflow:global step 9974: loss = 0.0970 (0.166 sec/step)\n",
            "I0601 12:22:58.306422 140438660523904 learning.py:507] global step 9974: loss = 0.0970 (0.166 sec/step)\n",
            "INFO:tensorflow:global step 9975: loss = 0.2784 (0.180 sec/step)\n",
            "I0601 12:22:58.487634 140438660523904 learning.py:507] global step 9975: loss = 0.2784 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9976: loss = 0.0798 (0.176 sec/step)\n",
            "I0601 12:22:58.665594 140438660523904 learning.py:507] global step 9976: loss = 0.0798 (0.176 sec/step)\n",
            "INFO:tensorflow:global step 9977: loss = 0.0842 (0.188 sec/step)\n",
            "I0601 12:22:58.855388 140438660523904 learning.py:507] global step 9977: loss = 0.0842 (0.188 sec/step)\n",
            "INFO:tensorflow:global step 9978: loss = 0.0158 (0.180 sec/step)\n",
            "I0601 12:22:59.037382 140438660523904 learning.py:507] global step 9978: loss = 0.0158 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9979: loss = 4.1960 (0.180 sec/step)\n",
            "I0601 12:22:59.218621 140438660523904 learning.py:507] global step 9979: loss = 4.1960 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9980: loss = 0.1157 (0.178 sec/step)\n",
            "I0601 12:22:59.397640 140438660523904 learning.py:507] global step 9980: loss = 0.1157 (0.178 sec/step)\n",
            "INFO:tensorflow:global step 9981: loss = 0.1649 (0.163 sec/step)\n",
            "I0601 12:22:59.562454 140438660523904 learning.py:507] global step 9981: loss = 0.1649 (0.163 sec/step)\n",
            "INFO:tensorflow:global step 9982: loss = 0.0268 (0.173 sec/step)\n",
            "I0601 12:22:59.736581 140438660523904 learning.py:507] global step 9982: loss = 0.0268 (0.173 sec/step)\n",
            "INFO:tensorflow:global step 9983: loss = 0.1393 (0.165 sec/step)\n",
            "I0601 12:22:59.902958 140438660523904 learning.py:507] global step 9983: loss = 0.1393 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 9984: loss = 0.0343 (0.182 sec/step)\n",
            "I0601 12:23:00.087195 140438660523904 learning.py:507] global step 9984: loss = 0.0343 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9985: loss = 0.0425 (0.168 sec/step)\n",
            "I0601 12:23:00.256720 140438660523904 learning.py:507] global step 9985: loss = 0.0425 (0.168 sec/step)\n",
            "INFO:tensorflow:global step 9986: loss = 0.1686 (0.175 sec/step)\n",
            "I0601 12:23:00.433187 140438660523904 learning.py:507] global step 9986: loss = 0.1686 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9987: loss = 0.0722 (0.175 sec/step)\n",
            "I0601 12:23:00.609882 140438660523904 learning.py:507] global step 9987: loss = 0.0722 (0.175 sec/step)\n",
            "INFO:tensorflow:global step 9988: loss = 0.3736 (0.177 sec/step)\n",
            "I0601 12:23:00.787969 140438660523904 learning.py:507] global step 9988: loss = 0.3736 (0.177 sec/step)\n",
            "INFO:tensorflow:global step 9989: loss = 0.1566 (0.157 sec/step)\n",
            "I0601 12:23:00.946714 140438660523904 learning.py:507] global step 9989: loss = 0.1566 (0.157 sec/step)\n",
            "INFO:tensorflow:global step 9990: loss = 0.2710 (0.169 sec/step)\n",
            "I0601 12:23:01.117291 140438660523904 learning.py:507] global step 9990: loss = 0.2710 (0.169 sec/step)\n",
            "INFO:tensorflow:global step 9991: loss = 0.1999 (0.180 sec/step)\n",
            "I0601 12:23:01.298605 140438660523904 learning.py:507] global step 9991: loss = 0.1999 (0.180 sec/step)\n",
            "INFO:tensorflow:global step 9992: loss = 0.0246 (0.182 sec/step)\n",
            "I0601 12:23:01.481630 140438660523904 learning.py:507] global step 9992: loss = 0.0246 (0.182 sec/step)\n",
            "INFO:tensorflow:global step 9993: loss = 0.0330 (0.172 sec/step)\n",
            "I0601 12:23:01.654742 140438660523904 learning.py:507] global step 9993: loss = 0.0330 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9994: loss = 0.0453 (0.167 sec/step)\n",
            "I0601 12:23:01.823275 140438660523904 learning.py:507] global step 9994: loss = 0.0453 (0.167 sec/step)\n",
            "INFO:tensorflow:global step 9995: loss = 0.1049 (0.161 sec/step)\n",
            "I0601 12:23:01.985796 140438660523904 learning.py:507] global step 9995: loss = 0.1049 (0.161 sec/step)\n",
            "INFO:tensorflow:global step 9996: loss = 0.0640 (0.239 sec/step)\n",
            "I0601 12:23:02.226002 140438660523904 learning.py:507] global step 9996: loss = 0.0640 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9997: loss = 0.0681 (0.193 sec/step)\n",
            "I0601 12:23:02.419958 140438660523904 learning.py:507] global step 9997: loss = 0.0681 (0.193 sec/step)\n",
            "INFO:tensorflow:global step 9998: loss = 0.0615 (0.172 sec/step)\n",
            "I0601 12:23:02.593032 140438660523904 learning.py:507] global step 9998: loss = 0.0615 (0.172 sec/step)\n",
            "INFO:tensorflow:global step 9999: loss = 0.1171 (0.165 sec/step)\n",
            "I0601 12:23:02.759625 140438660523904 learning.py:507] global step 9999: loss = 0.1171 (0.165 sec/step)\n",
            "INFO:tensorflow:global step 10000: loss = 0.1541 (0.183 sec/step)\n",
            "I0601 12:23:02.944198 140438660523904 learning.py:507] global step 10000: loss = 0.1541 (0.183 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I0601 12:23:02.944984 140438660523904 learning.py:777] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I0601 12:23:02.945158 140438660523904 learning.py:785] Finished training! Saving model to disk.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hAwrUFVZw24",
        "outputId": "0b5c514f-31f4-4eeb-d91b-7a99f80467e1"
      },
      "source": [
        "%cd models/research/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Face mask Detection/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIpR7PLco279",
        "outputId": "2fdead61-b5b3-4043-a3a0-5f72562d9311"
      },
      "source": [
        "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-10000 --output_directory mask_model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/nets/mobilenet/mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:150: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0601 12:54:19.267891 140454876776320 deprecation_wrapper.py:119] From export_inference_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0601 12:54:19.273314 140454876776320 deprecation.py:323] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:348: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0601 12:54:19.276792 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:348: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0601 12:54:19.279738 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/preprocessor.py:2154: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0601 12:54:19.324305 140454876776320 deprecation.py:323] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/preprocessor.py:2154: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0601 12:54:19.344335 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0601 12:54:19.366598 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0601 12:54:19.377798 140454876776320 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fbdbd5ce510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fbdbd5ce510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.445388 140454876776320 ag_logging.py:145] Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fbdbd5ce510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7fbdbd5ce510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4ec190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4ec190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.477636 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4ec190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4ec190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd5ce810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd5ce810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.613405 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd5ce810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd5ce810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cea10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cea10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.673234 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cea10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cea10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4a6950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4a6950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.705525 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4a6950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd4a6950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.766397 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd54d510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd54d510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.795264 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd54d510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd54d510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbe30e44350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbe30e44350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.836341 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbe30e44350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbe30e44350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.898005 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd49bd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd49bd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.927118 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd49bd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd49bd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:19.994863 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5cef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eabd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eabd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.025117 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eabd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eabd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.089802 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd47f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd47f610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.118969 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd47f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd47f610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.181183 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd565e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd565e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.210143 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd565e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd565e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.272577 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a5f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eeb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eeb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.305118 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eeb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3eeb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.374895 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ce4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3ee590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3ee590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.407202 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3ee590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd3ee590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd5cea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd5cea50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.447802 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd5cea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd5cea50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3dbe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3dbe50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.508717 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3dbe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3dbe50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.539056 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3bec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3bec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.608264 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3bec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3bec50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.637103 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd270410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a6110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a6110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.699176 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a6110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a6110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd1d6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd1d6490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.728402 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd1d6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd1d6490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd1dce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd1dce90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.794564 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd1dce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd1dce90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd2a6890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd2a6890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.823553 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd2a6890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd2a6890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.890595 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd4a61d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd0b1a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd0b1a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.921057 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd0b1a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd0b1a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:20.984063 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd14c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd14c4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.014874 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd14c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd14c4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbe30e44cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbe30e44cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.077344 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbe30e44cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbe30e44cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd146790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd146790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.107459 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd146790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd146790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd2d6850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd2d6850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.149502 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd2d6850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd2d6850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd551110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd551110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.220002 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd551110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd551110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd04c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd04c590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.250356 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd04c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd04c590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd080050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd080050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.314073 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd080050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd080050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.347871 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd284f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd284f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.409954 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd284f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd284f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf3fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf3fd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.441874 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf3fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf3fd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd003210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd003210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.508892 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd003210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd003210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.539274 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcfce610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd176250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd176250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.604949 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd176250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd176250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd03c210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd03c210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.634272 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd03c210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd03c210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd171ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd171ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.696107 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd171ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd171ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf79bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf79bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.725279 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf79bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcf79bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd0ada10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd0ada10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.765071 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd0ada10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbd0ada10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5515d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5515d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.831633 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5515d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5515d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbce00410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbce00410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.860444 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbce00410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbce00410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.920949 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:21.949832 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.012276 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd394d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcdbded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcdbded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.041350 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcdbded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcdbded0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf66ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf66ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.105437 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf66ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf66ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd551990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd551990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.134172 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd551990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbd551990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.198303 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbe9d4650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6f310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.333354 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd6f310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd04cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd04cf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.404487 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd04cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd04cf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd0c9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd0c9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.434116 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd0c9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcd0c9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd4ef290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd4ef290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.473880 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd4ef290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbd4ef290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd0b1710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd0b1710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.533876 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd0b1710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd0b1710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0d450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0d450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.563592 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0d450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0d450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.625560 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcbcd090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcbcd090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.654157 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcbcd090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcbcd090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3eee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3eee50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.718684 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3eee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd3eee50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc61690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc61690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.747106 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc61690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc61690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbce43ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbce43ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.811039 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbce43ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbce43ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb043d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb043d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.839744 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb043d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb043d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcd3f390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcd3f390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.909350 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcd3f390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcd3f390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcad25d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcad25d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:22.938842 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcad25d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcad25d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf42f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf42f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.003857 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf42f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcf42f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf0d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf0d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.035367 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf0d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf0d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ebf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ebf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.100640 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ebf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd5ebf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb04890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb04890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.129558 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb04890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcb04890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbce6c690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbce6c690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.169357 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbce6c690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbce6c690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb59110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb59110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.230840 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb59110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb59110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0dd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.260848 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcc0dd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcc0dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcc0dd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.328737 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcc0dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcc0dd90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92a510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92a510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.362468 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92a510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92a510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.425095 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9d6650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9d6650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.453942 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9d6650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9d6650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.515653 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcdbdad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9549d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9549d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.545899 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9549d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9549d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcd710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcd710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.614697 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcd710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcd710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.643227 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbf4090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbf4090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.705031 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbf4090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbf4090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9fe450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9fe450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.734880 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9fe450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9fe450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.797396 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcb30290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc916b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc916b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.826226 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc916b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc916b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbca89910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbca89910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.866279 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbca89910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbca89910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fba10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fba10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.936148 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fba10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fba10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc716110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc716110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:23.965816 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc716110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc716110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fbed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fbed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.028259 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fbed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8fbed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6dac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6dac90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.063960 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6dac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6dac90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbca20310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbca20310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.127997 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbca20310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbca20310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.156959 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc92aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.227062 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc691c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc691c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.257539 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc691c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc691c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.320855 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc9d6790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6e5f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6e5f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.350029 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6e5f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc6e5f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcefef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcefef50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.416774 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcefef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcefef50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc5da3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc5da3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.447657 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc5da3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc5da3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8e7d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8e7d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.511214 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8e7d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc8e7d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc610a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc610a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.540369 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc610a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc610a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbc7dfc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbc7dfc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.580875 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbc7dfc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbc7dfc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd17f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd17f310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.641140 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd17f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd17f310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc4fe110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc4fe110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.670802 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc4fe110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc4fe110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0601 12:54:24.806604 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0601 12:54:24.817585 140454876776320 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0601 12:54:24.817999 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbdf11fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbdf11fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.882335 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbdf11fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbdf11fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0601 12:54:24.885278 140454876776320 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/predictors/convolutional_box_predictor.py:147: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0601 12:54:24.885684 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/predictors/convolutional_box_predictor.py:147: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0601 12:54:24.885809 140454876776320 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc377dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc377dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:24.948543 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc377dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc377dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcfa1a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcfa1a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.018646 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcfa1a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcfa1a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/box_list_ops.py:136: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0601 12:54:25.044576 140454876776320 deprecation.py:323] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/core/box_list_ops.py:136: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/utils/ops.py:1085: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0601 12:54:25.646126 140454876776320 deprecation.py:506] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/utils/ops.py:1085: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbd41f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbd41f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.702940 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbd41f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbd41f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.767548 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcefc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcefc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.797938 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcefc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcefc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbd0a5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbd0a5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.859218 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbd0a5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbd0a5d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbd0a650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbd0a650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.887879 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbd0a650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbd0a650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.957022 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbca3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbca3750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:25.988331 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbca3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbca3750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbccfb190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbccfb190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.051394 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbccfb190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbccfb190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.081078 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.142447 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.171600 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbcb5b50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbcd96d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbcd96d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.214118 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbcd96d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbbcd96d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.283132 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb78d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb78d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.313838 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb78d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb78d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.377088 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb54650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb54650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.409868 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb54650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb54650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd95d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd95d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.471585 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd95d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd95d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb7df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb7df10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.501339 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb7df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb7df10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd49b9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd49b9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.568970 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd49b9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd49b9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb9a590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb9a590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.599442 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb9a590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbb9a590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.662544 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9ad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9ad10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.692272 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9ad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9ad10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.755754 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcd9610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbaaba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbaaba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.784761 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbaaba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbbaaba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbbcfc350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbbcfc350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.830728 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbbcfc350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbbcfc350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcdc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcdc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.891473 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcdc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbcbcdc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb972310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb972310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.921343 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb972310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb972310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbb466d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbb466d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:26.983753 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbb466d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbb466d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb9a10d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb9a10d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.013218 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb9a10d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb9a10d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.074838 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9a990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.104037 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbba9a990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.182959 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcfc190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf43d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf43d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.217111 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf43d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbcaf43d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.281416 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb943350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb943350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.311598 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb943350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb943350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcf0510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcf0510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.374955 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcf0510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbcf0510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.405466 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbc9bc8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.479284 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbba8390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb839a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb839a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.509648 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb839a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb839a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb965a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb965a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.549838 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb965a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb965a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbad8b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbad8b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.610657 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbad8b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbbad8b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb72a1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb72a1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:27.639983 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb72a1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb72a1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0601 12:54:27.644630 140454876776320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0601 12:54:27.654626 140454876776320 ag_logging.py:145] Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0601 12:54:27.659646 140454876776320 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbcd9610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbcd9610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0601 12:54:27.680615 140454876776320 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbcd9610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbcd9610>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41410>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0601 12:54:27.694088 140454876776320 ag_logging.py:145] Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fbdbbd41410>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0601 12:54:27.699297 140454876776320 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbd41a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbd41a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "W0601 12:54:27.720155 140454876776320 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbd41a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fbdbbd41a90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb0b9ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb0b9ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.413340 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb0b9ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb0b9ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.475357 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0284d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0284d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.492810 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0284d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0284d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.546884 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.564326 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.619322 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dd10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0281d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0281d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.642272 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0281d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb0281d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.696626 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.713608 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.773185 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.791675 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07d310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07d310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.832555 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07d310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07d310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.887851 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbd565390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb093990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb093990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.905282 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb093990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb093990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.965776 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:28.982859 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.037101 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb02bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb02bad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.057410 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb02bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb02bad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.117930 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb038210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb038210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.135981 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb038210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb038210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.190927 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.208310 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb020e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.268593 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb07f4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb07f4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.285940 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb07f4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb07f4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbb07d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbb07d3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.325398 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbb07d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7fbdbb07d3d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0381d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0381d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.378921 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0381d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0381d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.396250 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb03b9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0200d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0200d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.458000 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0200d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb0200d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb092650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb092650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.475004 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb092650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb092650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.528980 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.550833 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.608843 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb007450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb007450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.626072 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb007450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb007450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.686278 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07d510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbaff9950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbaff9950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.705016 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbaff9950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbaff9950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dc90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.768640 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbb07dc90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb028650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb028650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.787489 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb028650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb028650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc6e53d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc6e53d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.844125 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc6e53d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc6e53d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.863469 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbb037f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.905260 140454876776320 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7fbdbb07de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc568890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc568890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.960645 140454876776320 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc568890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7fbdbc568890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbafca490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbafca490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0601 12:54:29.978125 140454876776320 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbafca490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7fbdbafca490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:330: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0601 12:54:29.994755 140454876776320 deprecation.py:323] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:330: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:484: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0601 12:54:29.998020 140454876776320 deprecation.py:323] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:484: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0601 12:54:29.999163 140454876776320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "246 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.85m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/11.28k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/8.20k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (8, 8/8 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x8, 8.19k/8.19k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/3.08k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (3, 3/3 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x3, 3.07k/3.07k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "246 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/2.55k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map_1/while/mul_3 (300/300 flops)\n",
            "  map_1/while/mul_2 (300/300 flops)\n",
            "  map_1/while/mul_1 (300/300 flops)\n",
            "  map_1/while/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_1/while/add_1 (1/1 flops)\n",
            "  map_1/while/add (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/add_1 (1/1 flops)\n",
            "  map/while/add (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  Preprocessor/map/while/add_1 (1/1 flops)\n",
            "  Preprocessor/map/while/add (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul_3 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul_2 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Maximum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/add_4 (1/1 flops)\n",
            "  GridAnchorGenerator/add_3 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0601 12:54:31.047075 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2021-06-01 12:54:31.968019: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2021-06-01 12:54:31.975698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:31.976296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-01 12:54:31.976791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-06-01 12:54:31.979152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-06-01 12:54:31.980935: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-06-01 12:54:31.981603: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-06-01 12:54:31.984820: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-06-01 12:54:31.986954: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-06-01 12:54:31.995967: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-01 12:54:31.996119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:31.996724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:31.997259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-06-01 12:54:31.997779: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-06-01 12:54:32.002410: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-06-01 12:54:32.002596: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55695a52fd40 executing computations on platform Host. Devices:\n",
            "2021-06-01 12:54:32.002622: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2021-06-01 12:54:32.196839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:32.197629: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55695a52f2c0 executing computations on platform CUDA. Devices:\n",
            "2021-06-01 12:54:32.197663: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2021-06-01 12:54:32.197881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:32.198424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-01 12:54:32.198495: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-06-01 12:54:32.198519: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-06-01 12:54:32.198540: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-06-01 12:54:32.198559: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-06-01 12:54:32.198578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-06-01 12:54:32.198596: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-06-01 12:54:32.198615: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-01 12:54:32.198685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:32.199279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:32.199774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-06-01 12:54:32.199839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-06-01 12:54:32.201077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-01 12:54:32.201103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-06-01 12:54:32.201114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-06-01 12:54:32.201253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:32.201810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:32.202332: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-06-01 12:54:32.202374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14161 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0601 12:54:32.203136 140454876776320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0601 12:54:32.205228 140454876776320 saver.py:1280] Restoring parameters from training/model.ckpt-10000\n",
            "2021-06-01 12:54:34.637604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:34.638228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-01 12:54:34.638314: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-06-01 12:54:34.638337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-06-01 12:54:34.638359: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-06-01 12:54:34.638378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-06-01 12:54:34.638396: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-06-01 12:54:34.638415: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-06-01 12:54:34.638435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-01 12:54:34.638519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:34.639088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:34.639587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-06-01 12:54:34.639627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-01 12:54:34.639640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-06-01 12:54:34.639650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-06-01 12:54:34.639743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:34.640300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:34.640822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14161 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-10000\n",
            "I0601 12:54:34.642728 140454876776320 saver.py:1280] Restoring parameters from training/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0601 12:54:35.340141 140454876776320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0601 12:54:35.340387 140454876776320 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0601 12:54:35.653464 140454876776320 graph_util_impl.py:311] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0601 12:54:35.766206 140454876776320 graph_util_impl.py:364] Converted 356 variables to const ops.\n",
            "2021-06-01 12:54:36.025347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:36.025998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-06-01 12:54:36.026094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2021-06-01 12:54:36.026118: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2021-06-01 12:54:36.026140: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2021-06-01 12:54:36.026160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2021-06-01 12:54:36.026191: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2021-06-01 12:54:36.026210: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2021-06-01 12:54:36.026230: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-06-01 12:54:36.026314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:36.026867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:36.027376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2021-06-01 12:54:36.027418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-06-01 12:54:36.027432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2021-06-01 12:54:36.027441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2021-06-01 12:54:36.027534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:36.028094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-06-01 12:54:36.028601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14161 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:259: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0601 12:54:36.605188 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:259: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:262: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0601 12:54:36.607963 140454876776320 deprecation.py:323] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:262: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:268: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0601 12:54:36.608431 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:268: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:274: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0601 12:54:36.608679 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/exporter.py:274: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0601 12:54:36.609005 140454876776320 builder_impl.py:636] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0601 12:54:36.609123 140454876776320 builder_impl.py:456] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: mask_model/saved_model/saved_model.pb\n",
            "I0601 12:54:37.066751 140454876776320 builder_impl.py:421] SavedModel written to: mask_model/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Face mask Detection/models/research/object_detection/utils/config_util.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0601 12:54:37.116924 140454876776320 deprecation_wrapper.py:119] From /content/drive/My Drive/Face mask Detection/models/research/object_detection/utils/config_util.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to mask_model/pipeline.config\n",
            "I0601 12:54:37.117192 140454876776320 config_util.py:182] Writing pipeline config file to mask_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}